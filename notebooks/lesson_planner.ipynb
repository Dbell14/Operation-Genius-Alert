{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24020860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Casham2045\\miniconda3\\envs\\ds\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import pymupdf4llm\n",
    " \n",
    "import faiss\n",
    " \n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89a63991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dotenv in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (0.9.9)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from dotenv) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39bb7f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf_keras in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: tensorflow<2.20,>=2.19 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tf_keras) (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (3.11.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (3.14.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf_keras) (0.5.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf_keras) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (14.1.0)\n",
      "Requirement already satisfied: namex in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (0.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf_keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf_keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf_keras) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf_keras) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf_keras) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf_keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf_keras) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf_keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (0.1.2)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (1.11.0.post1)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (4.55.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from sentence-transformers) (0.34.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from transformers) (2025.7.34)\n",
      "Requirement already satisfied: requests in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from transformers) (0.6.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow) (1.74.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: rich in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.1.0)\n",
      "Requirement already satisfied: namex in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: pymupdf4llm in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (0.0.27)\n",
      "Requirement already satisfied: pymupdf>=1.26.3 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from pymupdf4llm) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tf_keras\n",
    "!pip install faiss-cpu sentence-transformers transformers tensorflow \n",
    "!pip install pymupdf4llm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60b64348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tasks(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Finds a task for a student based on student's grade\n",
    "    \"\"\"\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    \n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "    You are a Software Engineering tutor. You analyze students' grades and find short tasks to improve their learning. \n",
    "    Your job is to create clear, actionable 7-day study plans for students who are struggling in a subject. \n",
    "    Each plan should include:\n",
    "    - Daily micro-tasks (small, manageable steps)\n",
    "    - Spaced review of previously covered material\n",
    "    - Clear instructions for practice problems or study activities\n",
    "    - Motivational and encouraging language to help the student stay engaged\n",
    "    Keep the plan practical, concise, and easy for a student to follow. \n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"student's prompt is {text}    \n",
    "    \"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "    )\n",
    "\n",
    "    output = completion.choices[0].message.content.strip()\n",
    "    print(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3f516e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**7-Day Study Plan for Improving Your Understanding of For Loops**\n",
      "\n",
      "**Objective**: To build a strong foundation in using for loops through practice, review, and application.\n",
      "\n",
      "---\n",
      "\n",
      "### Day 1: Introduction to For Loops\n",
      "- **Micro-tasks**:\n",
      "  1. Watch a 10-minute introductory video on for loops (YouTube is a great resource).\n",
      "  2. Read a short article or tutorial that explains the syntax of for loops.\n",
      "- **Spaced Review**: Briefly review the basics of loops you might have learned in class (0-5 minutes).\n",
      "- **Practice Activity**: Write a simple for loop in your favorite programming language that prints numbers 1 to 10. \n",
      "- **Encouragement**: You're starting to break down barriers! Every bit of understanding will get you closer to mastering loops.\n",
      "\n",
      "---\n",
      "\n",
      "### Day 2: Basic Exercises\n",
      "- **Micro-tasks**:\n",
      "  1. Review the for loop syntax you learned yesterday (5 minutes).\n",
      "  2. Complete at least three basic exercises home assignments or online platforms (like LeetCode or HackerRank) focusing on for loops.\n",
      "- **Spaced Review**: Recall your notes from yesterday—check if you remember the syntax without looking.\n",
      "- **Practice Activity**: Modify your Day 1 loop to print \"Number: 1\" to \"Number: 10\" instead of just numbers.  \n",
      "- **Encouragement**: Small steps lead to big successes! You're doing great by mixing revision with new exercises.\n",
      "\n",
      "---\n",
      "\n",
      "### Day 3: Applying For Loops\n",
      "- **Micro-tasks**:\n",
      "  1. Find and read about common use cases for for loops in programming (10 minutes).\n",
      "  2. Choose a simple project idea (like generating a multiplication table) to work on.\n",
      "- **Spaced Review**: Review your Day 2 exercises. Try to solve at least one without looking at the solutions.\n",
      "- **Practice Activity**: Implement a multiplication table using for loops (1 to 10, for both sides). \n",
      "- **Encouragement**: You're making tangible progress! Projects help solidify concepts, and you're creating real code!\n",
      "\n",
      "---\n",
      "\n",
      "### Day 4: Nested For Loops\n",
      "- **Micro-tasks**:\n",
      "  1. Watch a short tutorial on nested for loops (10 minutes).\n",
      "  2. Read an article about when and why to use nested loops (5-10 minutes).\n",
      "- **Spaced Review**: Go over your multiplication table code from Day 3 and try to explain the logic behind it (5 minutes).\n",
      "- **Practice Activity**: Create a pattern with stars (e.g., a pyramid) using nested for loops.\n",
      "- **Encouragement**: You've reached the next level! Nested loops may seem complex, but you're more than capable of handling them.\n",
      "\n",
      "---\n",
      "\n",
      "### Day 5: Review and Reinforcement\n",
      "- **Micro-tasks**:\n",
      "  1. Review all your notes and code from the past four days (20 minutes).\n",
      "  2. Identify any areas where you still feel unsure.\n",
      "- **Spaced Review**: Quiz yourself on for loop syntax and common use cases (5 minutes).\n",
      "- **Practice Activity**: Solve additional problems that require both single and nested for loops (resources like freeCodeCamp may have relevant exercises).\n",
      "- **Encouragement**: Every review strengthens your knowledge! Remember, it’s okay to have questions; that’s how learning happens.\n",
      "\n",
      "---\n",
      "\n",
      "### Day 6: Advanced For Loop Concepts\n",
      "- **Micro-tasks**:\n",
      "  1. Watch a tutorial on how to work with collections (arrays, lists) using for loops (10 minutes).\n",
      "  2. Start researching for loop variations (like for-in, for-of for JS, or range in Python).\n",
      "- **Spaced Review**: Think through the advanced uses and types of for loops; discuss them with a peer or friend if possible (10 minutes).\n",
      "- **Practice Activity**: Create a program that takes an array of numbers and prints their squares.\n",
      "- **Encouragement**: Each day you are adding tools to your programming toolbox! Keep experimenting and pushing boundaries!\n",
      "\n",
      "---\n",
      "\n",
      "### Day 7: Reflection and Application\n",
      "- **Micro-tasks**:\n",
      "  1. Reflect on what you’ve learned over the week. Write down key concepts (10 minutes).\n",
      "  2. Map out a mini project where you can effectively use for loops.\n",
      "- **Spaced Review**: Go over your previous exercises and refine your code, applying any new knowledge (15 minutes).\n",
      "- **Practice Activity**: Implement your mini project idea from the previous task. \n",
      "- **Encouragement**: You’ve come full circle! Every coder struggles at times, but you’ve put in the work—be proud of your progress!\n",
      "\n",
      "---\n",
      "\n",
      "### Final Note:\n",
      "Keep practicing beyond this week! For loops are a fundamental part of programming; the more you use them, the more comfortable you’ll become. Celebrate your achievements, and know that your hard work will pay off! 🎉\n",
      "**7-Day Study Plan for Improving Your Understanding of For Loops**\n",
      "\n",
      "**Objective**: To build a strong foundation in using for loops through practice, review, and application.\n",
      "\n",
      "---\n",
      "\n",
      "### Day 1: Introduction to For Loops\n",
      "- **Micro-tasks**:\n",
      "  1. Watch a 10-minute introductory video on for loops (YouTube is a great resource).\n",
      "  2. Read a short article or tutorial that explains the syntax of for loops.\n",
      "- **Spaced Review**: Briefly review the basics of loops you might have learned in class (0-5 minutes).\n",
      "- **Practice Activity**: Write a simple for loop in your favorite programming language that prints numbers 1 to 10. \n",
      "- **Encouragement**: You're starting to break down barriers! Every bit of understanding will get you closer to mastering loops.\n",
      "\n",
      "---\n",
      "\n",
      "### Day 2: Basic Exercises\n",
      "- **Micro-tasks**:\n",
      "  1. Review the for loop syntax you learned yesterday (5 minutes).\n",
      "  2. Complete at least three basic exercises home assignments or online platforms (like LeetCode or HackerRank) focusing on for loops.\n",
      "- **Spaced Review**: Recall your notes from yesterday—check if you remember the syntax without looking.\n",
      "- **Practice Activity**: Modify your Day 1 loop to print \"Number: 1\" to \"Number: 10\" instead of just numbers.  \n",
      "- **Encouragement**: Small steps lead to big successes! You're doing great by mixing revision with new exercises.\n",
      "\n",
      "---\n",
      "\n",
      "### Day 3: Applying For Loops\n",
      "- **Micro-tasks**:\n",
      "  1. Find and read about common use cases for for loops in programming (10 minutes).\n",
      "  2. Choose a simple project idea (like generating a multiplication table) to work on.\n",
      "- **Spaced Review**: Review your Day 2 exercises. Try to solve at least one without looking at the solutions.\n",
      "- **Practice Activity**: Implement a multiplication table using for loops (1 to 10, for both sides). \n",
      "- **Encouragement**: You're making tangible progress! Projects help solidify concepts, and you're creating real code!\n",
      "\n",
      "---\n",
      "\n",
      "### Day 4: Nested For Loops\n",
      "- **Micro-tasks**:\n",
      "  1. Watch a short tutorial on nested for loops (10 minutes).\n",
      "  2. Read an article about when and why to use nested loops (5-10 minutes).\n",
      "- **Spaced Review**: Go over your multiplication table code from Day 3 and try to explain the logic behind it (5 minutes).\n",
      "- **Practice Activity**: Create a pattern with stars (e.g., a pyramid) using nested for loops.\n",
      "- **Encouragement**: You've reached the next level! Nested loops may seem complex, but you're more than capable of handling them.\n",
      "\n",
      "---\n",
      "\n",
      "### Day 5: Review and Reinforcement\n",
      "- **Micro-tasks**:\n",
      "  1. Review all your notes and code from the past four days (20 minutes).\n",
      "  2. Identify any areas where you still feel unsure.\n",
      "- **Spaced Review**: Quiz yourself on for loop syntax and common use cases (5 minutes).\n",
      "- **Practice Activity**: Solve additional problems that require both single and nested for loops (resources like freeCodeCamp may have relevant exercises).\n",
      "- **Encouragement**: Every review strengthens your knowledge! Remember, it’s okay to have questions; that’s how learning happens.\n",
      "\n",
      "---\n",
      "\n",
      "### Day 6: Advanced For Loop Concepts\n",
      "- **Micro-tasks**:\n",
      "  1. Watch a tutorial on how to work with collections (arrays, lists) using for loops (10 minutes).\n",
      "  2. Start researching for loop variations (like for-in, for-of for JS, or range in Python).\n",
      "- **Spaced Review**: Think through the advanced uses and types of for loops; discuss them with a peer or friend if possible (10 minutes).\n",
      "- **Practice Activity**: Create a program that takes an array of numbers and prints their squares.\n",
      "- **Encouragement**: Each day you are adding tools to your programming toolbox! Keep experimenting and pushing boundaries!\n",
      "\n",
      "---\n",
      "\n",
      "### Day 7: Reflection and Application\n",
      "- **Micro-tasks**:\n",
      "  1. Reflect on what you’ve learned over the week. Write down key concepts (10 minutes).\n",
      "  2. Map out a mini project where you can effectively use for loops.\n",
      "- **Spaced Review**: Go over your previous exercises and refine your code, applying any new knowledge (15 minutes).\n",
      "- **Practice Activity**: Implement your mini project idea from the previous task. \n",
      "- **Encouragement**: You’ve come full circle! Every coder struggles at times, but you’ve put in the work—be proud of your progress!\n",
      "\n",
      "---\n",
      "\n",
      "### Final Note:\n",
      "Keep practicing beyond this week! For loops are a fundamental part of programming; the more you use them, the more comfortable you’ll become. Celebrate your achievements, and know that your hard work will pay off! 🎉\n"
     ]
    }
   ],
   "source": [
    "response = get_tasks('I got a low grade in for loops')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2d75c066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "data = \".\"\n",
    "def get_tags(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Finds tags for the requested topic in software engineering\n",
    "    \"\"\"\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    system_prompt = f\"\"\"\n",
    "    Can you come up with a list of tags to quickly search material for the 7 day study plan for software engineers. \n",
    "    These are the topics covered in the Data Science course:{data}\n",
    "    Don't use hashtag in the beginning of the words. Don't use hashtags from social media.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"student's prompt is {text}    \n",
    "    \"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "    )\n",
    "\n",
    "    output = completion.choices[0].message.content.strip()\n",
    "    #print(output)\n",
    "    return output\n",
    "\n",
    "get_tags(\"AB Testing\")\n",
    "updated_tags = get_tags('AB Testing')\n",
    "print(type(updated_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5b20ae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_tags = updated_tags.replace(\"\\n\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab13bfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Introduction to K-Nearest-Neighbors.pdf:\n",
      "# **Introduction to** **K-Nearest-Neighbors**\n",
      "\n",
      "\n",
      "#### **Agenda - Goals**\n",
      "\n",
      "##### **●**\n",
      "\n",
      "\n",
      "## **Warm Up**\n",
      "\n",
      "\n",
      "## **k-Nearest Neighbors**\n",
      "\n",
      "\n",
      "#### **k-Nearest Neighbors (kNN)**\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#### **k-Nearest Neighbors (\n",
      "Processing NLP & Vector Embeddings.pdf:\n",
      "# **Natural Language** **Processing & Vector** **Embeddings**\n",
      "\n",
      "\n",
      "### **Agenda - Goals**\n",
      "\n",
      "\n",
      "**●** **…**\n",
      "\n",
      "\n",
      "## **Kahoot**\n",
      "\n",
      "\n",
      "Let’s begin todays Kahoot\n",
      "\n",
      "\n",
      "## **Pre-Class Review**\n",
      "\n",
      "\n",
      "### **Pre-Class Review**\n",
      "\n",
      "\n",
      "\n",
      "Processing Probability Review.pdf:\n",
      "# **Probability Review**\n",
      "\n",
      "\n",
      "#### **Agenda - Schedule**\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#### **Agenda - Announcements**\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "#### **Agenda - Goals**\n",
      "\n",
      "\n",
      "**●**\n",
      "**Review basic probability**\n",
      "\n",
      "\n",
      "**●**\n",
      "**Understand how sample calculation\n",
      "Processing Random Forests.pdf:\n",
      "# **Random Forests &** **Boosted Forests**\n",
      "\n",
      "\n",
      "### **Agenda - Schedule**\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "### **Agenda - Goals**\n",
      "\n",
      "\n",
      "**●**\n",
      "\n",
      "\n",
      "## **Bagging**\n",
      "\n",
      "\n",
      "|team1_3point|team2_turnover|team1_won|\n",
      "|---|---|---|\n",
      "|35|15|1|\n",
      "|28.5|12|\n",
      "Processing Shopping Dataset Case Study.pdf:\n",
      "# **Shopping Dataset Case** **Study**\n",
      "\n",
      "\n",
      "### **Agenda - Goals**\n",
      "\n",
      "\n",
      " Apply basic and intermediate pandas methods to **explore a structured dataset**\n",
      "\n",
      "\n",
      " - Perform **univariate and bivariate analysis** on \n",
      "Processing SQL Review II.pdf:\n",
      "# **SQL Review II**\n",
      "\n",
      "\n",
      "### **Agenda - Announcements**\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "### **Agenda - Goals**\n",
      "\n",
      "\n",
      "**●**\n",
      "**Simulate the interview process by asking you to complete and present**\n",
      "\n",
      "\n",
      "**technical challenges live.**\n",
      "\n",
      "\n",
      "**●*\n",
      "Processing SQL Review.pdf:\n",
      "# **SQL Review**\n",
      "\n",
      "\n",
      "### **Agenda - Announcements**\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "### **Agenda - Goals**\n",
      "\n",
      "\n",
      "**●**\n",
      "**Simulate the interview process by asking you to complete and present**\n",
      "\n",
      "\n",
      "**technical challenges live.**\n",
      "\n",
      "\n",
      "**●**\n",
      "*\n",
      "Processing Transformer Architecture.pdf:\n",
      "# **A Quick Run-Through of** **Transformer** **Architecture**\n",
      "\n",
      "\n",
      "### **Agenda - Goals**\n",
      "\n",
      "#### **●** **Understand how LLMs work at a high level** **●** **Big idea behind Attention** **●** **Why Attentio\n",
      "Processing Twitter Dataset Case Study.pptx.pdf:\n",
      "# **Twitter Dataset Case** **Study**\n",
      "\n",
      "\n",
      "#### **Agenda - Goals**\n",
      "\n",
      "\n",
      " Perform time series exploration using pandas\n",
      "\n",
      "\n",
      " Extract key date-time features like hour and weekday\n",
      "\n",
      "\n",
      " Analyze and visualize patterns\n",
      "Processing Types of Visualizations Review.pdf:\n",
      "# **Types of Visualizations** **Review**\n",
      "\n",
      "\n",
      "|“The existence of Comet NEOWISE (here depicted as a series|Col2|\n",
      "|---|---|\n",
      "|_of red dots) was discovered by analyzing astronomical survey_|_of red dots) was\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "slides = {}\n",
    "pdf_directory = r\"../data\"\n",
    "for filename in os.listdir(pdf_directory):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            filepath = os.path.join(pdf_directory, filename)\n",
    "            # Now, you can process each PDF file using pymupdf4llm\n",
    "            # For example, to extract text as Markdown:\n",
    "            markdown_content = pymupdf4llm.to_markdown(filepath)\n",
    "            print(f\"Processing {filename}:\")\n",
    "            # You can then work with the extracted markdown_content\n",
    "            print(markdown_content[:200]) # Print first 200 characters for demonstration\n",
    "            slides[filename] = markdown_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4271760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Introduction to K-Nearest-Neighbors.pdf': '# **Introduction to** **K-Nearest-Neighbors**#### **Agenda - Goals**##### **●**## **Warm Up**## **k-Nearest Neighbors**#### **k-Nearest Neighbors (kNN)**#### **k-Nearest Neighbors (kNN)**##### You recognize some cybersecurity fellows, as well as data science fellows. **You notice that everyone is congregating and chatting in groups.**##### But then, you notice someone that you do not recognize. Considering however that all cyber-security fellows are sticking together, which **fellowship does this person most likely belong to?**##### Most likely a cyber-security fellow, no?##### What if we have someone that’s on the periphery of both groups ? We’ll solve this during our discussion of the kNN algorithm.#### **k-Nearest Neighbors (kNN)**We formalize this idea via the following formula for conditional probability. Once again let’s break thisdown before moving to an example.The likelihood the **class of this sample is “j”,** given **the point x** **0** is equal to*Note, we identify the set of “K” nearest points as N 0 . There’snothing special about this name (for now), we could have named it“Roofus” if we wanted to.The likelihood the **class of this sample is “j”,** given **the point x** **0** is equal toThe likelihood the **class of this sample is “j”,** given **the point x** **0** is equal toThe likelihood the **class of this sample is “j”,** given **the point x** **0** is equal toYou may be thinking “ _Darn that’s a whole lot of symbols to say something so simple_ .”However, when it comes to creating ideas in maths, we **cannot be ambiguous** . Therefore weformalize these ideas in a **common set of symbols that all humans agree on** . It’s a beautifulthing really.Succinctly put, we estimate the **conditional probability that x0 belongs to class j as the fraction of the K****nearest points** **whose response values equal j** .Let’s bring back our kibble/loud dataset that identifies **cats, hamsters, and dogs** . I reduced thedata-points to make this graph easier to discuss. You may notice the axes now have equal range, this willI introduce a mystery animal. Let’s assume they are located on coordinate (40, 30). Let’s estimate theprobability that this animal is a cat, dog, or hamster using our **estimated conditional probability.**#### **Small Aside - Euclidean Distance (L2)**#### **Small Aside - Euclidean Distance (L2)**#### **Small Aside - Euclidean Distance (L2)**#### **Small Aside - Euclidean Distance (L2)**#### **Small Aside - Euclidean Distance (L2)**#### **Small Aside - Euclidean Distance (L2)**#### **Small Aside - Euclidean Distance (L2)**#### **Small Aside - Manhattan Distance (L1)**Now, picture we can only travel in straight lines andturn in right angles (as if we were on the streets of**manhattan** ).This entails simply adding the sides of our righttriangle!Can anyone calculate this?#### **Small Aside - Manhattan Distance (L1)**Now, picture we can only travel in straight lines andturn in right angles (as if we were on the streets of**manhattan** ).This entails simply adding the sides of our righttriangle!Can anyone calculate this?And perhaps propose a formula for us to use?#### **Small Aside - Manhattan Distance (L1)**##### ⅔ ⅓We’re going to pause our discussion ofkNN here.However there is more to evaluate whendiscussing this **simple, yet powerful****algorithm.**What are some questions you mighthave regarding kNN?We’re going to pause our discussion ofkNN here.However there is more to evaluate whendiscussing this **simple, yet powerful****algorithm.**What are some questions you mighthave regarding kNN?**●****Why are my axes normalized?****●** **When do we use euclidean vs****manhattan?****●****What happens if we have****categorical data?****●****What happens as I increase my****dimensions?****●** **What are some cons to kNN?**##### Going back to our TKH industry event discussion, we simply select some “K” that accurately classifies this person as a data or cyber fellow.##### **k=3**##### **Class = Cyber**##### **k=5**##### **Class = Cyber**##### Class = Cyber ( are we suffering from imbalance??? )## **Choosing a K - HyperParam**##### Let’s bring back our scatter plot (with a twist!) To obtain the decision boundary for kNN, we could compute the class using kNN for eachRed = cat; yellow = hammie; blue = dog##### We begin with k=1. What do you notice about the error rate? Does it make any mistakes?Red = cat; yellow = hammie; blue = dog##### None whatsoever! While our “training” rate might seem ideal, let’s see what happens when we introduce a new test sample. Who is our hamster friend **classified as?**##### A cat . Remember everyone, a classifier that perfectly fits our training dataRed = cat; yellow = hammie; blue = dog##### We move onto k=3. What happens to our training error rate now?Red = cat; yellow = hammie; blue = dog##### Unfortunately a few training samples are classified incorrectly, but this could actually be preferable when it comes to our testing data !##### Bringing back our hamster, we see that it is now correctly classified as a hamster (ignore the roughness of my sketches)Red = cat; yellow = hammie; blue = dog##### Finally lets try k=6. What happens to our training error rate now?#### **kNN - Importance of Data Scaling**##### _X1: (-2 to 2)_ _X2: (-2 to 2)_ Now that we’ve standardized our dataset, we can assign equal **importance to dimensions.** Subsequently, we update our predictions.#### **kNN**###### To conclude our conversation on the supervised learning classifier kNN, it is a **powerful non-parametric supervised learning algorithm that utilizes a** . **fairly “lazy” classification method** Pros ● No optimization involved ● Comparable performance to Naive Bayes **●** **Easy to understand** Cons ● Sensitive to class imbalance ● Need to store entire training dataset for prediction                       Good visual of kNN from https://knn [notebook.netlify.app/](https://knn-notebook.netlify.app/)##### Let’s review the following gif to see the process that kNN takes to classify a new test observation.## **Classification Challenges**#### **Classification Challenges**#### **Choosing a Distance Metric**#### **Choosing a Distance Metric**What do you notice about the **sparsity** of our data as we increase dimensions?Notice how the frequency of distances converges on a specific value as we increase dimensions:[https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote02_kNN.html](https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote02_kNN.html)#### **The Curse of Dimensionality**##### Lower dimensional manifold in a nutshell: “ Wow this looks really complex… ”#### **Handling Data Imbalance**_True Positives + True Negatives__False Negatives_##### This leads to what we call the **accuracy** paradox (null accuracy). Let’s say you go to another industry event and you see 9 cyber fellows and 1 data fellow. You train a kNN algorithm and it gives you a 90% accuracy rate. Wow! This must be a **good model, no?**_True Positives + True Negatives__False Negatives__9 + 0_**90%**_9 + 0_**90%**#### **Over-Sampling Vs Under-Sampling**#### **Over-Sampling Vs Under-Sampling**#### **SMOTE**_Synthetic Minority Over-sampling Technique_This technique entails creating new _synthetic minority classes_ via a somewhat randomized process.1. Choose a random set of the minority class2. Find k-nearest-neighbors for each sample of the same class3. Calculate a new synthetic class between this sample and all of its neighborsa. Choose a random value between 0 & 1 to calculate where this newly random point willexist in the space between your data point and its neighbors##### This allows us to “purposefully” oversample our dataset to improve the predictive qualities of our dataset.#### **Handling Data Imbalance**##### This is especially useful when trying to detect some real relatively rare class in your dataset: ● Actual fraud **● A rare disease** ● **A 16-seeded team beating a 1-seeded team**## **End of Class Announcements**##### ○ Where does variance/bias exist in kNN?|Neural network training|makes||---|---||**_beautiful fractals_**||',\n",
       " 'NLP & Vector Embeddings.pdf': '# **Natural Language** **Processing & Vector** **Embeddings**### **Agenda - Goals****●** **…**## **Kahoot**Let’s begin todays Kahoot## **Pre-Class Review**### **Pre-Class Review**## **Natural Language Processing**### **Natural Language Processing**### **Natural Language Processing Techniques**As it turns out, computer scientists have been attempting to solve this problemfor a quite a long time. Let’s review the foundational techniques of analyzing a“corpus” of text._**●**__**Bag of Words**_ (Harris 1954)_**●**_ _**TF-IDF**_ (Jones 1972)These techniques are dated by this point, **but it doesn’t mean these techniques****are useless.** Let’s see what their purpose is in the world of document analysis.### **Bag of Words**Let’s take three example text files and see how the BOW technique analyzes them.We will use **3 example reviews from Amazon and their subsequent reviews (out****of 5 stars)** .What’s the first step to the BOW technique?**(1)****(2)**### **Term Frequency-Inverse Document Frequency** **(TF-IDF)**While BOW is a trivial technique to interpret text, we can iterate upon thisimplementation via the **Term Frequency-Inverse Document Frequency** algorithm.The steps to this include:_**1.**_ _**BOW steps up to step 2**__**2.**_ _**Calculate the total number of times word t appears in document d, divided by all the**__**terms in document d (term frequency)**__**3.**_ _**Calculate the total number of documents divided by the number of documents**__**containing term t (inverse document frequency)**__**4.**_ _**Multiply these two values together to calculate the tf-idf.**_## **Vector Embeddings**### **Word Embeddings - Data Representations**### **Word Embeddings - Word2Vec**By observing wheres these data-samples exist in the **semantic feature**Lastly, to demonstrate the power of word2vec transformations, let’s say wehave the additional data-samples “ **evening** ” and “ **dinner** .”Try adding the vectors “lunch” + “evening” [1, 4] + [3, -3].Which value do we get?### **Word Embeddings - Word2Vec**### **Word Embeddings - Word2Vec**### **Word Embeddings - Word2Vec (SkipGram)**Let’s observe the steps to train a **skip-gram word2vec**_**1.**_ _**Tokenize your text into words (or n-grams)**__**2.**_ _**Eliminate stop-words and punctuation**_**3.** **Choose a window size of “n”****4.** **Loop through each window of your corpus****a.****Train your single hidden layer neural network on each (n) context****words & target word**_**The dog eats the bone**__**The cat eats fish.**__**The cat scratches its owner.**_## **Embedding Everything**### **Transformer Embeddings**## **End of Class Announcements**',\n",
       " 'Probability Review.pdf': '# **Probability Review**#### **Agenda - Schedule**#### **Agenda - Announcements**#### **Agenda - Goals****●****Review basic probability****●****Understand how sample calculations differ from population****●****Understand & apply Bayes Theorem**## **Inferring from a Sample**We often use humans when discussing population vs sample, but thisapplies **to any dataset** . Ex: All AAPL stock prices since Dec 14, 1984( **population** ) & AAPL stock price on Dec 12, 2024 ( **sample** ).Our equations for measures of dispersion change based on which subset weare calculating our metrics on. This is **because a sample is an estimate**, and a.**population is ground truth**## **Probability Review**|Event|Probability||---|---||**Dog**|0.5||**Cat**|0.3||**Hamster**|0.1||**Lizard**|0.0||**No pet**|0.1|Let’s increase our sample space in order to discuss more complex terms.Here we describe the probabilities that an american household has somespecific pet.**Dog** **Cat** **Hamster** **Lizard** **None**Graphing these values gives us the **probability distribution** .|Event|Probability||---|---||**Dog**|0.5||**Cat**|0.3||**Hamster**|0.1||**Lizard**|0.0||**No pet**|0.1|## **Probability in Data Analysis -** **Bayes Theorem**#### **Probability in Data Analysis**#### **Bayes Theorem - Frequentist World-View**#### **Bayes Theorem - Frequentist Pros**#### **Bayes Theorem - Frequentist Cons**#### **Bayes Theorem - Frequentist Cons**#### **Bayes Theorem - Bayesian Statistics**_statistician_## **P(H) P(E|H)**Here’s the formula, let’s **break down its components** before going throughour covid example.Remember, the “|” is the symbolfor conditional probabilitystatements.“Hypothesis given Event”## **P(H) P(E|H)**The probability the **hypothesis** is true given the **event** is equal toThe probability the **hypothesis** is true given the **event** is equal toThe probability the **hypothesis** is true given the **event** is equal to## **P(H) P(E|H)**Divided by the probability of **event** occurring. This part is sometimesdeceptively simple. Keep in mind that we want to consider the **event occurs****given the hypothesis is true and given the hypothesis is false** !Let’s understand how to calculate this. I find diagrams to be the most helpfulin visualizing this calculationTo calculate P(E), we have to consider the intersection of P(E) and P(H), aswell as the space where P(E) exists outside of P(H)This intersect can be labeled **P(E & H)**In terms of conditional probability, that is **P(H)P(E|H)**And lastly we have **P(E & -H).** Can anyone express this in terms ofconditional probability as well?**P(-H)P(E|-H). This allows us to express P(E) as P(H)P(E|H) + P(-H)P(E|-H)**## **P(H) P(E|H)****P(H|E) = 0.089****P(H|E) = 0.47**## **Wrap-Up**',\n",
       " 'Random Forests.pdf': '# **Random Forests &** **Boosted Forests**### **Agenda - Schedule**### **Agenda - Goals****●**## **Bagging**|team1_3point|team2_turnover|team1_won||---|---|---||35|15|1||28.5|12|0||40|18|1||25.0|20.0|0|1 0 1 0And this is only for our4-sample dataset. Whatif we have 100, 1000 or1,000,000 samples?|team1_3point|team2_turnover|team1_won||---|---|---||35|15|1||28.5|12|0||40|18|1||25.0|20.0|0|Going back to the formulation of our decision trees, our trees will **overfit to****this noisy data and fail to generalize on new test samples.**Is this considered high bias or high variance?1 0 1 0|team1_3point|team2_turnover|team1_won||---|---|---||35|15|1||28.5|12|0||40|18|1||25.0|20.0|0|Therefore, we need a method to cut through all this noise and somehow**extract the true signal from this dataset** . The first technique we will learn is.**bagging**### **Bagging - Bootstrapping**### **Bagging - Bootstrapping**### **Bagging - Bootstrapping + Aggregating**Let’s apply this technique to our decision trees inorder to implement what we call “ **bagged trees.** ”The algorithm for **bagging (bootstrapping +****aggregating)** is applied through the following steps:1. Select _n_ random subsets of datasets withreplacement ( **bootstrap** )2. Grow arbitrarily large trees on each subset3. “ _Democratically_ ” select the prediction whichhas the most votes across all trees( **aggregate** ).|team1_3point|team2_turnover|team1_won||---|---|---||35|15|1||28.5|12|0||40|18|1||25.0|20.0|0||37.5|14.0|1||30.0|16.0|0||42.0|19.5|1||33.5|21.0|0|Let’s bring back our basketball dataset to see how we can apply **bagging** andstrengthen the true signal of our dataset. We include a few more data pointsto make this a little more interesting.|28.5|12|0||---|---|---||37.5|14.0|1||30.0|16.0|0||Col1|35|15|1||---|---|---|---|||42.0|19.5|1|||28.5|12|0||40|18|1||---|---|---||33.5|21.0|0||25.0|20.0|0||team1_3point|team2_turnover|team1_won||---|---|---||35|15|1||28.5|12|0||40|18|1||25.0|20.0|0||37.5|14.0|1||30.0|16.0|0||42.0|19.5|1||33.5|21.0|0||Col1|28.5|12|0||---|---|---|---|||42.0|19.5|1|||28.5|12|0|First, we will make 4 random subsets of data (with replacement). This is the**bootstrap** step.**Note** : keep in mind thatthis example is toosimple to make anymeaningful tree|28.5|12|0||---|---|---||37.5|14.0|1||30.0|16.0|0|1 0|35|15|1||---|---|---||42.0|19.5|1||28.5|12|0||40|18|1||---|---|---||33.5|21.0|0||25.0|20.0|0||28.5|12|0||---|---|---||42.0|19.5|1||28.5|12|0|1 0|team1_3point|team2_turnover|team1_won_pred||---|---|---||35|15|???||28.5|12|???||40|18|???||25.0|20.0|???||37.5|14.0|???||30.0|16.0|???||42.0|19.5|???||33.5|21.0|???|1 0|team1_3point|team2_turnover|team1_won_pred||---|---|---||35|15|???||28.5|12|???||40|18|???||25.0|20.0|???||37.5|14.0|???||30.0|16.0|???||42.0|19.5|???||33.5|21.0|???|1 010|team1_3point|team2_turnover|team1_won_pred||---|---|---||35|15|???||28.5|12|???||40|18|???||25.0|20.0|???||37.5|14.0|???||30.0|16.0|???||42.0|19.5|???||33.5|21.0|???|One question that youmight be thinking is“wait so now we’veintroduced a parameter’to indicate how manytrees we will train, isthis anotherhyperparameter thatwe must find viaGridSearch?”1 0101 0|team1_3point|team2_turnover|team1_won_pred||---|---|---||35|15|**1**||28.5|12|???||40|18|???||25.0|20.0|???||37.5|14.0|???||30.0|16.0|???||42.0|19.5|???||33.5|21.0|???|1 01 0tie|team1_3point|team2_turnover|team1_won_pred|team1_won||---|---|---|---||35|15|**1**|1||28.5|12|**0**|0||40|18|**1**|1||25.0|20.0|**0**|0||37.5|14.0|**1**|1||30.0|16.0|**0**|0||42.0|19.5|**1**|1||33.5|21.0|**0 or 1**|0|Just for fun, let’s fill out the rest of these samples and observe the accuracy. Noticethat we occasionally get **ties.** In this case, we decide randomly which class tochoose which leads us to an accuracy that ranges from **85% to 100%**As it turns out, the number of trees that we train _**“B”**_ does not suffer from overfitting (high variance) as weincrease this amount! Instead, error simply _settles_ after enough trees are generated. **WOW!**Therefore, we simplyuse a **sufficiently large****B** until we do not seelarge gains in testaccuracy.One technique we canuse is to start large(100), and then see howmany trees we can**remove for the same****test accuracy rate.**Impurity Removed = 0.8751 0Impurity Removed = 0.33Impurity Removed = 11 0Impurity Removed = 0.8751 0By adding all the impurity removed, we can observe which predictor is the **most important** . In thisdataset, which feature seems to remove the most impurity?## **Random Forests**### **Random Forests**|team1_3point|team2_turnover|team1_won||---|---|---||35|15|1||28.5|12|0||40|18|1||25.0|20.0|0||37.5|14.0|1||30.0|16.0|0||42.0|19.5|1||33.5|21.0|0|Let’s go back to our basketball example once more, and walk through thesteps of bagging with this additional caveat|28.5|12|0||---|---|---||37.5|14.0|1||30.0|16.0|0||Col1|35|15|1||---|---|---|---|||42.0|19.5|1|||28.5|12|0||40|18|1||---|---|---||33.5|21.0|0||25.0|20.0|0||team1_3point|team2_turnover|team1_won||---|---|---||35|15|1||28.5|12|0||40|18|1||25.0|20.0|0||37.5|14.0|1||30.0|16.0|0||42.0|19.5|1||33.5|21.0|0||Col1|28.5|12|0||---|---|---|---|||42.0|19.5|1|||28.5|12|0|First, we will make 4 random subsets of data (with replacement). This is the**bootstrap** step.|28.5|12|0||---|---|---||37.5|14.0|1||30.0|16.0|0||35|15|1||---|---|---||42.0|19.5|1||28.5|12|0||40|18|1||---|---|---||33.5|21.0|0||25.0|20.0|0||28.5|12|0||---|---|---||42.0|19.5|1||28.5|12|0|1 01 0|team1_3point|team2_turnover|team1_won_pred|team1_won||---|---|---|---||35|15|**1**|1||28.5|12|**0**|0||40|18|**1**|1||25.0|20.0|**0**|0||37.5|14.0|**1**|1||30.0|16.0|**0**|0||42.0|19.5|**1**|1||33.5|21.0|**1**|0|Once again, we allow these trees to democratically elect the prediction based on their **bootstrapped****samples and limited predictors. Notice that we get no ties! We walk away with one accuracy!**This outcome is not unique to our dataset. Notice the **Test:RandomForest** error rate performs noticeably**better than the simple bagged model** .- Computationally **expensive**## **Boosting - AdaBoost****Trees with better information on****which mistakes they should avoid****should also be better classifiers!****Metaphors get tough in this context****but consider the following:****You, a New Yorker/Connecticuter,****are voting for public transportation****policies in your city. Might you have****better context than an extra-state****voter?**|28.5|12|0||---|---|---||37.5|14.0|1||30.0|16.0|0|1 0|35|15|1||---|---|---||42.0|19.5|1||28.5|12|0||40|18|1||---|---|---||33.5|21.0|0||25.0|20.0|0||28.5|12|0||---|---|---||42.0|19.5|1||28.5|12|0|### **Boosting - AdaBoost**|team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|1/8||28.5|12|0|1/8||40|18|1|1/8||25.0|20.0|0|1/8||37.5|14.0|1|1/8||30.0|16.0|0|1/8||42.0|19.5|1|1/8||33.5|21.0|0|1/8|1 0|team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|1/8||28.5|12|0|1/8||40|18|1|1/8||25.0|20.0|0|1/8||37.5|14.0|1|1/8||30.0|16.0|0|1/8||42.0|19.5|1|1/8||33.5|21.0|0|1/8|Just like with random forests, we will grow **stumps** on a subset of predictors(one tree per predictor). However this time we use the **entire dataset.**= 0= 2= 4= 2Gini = 1 ((0/2)^2+(2/2)^2)= 2= 2= 2= 2|team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|1/8||28.5|12|0|1/8||40|18|1|1/8||25.0|20.0|0|1/8||37.5|14.0|1|1/8||30.0|16.0|0|1/8||42.0|19.5|1|1/8||33.5|21.0|0|1/8|= 0= 2= 4= 2Gini = 0.44Gini = 0= 2= 2= 2= 2|team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|1/8||28.5|12|0|1/8||40|18|1|1/8||25.0|20.0|0|1/8||37.5|14.0|1|1/8||30.0|16.0|0|1/8||42.0|19.5|1|1/8||33.5|21.0|0|1/8|= 0= 2= 4= 2Total Gini = 0.44 *(6/8) + 0 * (2/8)= 2= 2= 2= 2|team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|1/8||28.5|12|0|1/8||40|18|1|1/8||25.0|20.0|0|1/8||37.5|14.0|1|1/8||30.0|16.0|0|1/8||42.0|19.5|1|1/8||33.5|21.0|0|1/8|= 0= 2= 4= 2= 2= 2= 2= 2|team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|1/8||28.5|12|0|1/8||40|18|1|1/8||25.0|20.0|0|1/8||37.5|14.0|1|1/8||30.0|16.0|0|1/8||42.0|19.5|1|1/8||33.5|21.0|0|1/8|= 0= 2= 4= 2Total Error = ⅛ + ⅛ = **0.25**0 -> Perfect stump1 -> Bad stump|team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|1/8||28.5|12|0|1/8||40|18|1|1/8||25.0|20.0|0|1/8||37.5|14.0|1|1/8||30.0|16.0|0|1/8||42.0|19.5|1|1/8||33.5|21.0|0|1/8|= 0= 2= 4= 2|team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|1/8||28.5|12|0|1/8||40|18|1|1/8||25.0|20.0|0|1/8||37.5|14.0|1|1/8||30.0|16.0|0|1/8||42.0|19.5|1|1/8||33.5|21.0|0|1/8||team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|1/8||28.5|12|0|1/8||40|18|1|1/8||25.0|20.0|0|1/8||37.5|14.0|1|1/8||30.0|16.0|0|1/8||42.0|19.5|1|1/8||33.5|21.0|0|1/8||team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|1/8||28.5|12|0|1/8||40|18|1|1/8||25.0|20.0|0|1/8||37.5|14.0|1|1/8||30.0|16.0|0|1/8||42.0|19.5|1|1/8||33.5|21.0|0|1/8||team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|0.10||28.5|12|0|0.10||40|18|1|0.10||25.0|20.0|0|0.10||37.5|14.0|1|0.10||30.0|16.0|0|0.16||42.0|19.5|1|0.10||33.5|21.0|0|0.16||team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|0.1086||28.5|12|0|0.1086||40|18|1|0.1086||25.0|20.0|0|0.1086||37.5|14.0|1|0.1086||30.0|16.0|0|0.1739||42.0|19.5|1|0.1086||33.5|21.0|0|0.1739||team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|0.1086||28.5|12|0|0.1086||40|18|1|0.1086||25.0|20.0|0|0.1086||37.5|14.0|1|0.1086||30.0|16.0|0|0.1739||42.0|19.5|1|0.1086||33.5|21.0|0|0.1739||team1_3point|team2_turnover||---|---||35|15||28.5|12||40|18||25.0|20.0||37.5|14.0||30.0|16.0||42.0|19.5||33.5|21.0||team1_3point|team2_turnover||---|---||33.5|21.0||28.5|12||30.0|16.0||33.5|21.0||28.5|12||40|18||30.0|16.0||25.0|20.0||team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||33.5|21.0|0|1/8||28.5|12|0|1/8||30.0|16.0|0|1/8||33.5|21.0|0|1/8||28.5|12|0|1/8||40|18|1|1/8||30.0|16.0|0|1/8||25.0|20.0|0|1/8||team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||33.5|21.0|0|1/8||28.5|12|0|1/8||30.0|16.0|0|1/8||33.5|21.0|0|1/8||28.5|12|0|1/8||40|18|1|1/8||30.0|16.0|0|1/8||25.0|20.0|0|1/8|**team1_3point** **team2_turnover** **0.24**This is a limited example.You should instead expectto have 10,20, or 30 treeson a dataset **of thousands****if not millions of rows.**|team1_3point|team2_turnover||---|---||21|18||36|17||39|15|## **Boosting - Gradient Boosting**### **Gradient Boosting**## **End of Class Announcements**',\n",
       " 'Shopping Dataset Case Study.pdf': '# **Shopping Dataset Case** **Study**### **Agenda - Goals** Apply basic and intermediate pandas methods to **explore a structured dataset** - Perform **univariate and bivariate analysis** on real-world shopping data Create visualizations using seaborn to support your findings Use grouping and aggregation techniques such as groupby(), pivot_table(), qcut(), andagg() Develop and **communicate insights clearly based on observed data patterns**, not justthe code used## **Shopping Dataset Case Study**You are a Data Analyst for *FlastFash*, a Budapest-based online clothingstore that\\'s looking to break into the American market.### **Shopping Dataset Case Study**Prepare a report for your manager by answering the listed reflectionquestions!## **Visualizing Data - Seaborn**### **Visualizing Data - Bar Graph**Notice that thesex-axis labels aren’teasy to read…#### **df.value_counts(“Color”).plot.bar()**We can quickly plot the frequencies of categories by specifying a**categorical column** in the **value_counts** method, and then by calling the**plot.bar** () method.#### **df.value_counts(“Color”).plot.barh()**### **Visualizing Data - Histogram**What can we do tobetter observe ourdistributions?#### **df[“Purchase Amount (USD)”].plot.hist()**By specifying a **numerical column** and then calling the **plot.hist()** method,we can plot a histogram on a numeric series to observe the distribution ofour dataset.#### **df[“Purchase Amount (USD)”].plot.hist(bins=30)**By **increasing the number of bins**, we can better observe the distributionsthat are apparent in our dataset. What kind of distribution do we see here?#### **sns.scatterplot(df, x=\"Age\", y=\"Purchase Amount (USD)\")**By specifying a **dataframe, and two numerical columns** in the **scatterplot**method, we can plot a scatter-plot to observe the relationship between twonumeric variables. **Do you notice any correlation between age and****purchase amount?**#### **corr** **df[[\"Age\", \"Purchase Amount (USD)\"]]. ()**As we see from the correlation matrix, there is no correlation between ageand purchase amount. However can you identify **clusters** of data whichmight be emerging between these two variables?### **Visualizing Data - Box Plot**#### **sns.boxplot(df, x=\"Review Rating\", y=\"Purchase Amount (USD)\")**By specifying a **dataframe, one categorical, and one numerical column** inthe **boxplot** method, we can plot a box-plot to observe how a distributionvaries across categories. **Do you notice any sizeable differences in median?**## **Shopping Dataset Case Study**Complete this analysis and meet back at 9:20 to answer analytical questionsvia the wheel.## **TLAB #3****Doing your Own EDA**',\n",
       " 'SQL Review II.pdf': '# **SQL Review II**### **Agenda - Announcements**### **Agenda - Goals****●****Simulate the interview process by asking you to complete and present****technical challenges live.****●****Continue working on TLAB #3**## **LeetCode Q1**## **LeetCode Q2**## **LeetCode Q3**## **LeetCode Q4**## **TLAB #3**',\n",
       " 'SQL Review.pdf': '# **SQL Review**### **Agenda - Announcements**### **Agenda - Goals****●****Simulate the interview process by asking you to complete and present****technical challenges live.****●****Continue working on TLAB #3**## **LeetCode Q1**## **LeetCode Q2**## **LeetCode Q3**## **LeetCode Q4**## **TLAB #3**',\n",
       " 'Transformer Architecture.pdf': \"# **A Quick Run-Through of** **Transformer** **Architecture**### **Agenda - Goals**#### **●** **Understand how LLMs work at a high level** **●** **Big idea behind Attention** **●** **Why Attention sparked the modern AI Boom**## **Text Prediction via Neural** **Networks**In more niche circles, we could even apply the transformer architecture to EEG wavesto text (aka mind-reading).## **LLMs and Attention**### **LLMs**For now we want you to think of LLMs as an advancedversion of autocomplete, given a prompt.Rather than providing options of words to complete a phrase,an LLMs output contains a probability distribution of thenext likely word.Instead of always selecting the most probable word however,we can adjust a parameter called **temperature**, such that wesee a bit of randomness in the next outputted word.The recognition of these traits were **learned independently by the neural network itself.**Similarly as the word embedded vectors pass through the transformer architecture, eachhead of attention learns different patterns within the body of text#### Innovations in hardware allow us to run these neural networks. Attention models can process all words at once. Without parallel hardware, LLMs would not work!Almost all of the technology behind this third AI boom has come from the transformerarchitecture! Although originally invented for text, (machine translation) it can be used onimage data, audio data, biological data (protein folding) and much more!In short, transformers aren't just good at reading, they're good at any problem where themodel needs to look at a lot of data and decide what's important.\",\n",
       " 'Twitter Dataset Case Study.pptx.pdf': '# **Twitter Dataset Case** **Study**#### **Agenda - Goals** Perform time series exploration using pandas Extract key date-time features like hour and weekday Analyze and visualize patterns in tweet volume and sentiment Use string matching techniques to filter tweets by content Focus on developing insightful conclusions, not just writing code## **Twitter Dataset Case Study**You are a Data Scientist for *SuperEgo* an NYC-based research institutelooking to create a language model that closely emulates a twitter-user.#### **Twitter Dataset Case Study**Like yesterday, we will use the first-half of class to work on this case studytogether.After break, we will ask you to complete this case study in your groups.We will congregate back at 9:20 to discuss results (with the wheels help).## **Pandas Time Series Data**#### **Pandas Review - Time Bound Data****NOTE:** If it takes more than 2minutes to make your plot (and itcomes out looking like nonsense),you’ve made the **wrong plot.****Don’t make plots just to make plots.**##### **sns.lineplot(df, x=\"date\", y=\"sentiment\")****df[“Date”] = pd.to_datetime(df[“Date”])**Before we do ANYTHING! We must ensurethat our date column is being treated as a“datetime” column.We can do this by calling the “ **to_datetime** ()”method on our date column, and reassigning itback into our original column. Remember, if wedon’t save our changes, we lose them!|ID|Date|Amount||---|---|---||1|Mon Apr 17 20:30 2023|5.24||2|Mon Apr 17 20:31 2023|10.98||3|Mon Apr 17 20:35 2023|1.58||4|Mon Apr 17 23:35 2023|50.60||5|Tues Apr 18 04:20<br>2023|34.01||6|Tues Apr 18 07:50<br>2023|25.05||7|Thurs Apr 20 12:50<br>2023|5.63|For demonstration purposes, let’s look at a dataset of **transactions** in an online shoppingplatform.This dataset is not in our case study, but it will help us understand the resample method.**df.resample(“1D”, on=”Date”)**|ID|Date|Amount||---|---|---||1|Mon Apr 17 20:30 2023|5.24||2|Mon Apr 17 20:31 2023|10.98||3|Mon Apr 17 20:35 2023|1.58||4|Mon Apr 17 23:35 2023|50.60||5|Tues Apr 18 04:20<br>2023|34.01||6|Tues Apr 18 07:50<br>2023|25.05||7|Thurs Apr 20 12:50<br>2023|5.63|**df.resample(“1D”, on=”Date”)**|ID|Date|Amount||---|---|---||1|Mon Apr 17 20:30 2023|5.24||2|Mon Apr 17 20:31 2023|10.98||3|Mon Apr 17 20:35 2023|1.58||4|Mon Apr 17 23:35 2023|50.60||5|Tues Apr 18 04:20<br>2023|34.01||6|Tues Apr 18 07:50<br>2023|25.05||7|Thurs Apr 20 12:50<br>2023|5.63|**df.resample(“1D”, on=”Date”)[“Amount”].mean()**Note that we also getNaN values. These aredays that **don’t have****data**|ID|Date|Amount||---|---|---||1|Mon Apr 17 20:30 2023|5.24||2|Mon Apr 17 20:31 2023|10.98||3|Mon Apr 17 20:35 2023|1.58||4|Mon Apr 17 23:35 2023|50.60||5|Tues Apr 18 04:20<br>2023|34.01||6|Tues Apr 18 07:50<br>2023|25.05||7|Thurs Apr 20 12:50<br>2023|5.63|Just like with **groupby**, we can add a method to calculate some **summary****statistic** . This will select all rows that fall on **the same day…****df.resample(“1D”, on=”Date”)[“Amount”].mean()**Note that we also getNaN values. These aredays that **don’t have****data**|Date|Amount||---|---||Mon Apr 17 2023|17.1||Tues Apr 18 2023|29.53||Wednesday Apr 19 2023|NaN||Thurs Apr 20 2023|5.63|##### **df[\"date\"] = pd.to_datetime(df[\"date\"])** **df.resample(on=\"date\", rule=\"1D\")[\"sentiment\"].mean()**Let’s apply these same principles to our Twitter dataset to better visualizeour former line plot. First we will convert our “date” column to a date-timetype.##### **df[\"date\"] = pd.to_datetime(df[\"date\"])** **df.resample(on=\"date\", rule=\"1D\")[\"sentiment\"].mean()**Now we can resample our dataframe to calculate the average sentimentspers day. **While this is a good start**, how can we plot these values using aline plot?##### **df[\"date\"] = pd.to_datetime(df[\"date\"])** **df.resample(on=\"date\", rule=\"1D\")[\"sentiment\"].mean().plot.line()**###### **df.resample(on=\"date\", rule=\"1D\")[\"sentiment\"].mean().interpolate().plot.line()**## **Regex**As this is a Twitter dataset, we should probably utilize some sort oftext-based analysis. What have we learned about in the past which will helpus figure out what people are talking about?#### **Regular Expressions (Regex)****review**_Farukh is great__Where is Farukh?__Farrrrukh is terrible__I like Python27__@@@19586_|Regex Pattern|Col2||---|---||||_Farukh_**review**_Farukh is great__Where is Farukh?__Farrrrukh is terrible__I like Python27__@@@19586_For example, by just using the regex string “Farukh”, we will look for all rowsthat contain the string “Farukh.” Which rows will be matched?|Regex Pattern|Col2||---|---||||_Farukh_|Regex Pattern|Col2||---|---||||Remember, acomputer does notunderstand intent. Itwill only do exactlywhat you want it to do|Regex Pattern|Col2||---|---||||_Farukh_**review**_Farukh is great__Where is Farukh?__Farrrrukh is terrible__I like Python27__@@@19586_|Regex Pattern<br>^Far*ukh|review||---|---||Regex Pattern<br>_^Far*ukh_|_Farukh is great_||Regex Pattern<br>_^Far*ukh_|_Where is Farukh?_||Regex Pattern<br>_^Far*ukh_|_Farrrrukh is terrible_||Regex Pattern<br>_^Far*ukh_|_I like Python27_||Regex Pattern<br>_^Far*ukh_|_@@@19586_|By placing a caret at the front, we only find reviews that that begin with theword “Farukh” with an arbitrary number of r’s/|Regex Pattern|Col2||---|---|||||Regex Pattern|Col2||---|---||||Knowing regex will save you **hours of work** .#### **Regular Expressions (Regex)**Find all participants wholive in states startingwith “New”|age|age_spouse|State|income||---|---|---|---||32|35|New York|30,000||48|47|New Mexico|70,000||21|NA|California|20,0000|Find all participants wholive in states startingwith “New”|age|age_spouse|State|income||---|---|---|---||32|35|New York|30,000||48|47|New Mexico|70,000||21|NA|California|20,0000|Find all participants wholive in states startingwith “New”### **df[df.State.str.contains(“^New”)]**|age|age_spouse|State|income||---|---|---|---||32|35|New York|30,000||48|47|New Mexico|70,000||21|NA|California|20,0000||user|tweet||---|---||Daniiej|omg i\\'ve an economics test.||sensuoushel<br>p|FOX and the contestants won\\'t go about it<br>right||Taj_Milahi|good luck bro on the test||user|tweet||---|---||Daniiej|omg i\\'ve an economics test.||sensuoushel<br>p|FOX and the contestants won\\'t go about it<br>right||Taj_Milahi|good luck bro on the test||user|tweet||---|---||Daniiej|omg i\\'ve an economics test.||sensuoushel<br>p|FOX and the contestants won\\'t go about it<br>right||Taj_Milahi|good luck bro on the test|## **Twitter Dataset Case Study**Complete this analysis and meet back at 9:20 to answer analytical questionsvia the wheel.## **TLAB #3**',\n",
       " 'Types of Visualizations Review.pdf': '# **Types of Visualizations** **Review**|“The existence of Comet NEOWISE (here depicted as a series|Col2||---|---||_of red dots) was discovered by analyzing astronomical survey_|_of red dots) was discovered by analyzing astronomical survey_||_data…”_||### **Agenda - Goals****●****Understand which visualizations to choose for your analysis****●****Learn how to make data visualizations in Python****●****Understand the fundamentals of matplotlib**## **Warm-Up**## **Review of Variables**### **Visualizing Data**### **Independent vs Dependent Variable**### **Quantitative vs Categorical Variables**Now that we’re equipped with these terms, which **variable is quantitative**and which **variable is categorical** ?Now that we’re equipped with these terms, which **variable is quantitative**and which **variable is categorical** ?Again, let’s continue to define these terms. Is our dependent variable**continuous** or **discrete** ?## **Visualizing Data****Univariate** **Bivariate** **Multivariate**### **Visualizing Data - Describing vs Prescribing**### **Visualizing Data - Descriptive Analytics**In descriptive analytics, we are:_**●**__**Exploring what occurred in the past**__**●**__**Identifying anomalies**__**●**__**Identifying relationships and patterns**_**Ex** :_Current users using our platform,__last-years sales, historical placement rates,__current flying conditions (wind, temp, etc)_### **Visualizing Data - Bar Graph**### **Visualizing Data - Histogram**### **Visualizing Data - Box Plot**### **Visualizing Data - More Visualizations**## **Creating Visualizations in** **Python**### **Matplotlib - General Form****import matplotlib.pyplot as plt****fig, ax = plt.subplots()****ax.plot([1,2,3,4,3,5,2,4])****ax.set_title(“Test Plot”)****ax.set_xlabel(“x-axis”)****ax.set_ylabel(“y-axis”)****fig.savefig(“test.png”)**Since matplotlib is not a built in package, you must first download it via pipand then import it to all subsequent code**ax.pie() # create pie chart****ax.bar() # create bar chart****ax.scatter() # create scatter plot****ax.set_ylim() # set y-axis range****fig.savefig() # save image****fig.show() # show image****fig.clear() # clear image**With this review of methods, let’s break down what these **axes** methods do.As well as what our **figure** method does. This creates a new image!Notice these are _almost_ the same as the implicit methods, except this timewe only use the **plt** package name to call of our methods.We can use the **bar()** plot to make bar graphs (2 lists, just like with ourline-plot)Often times when you do data analysis, you need to increase the number ofbins to capture capture the distribution of your dataset.Notice that by increasing the number of bins, the more “detail” we can see.At some point however, we get “diminishing” returns in understandability,**so don’t go too far here.****More polygons → More resolution**## **Common Matplotlib Problem**### **Common Matplotlib Problems**## **Wrap-Up**## **Glossary****population** - entire group you could possibly get data from**sample** - a subset of your population which you collect data from**feature** - an important component of your data**independent variable** - something that does not change when other features in your data change**dependent variable** - a value which changes when other features in your data change**discrete variable** - a variable which is measured in whole numbers (think integers)**continuous variable** - a variable which is measured with all real numbers, including decimals**categorical variable** - something that is describes things (e.g. color, type, class, etc;)**quantitative variable** - something that measures things (e.g. age, height, weight, etc;)**latent variable -** a variable that is not directly observable, but can be inferred from other variables that can bedirectly measured'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_dict = {key: value.replace(\"\\n\", \"\").replace(\"\\r\", \"\") for key, value in slides.items()}\n",
    "cleaned_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d5cf180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# **Introduction to** **K-Nearest-Neighbors**#### **Agenda - Goals**##### **●**## **Warm Up**## **k-Nearest Neighbors**#### **k-Nearest Neighbors (kNN)**#### **k-Nearest Neighbors (kNN)**##### You recognize some cybersecurity fellows, as well as data science fellows. **You notice that everyone is congregating and chatting in groups.**##### But then, you notice someone that you do not recognize. Considering however that all cyber-security fellows are sticking together, which **fellowship does this person most likely belong to?**##### Most likely a cyber-security fellow, no?##### What if we have someone that’s on the periphery of both groups ? We’ll solve this during our discussion of the kNN algorithm.#### **k-Nearest Neighbors (kNN)**We formalize this idea via the following formula for conditional probability. Once again let’s break thisdown before moving to an example.The likelihood the **class of this sample is “j”,** given **the point x** **0** is equal to*Note, we identify the set of “K” nearest points as N 0 . There’snothing special about this name (for now), we could have named it“Roofus” if we wanted to.The likelihood the **class of this sample is “j”,** given **the point x** **0** is equal toThe likelihood the **class of this sample is “j”,** given **the point x** **0** is equal toThe likelihood the **class of this sample is “j”,** given **the point x** **0** is equal toYou may be thinking “ _Darn that’s a whole lot of symbols to say something so simple_ .”However, when it comes to creating ideas in maths, we **cannot be ambiguous** . Therefore weformalize these ideas in a **common set of symbols that all humans agree on** . It’s a beautifulthing really.Succinctly put, we estimate the **conditional probability that x0 belongs to class j as the fraction of the K****nearest points** **whose response values equal j** .Let’s bring back our kibble/loud dataset that identifies **cats, hamsters, and dogs** . I reduced thedata-points to make this graph easier to discuss. You may notice the axes now have equal range, this willI introduce a mystery animal. Let’s assume they are located on coordinate (40, 30). Let’s estimate theprobability that this animal is a cat, dog, or hamster using our **estimated conditional probability.**#### **Small Aside - Euclidean Distance (L2)**#### **Small Aside - Euclidean Distance (L2)**#### **Small Aside - Euclidean Distance (L2)**#### **Small Aside - Euclidean Distance (L2)**#### **Small Aside - Euclidean Distance (L2)**#### **Small Aside - Euclidean Distance (L2)**#### **Small Aside - Euclidean Distance (L2)**#### **Small Aside - Manhattan Distance (L1)**Now, picture we can only travel in straight lines andturn in right angles (as if we were on the streets of**manhattan** ).This entails simply adding the sides of our righttriangle!Can anyone calculate this?#### **Small Aside - Manhattan Distance (L1)**Now, picture we can only travel in straight lines andturn in right angles (as if we were on the streets of**manhattan** ).This entails simply adding the sides of our righttriangle!Can anyone calculate this?And perhaps propose a formula for us to use?#### **Small Aside - Manhattan Distance (L1)**##### ⅔ ⅓We’re going to pause our discussion ofkNN here.However there is more to evaluate whendiscussing this **simple, yet powerful****algorithm.**What are some questions you mighthave regarding kNN?We’re going to pause our discussion ofkNN here.However there is more to evaluate whendiscussing this **simple, yet powerful****algorithm.**What are some questions you mighthave regarding kNN?**●****Why are my axes normalized?****●** **When do we use euclidean vs****manhattan?****●****What happens if we have****categorical data?****●****What happens as I increase my****dimensions?****●** **What are some cons to kNN?**##### Going back to our TKH industry event discussion, we simply select some “K” that accurately classifies this person as a data or cyber fellow.##### **k=3**##### **Class = Cyber**##### **k=5**##### **Class = Cyber**##### Class = Cyber ( are we suffering from imbalance??? )## **Choosing a K - HyperParam**##### Let’s bring back our scatter plot (with a twist!) To obtain the decision boundary for kNN, we could compute the class using kNN for eachRed = cat; yellow = hammie; blue = dog##### We begin with k=1. What do you notice about the error rate? Does it make any mistakes?Red = cat; yellow = hammie; blue = dog##### None whatsoever! While our “training” rate might seem ideal, let’s see what happens when we introduce a new test sample. Who is our hamster friend **classified as?**##### A cat . Remember everyone, a classifier that perfectly fits our training dataRed = cat; yellow = hammie; blue = dog##### We move onto k=3. What happens to our training error rate now?Red = cat; yellow = hammie; blue = dog##### Unfortunately a few training samples are classified incorrectly, but this could actually be preferable when it comes to our testing data !##### Bringing back our hamster, we see that it is now correctly classified as a hamster (ignore the roughness of my sketches)Red = cat; yellow = hammie; blue = dog##### Finally lets try k=6. What happens to our training error rate now?#### **kNN - Importance of Data Scaling**##### _X1: (-2 to 2)_ _X2: (-2 to 2)_ Now that we’ve standardized our dataset, we can assign equal **importance to dimensions.** Subsequently, we update our predictions.#### **kNN**###### To conclude our conversation on the supervised learning classifier kNN, it is a **powerful non-parametric supervised learning algorithm that utilizes a** . **fairly “lazy” classification method** Pros ● No optimization involved ● Comparable performance to Naive Bayes **●** **Easy to understand** Cons ● Sensitive to class imbalance ● Need to store entire training dataset for prediction                       Good visual of kNN from https://knn [notebook.netlify.app/](https://knn-notebook.netlify.app/)##### Let’s review the following gif to see the process that kNN takes to classify a new test observation.## **Classification Challenges**#### **Classification Challenges**#### **Choosing a Distance Metric**#### **Choosing a Distance Metric**What do you notice about the **sparsity** of our data as we increase dimensions?Notice how the frequency of distances converges on a specific value as we increase dimensions:[https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote02_kNN.html](https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote02_kNN.html)#### **The Curse of Dimensionality**##### Lower dimensional manifold in a nutshell: “ Wow this looks really complex… ”#### **Handling Data Imbalance**_True Positives + True Negatives__False Negatives_##### This leads to what we call the **accuracy** paradox (null accuracy). Let’s say you go to another industry event and you see 9 cyber fellows and 1 data fellow. You train a kNN algorithm and it gives you a 90% accuracy rate. Wow! This must be a **good model, no?**_True Positives + True Negatives__False Negatives__9 + 0_**90%**_9 + 0_**90%**#### **Over-Sampling Vs Under-Sampling**#### **Over-Sampling Vs Under-Sampling**#### **SMOTE**_Synthetic Minority Over-sampling Technique_This technique entails creating new _synthetic minority classes_ via a somewhat randomized process.1. Choose a random set of the minority class2. Find k-nearest-neighbors for each sample of the same class3. Calculate a new synthetic class between this sample and all of its neighborsa. Choose a random value between 0 & 1 to calculate where this newly random point willexist in the space between your data point and its neighbors##### This allows us to “purposefully” oversample our dataset to improve the predictive qualities of our dataset.#### **Handling Data Imbalance**##### This is especially useful when trying to detect some real relatively rare class in your dataset: ● Actual fraud **● A rare disease** ● **A 16-seeded team beating a 1-seeded team**## **End of Class Announcements**##### ○ Where does variance/bias exist in kNN?|Neural network training|makes||---|---||**_beautiful fractals_**||',\n",
       " '# **Natural Language** **Processing & Vector** **Embeddings**### **Agenda - Goals****●** **…**## **Kahoot**Let’s begin todays Kahoot## **Pre-Class Review**### **Pre-Class Review**## **Natural Language Processing**### **Natural Language Processing**### **Natural Language Processing Techniques**As it turns out, computer scientists have been attempting to solve this problemfor a quite a long time. Let’s review the foundational techniques of analyzing a“corpus” of text._**●**__**Bag of Words**_ (Harris 1954)_**●**_ _**TF-IDF**_ (Jones 1972)These techniques are dated by this point, **but it doesn’t mean these techniques****are useless.** Let’s see what their purpose is in the world of document analysis.### **Bag of Words**Let’s take three example text files and see how the BOW technique analyzes them.We will use **3 example reviews from Amazon and their subsequent reviews (out****of 5 stars)** .What’s the first step to the BOW technique?**(1)****(2)**### **Term Frequency-Inverse Document Frequency** **(TF-IDF)**While BOW is a trivial technique to interpret text, we can iterate upon thisimplementation via the **Term Frequency-Inverse Document Frequency** algorithm.The steps to this include:_**1.**_ _**BOW steps up to step 2**__**2.**_ _**Calculate the total number of times word t appears in document d, divided by all the**__**terms in document d (term frequency)**__**3.**_ _**Calculate the total number of documents divided by the number of documents**__**containing term t (inverse document frequency)**__**4.**_ _**Multiply these two values together to calculate the tf-idf.**_## **Vector Embeddings**### **Word Embeddings - Data Representations**### **Word Embeddings - Word2Vec**By observing wheres these data-samples exist in the **semantic feature**Lastly, to demonstrate the power of word2vec transformations, let’s say wehave the additional data-samples “ **evening** ” and “ **dinner** .”Try adding the vectors “lunch” + “evening” [1, 4] + [3, -3].Which value do we get?### **Word Embeddings - Word2Vec**### **Word Embeddings - Word2Vec**### **Word Embeddings - Word2Vec (SkipGram)**Let’s observe the steps to train a **skip-gram word2vec**_**1.**_ _**Tokenize your text into words (or n-grams)**__**2.**_ _**Eliminate stop-words and punctuation**_**3.** **Choose a window size of “n”****4.** **Loop through each window of your corpus****a.****Train your single hidden layer neural network on each (n) context****words & target word**_**The dog eats the bone**__**The cat eats fish.**__**The cat scratches its owner.**_## **Embedding Everything**### **Transformer Embeddings**## **End of Class Announcements**',\n",
       " '# **Probability Review**#### **Agenda - Schedule**#### **Agenda - Announcements**#### **Agenda - Goals****●****Review basic probability****●****Understand how sample calculations differ from population****●****Understand & apply Bayes Theorem**## **Inferring from a Sample**We often use humans when discussing population vs sample, but thisapplies **to any dataset** . Ex: All AAPL stock prices since Dec 14, 1984( **population** ) & AAPL stock price on Dec 12, 2024 ( **sample** ).Our equations for measures of dispersion change based on which subset weare calculating our metrics on. This is **because a sample is an estimate**, and a.**population is ground truth**## **Probability Review**|Event|Probability||---|---||**Dog**|0.5||**Cat**|0.3||**Hamster**|0.1||**Lizard**|0.0||**No pet**|0.1|Let’s increase our sample space in order to discuss more complex terms.Here we describe the probabilities that an american household has somespecific pet.**Dog** **Cat** **Hamster** **Lizard** **None**Graphing these values gives us the **probability distribution** .|Event|Probability||---|---||**Dog**|0.5||**Cat**|0.3||**Hamster**|0.1||**Lizard**|0.0||**No pet**|0.1|## **Probability in Data Analysis -** **Bayes Theorem**#### **Probability in Data Analysis**#### **Bayes Theorem - Frequentist World-View**#### **Bayes Theorem - Frequentist Pros**#### **Bayes Theorem - Frequentist Cons**#### **Bayes Theorem - Frequentist Cons**#### **Bayes Theorem - Bayesian Statistics**_statistician_## **P(H) P(E|H)**Here’s the formula, let’s **break down its components** before going throughour covid example.Remember, the “|” is the symbolfor conditional probabilitystatements.“Hypothesis given Event”## **P(H) P(E|H)**The probability the **hypothesis** is true given the **event** is equal toThe probability the **hypothesis** is true given the **event** is equal toThe probability the **hypothesis** is true given the **event** is equal to## **P(H) P(E|H)**Divided by the probability of **event** occurring. This part is sometimesdeceptively simple. Keep in mind that we want to consider the **event occurs****given the hypothesis is true and given the hypothesis is false** !Let’s understand how to calculate this. I find diagrams to be the most helpfulin visualizing this calculationTo calculate P(E), we have to consider the intersection of P(E) and P(H), aswell as the space where P(E) exists outside of P(H)This intersect can be labeled **P(E & H)**In terms of conditional probability, that is **P(H)P(E|H)**And lastly we have **P(E & -H).** Can anyone express this in terms ofconditional probability as well?**P(-H)P(E|-H). This allows us to express P(E) as P(H)P(E|H) + P(-H)P(E|-H)**## **P(H) P(E|H)****P(H|E) = 0.089****P(H|E) = 0.47**## **Wrap-Up**',\n",
       " '# **Random Forests &** **Boosted Forests**### **Agenda - Schedule**### **Agenda - Goals****●**## **Bagging**|team1_3point|team2_turnover|team1_won||---|---|---||35|15|1||28.5|12|0||40|18|1||25.0|20.0|0|1 0 1 0And this is only for our4-sample dataset. Whatif we have 100, 1000 or1,000,000 samples?|team1_3point|team2_turnover|team1_won||---|---|---||35|15|1||28.5|12|0||40|18|1||25.0|20.0|0|Going back to the formulation of our decision trees, our trees will **overfit to****this noisy data and fail to generalize on new test samples.**Is this considered high bias or high variance?1 0 1 0|team1_3point|team2_turnover|team1_won||---|---|---||35|15|1||28.5|12|0||40|18|1||25.0|20.0|0|Therefore, we need a method to cut through all this noise and somehow**extract the true signal from this dataset** . The first technique we will learn is.**bagging**### **Bagging - Bootstrapping**### **Bagging - Bootstrapping**### **Bagging - Bootstrapping + Aggregating**Let’s apply this technique to our decision trees inorder to implement what we call “ **bagged trees.** ”The algorithm for **bagging (bootstrapping +****aggregating)** is applied through the following steps:1. Select _n_ random subsets of datasets withreplacement ( **bootstrap** )2. Grow arbitrarily large trees on each subset3. “ _Democratically_ ” select the prediction whichhas the most votes across all trees( **aggregate** ).|team1_3point|team2_turnover|team1_won||---|---|---||35|15|1||28.5|12|0||40|18|1||25.0|20.0|0||37.5|14.0|1||30.0|16.0|0||42.0|19.5|1||33.5|21.0|0|Let’s bring back our basketball dataset to see how we can apply **bagging** andstrengthen the true signal of our dataset. We include a few more data pointsto make this a little more interesting.|28.5|12|0||---|---|---||37.5|14.0|1||30.0|16.0|0||Col1|35|15|1||---|---|---|---|||42.0|19.5|1|||28.5|12|0||40|18|1||---|---|---||33.5|21.0|0||25.0|20.0|0||team1_3point|team2_turnover|team1_won||---|---|---||35|15|1||28.5|12|0||40|18|1||25.0|20.0|0||37.5|14.0|1||30.0|16.0|0||42.0|19.5|1||33.5|21.0|0||Col1|28.5|12|0||---|---|---|---|||42.0|19.5|1|||28.5|12|0|First, we will make 4 random subsets of data (with replacement). This is the**bootstrap** step.**Note** : keep in mind thatthis example is toosimple to make anymeaningful tree|28.5|12|0||---|---|---||37.5|14.0|1||30.0|16.0|0|1 0|35|15|1||---|---|---||42.0|19.5|1||28.5|12|0||40|18|1||---|---|---||33.5|21.0|0||25.0|20.0|0||28.5|12|0||---|---|---||42.0|19.5|1||28.5|12|0|1 0|team1_3point|team2_turnover|team1_won_pred||---|---|---||35|15|???||28.5|12|???||40|18|???||25.0|20.0|???||37.5|14.0|???||30.0|16.0|???||42.0|19.5|???||33.5|21.0|???|1 0|team1_3point|team2_turnover|team1_won_pred||---|---|---||35|15|???||28.5|12|???||40|18|???||25.0|20.0|???||37.5|14.0|???||30.0|16.0|???||42.0|19.5|???||33.5|21.0|???|1 010|team1_3point|team2_turnover|team1_won_pred||---|---|---||35|15|???||28.5|12|???||40|18|???||25.0|20.0|???||37.5|14.0|???||30.0|16.0|???||42.0|19.5|???||33.5|21.0|???|One question that youmight be thinking is“wait so now we’veintroduced a parameter’to indicate how manytrees we will train, isthis anotherhyperparameter thatwe must find viaGridSearch?”1 0101 0|team1_3point|team2_turnover|team1_won_pred||---|---|---||35|15|**1**||28.5|12|???||40|18|???||25.0|20.0|???||37.5|14.0|???||30.0|16.0|???||42.0|19.5|???||33.5|21.0|???|1 01 0tie|team1_3point|team2_turnover|team1_won_pred|team1_won||---|---|---|---||35|15|**1**|1||28.5|12|**0**|0||40|18|**1**|1||25.0|20.0|**0**|0||37.5|14.0|**1**|1||30.0|16.0|**0**|0||42.0|19.5|**1**|1||33.5|21.0|**0 or 1**|0|Just for fun, let’s fill out the rest of these samples and observe the accuracy. Noticethat we occasionally get **ties.** In this case, we decide randomly which class tochoose which leads us to an accuracy that ranges from **85% to 100%**As it turns out, the number of trees that we train _**“B”**_ does not suffer from overfitting (high variance) as weincrease this amount! Instead, error simply _settles_ after enough trees are generated. **WOW!**Therefore, we simplyuse a **sufficiently large****B** until we do not seelarge gains in testaccuracy.One technique we canuse is to start large(100), and then see howmany trees we can**remove for the same****test accuracy rate.**Impurity Removed = 0.8751 0Impurity Removed = 0.33Impurity Removed = 11 0Impurity Removed = 0.8751 0By adding all the impurity removed, we can observe which predictor is the **most important** . In thisdataset, which feature seems to remove the most impurity?## **Random Forests**### **Random Forests**|team1_3point|team2_turnover|team1_won||---|---|---||35|15|1||28.5|12|0||40|18|1||25.0|20.0|0||37.5|14.0|1||30.0|16.0|0||42.0|19.5|1||33.5|21.0|0|Let’s go back to our basketball example once more, and walk through thesteps of bagging with this additional caveat|28.5|12|0||---|---|---||37.5|14.0|1||30.0|16.0|0||Col1|35|15|1||---|---|---|---|||42.0|19.5|1|||28.5|12|0||40|18|1||---|---|---||33.5|21.0|0||25.0|20.0|0||team1_3point|team2_turnover|team1_won||---|---|---||35|15|1||28.5|12|0||40|18|1||25.0|20.0|0||37.5|14.0|1||30.0|16.0|0||42.0|19.5|1||33.5|21.0|0||Col1|28.5|12|0||---|---|---|---|||42.0|19.5|1|||28.5|12|0|First, we will make 4 random subsets of data (with replacement). This is the**bootstrap** step.|28.5|12|0||---|---|---||37.5|14.0|1||30.0|16.0|0||35|15|1||---|---|---||42.0|19.5|1||28.5|12|0||40|18|1||---|---|---||33.5|21.0|0||25.0|20.0|0||28.5|12|0||---|---|---||42.0|19.5|1||28.5|12|0|1 01 0|team1_3point|team2_turnover|team1_won_pred|team1_won||---|---|---|---||35|15|**1**|1||28.5|12|**0**|0||40|18|**1**|1||25.0|20.0|**0**|0||37.5|14.0|**1**|1||30.0|16.0|**0**|0||42.0|19.5|**1**|1||33.5|21.0|**1**|0|Once again, we allow these trees to democratically elect the prediction based on their **bootstrapped****samples and limited predictors. Notice that we get no ties! We walk away with one accuracy!**This outcome is not unique to our dataset. Notice the **Test:RandomForest** error rate performs noticeably**better than the simple bagged model** .- Computationally **expensive**## **Boosting - AdaBoost****Trees with better information on****which mistakes they should avoid****should also be better classifiers!****Metaphors get tough in this context****but consider the following:****You, a New Yorker/Connecticuter,****are voting for public transportation****policies in your city. Might you have****better context than an extra-state****voter?**|28.5|12|0||---|---|---||37.5|14.0|1||30.0|16.0|0|1 0|35|15|1||---|---|---||42.0|19.5|1||28.5|12|0||40|18|1||---|---|---||33.5|21.0|0||25.0|20.0|0||28.5|12|0||---|---|---||42.0|19.5|1||28.5|12|0|### **Boosting - AdaBoost**|team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|1/8||28.5|12|0|1/8||40|18|1|1/8||25.0|20.0|0|1/8||37.5|14.0|1|1/8||30.0|16.0|0|1/8||42.0|19.5|1|1/8||33.5|21.0|0|1/8|1 0|team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|1/8||28.5|12|0|1/8||40|18|1|1/8||25.0|20.0|0|1/8||37.5|14.0|1|1/8||30.0|16.0|0|1/8||42.0|19.5|1|1/8||33.5|21.0|0|1/8|Just like with random forests, we will grow **stumps** on a subset of predictors(one tree per predictor). However this time we use the **entire dataset.**= 0= 2= 4= 2Gini = 1 ((0/2)^2+(2/2)^2)= 2= 2= 2= 2|team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|1/8||28.5|12|0|1/8||40|18|1|1/8||25.0|20.0|0|1/8||37.5|14.0|1|1/8||30.0|16.0|0|1/8||42.0|19.5|1|1/8||33.5|21.0|0|1/8|= 0= 2= 4= 2Gini = 0.44Gini = 0= 2= 2= 2= 2|team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|1/8||28.5|12|0|1/8||40|18|1|1/8||25.0|20.0|0|1/8||37.5|14.0|1|1/8||30.0|16.0|0|1/8||42.0|19.5|1|1/8||33.5|21.0|0|1/8|= 0= 2= 4= 2Total Gini = 0.44 *(6/8) + 0 * (2/8)= 2= 2= 2= 2|team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|1/8||28.5|12|0|1/8||40|18|1|1/8||25.0|20.0|0|1/8||37.5|14.0|1|1/8||30.0|16.0|0|1/8||42.0|19.5|1|1/8||33.5|21.0|0|1/8|= 0= 2= 4= 2= 2= 2= 2= 2|team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|1/8||28.5|12|0|1/8||40|18|1|1/8||25.0|20.0|0|1/8||37.5|14.0|1|1/8||30.0|16.0|0|1/8||42.0|19.5|1|1/8||33.5|21.0|0|1/8|= 0= 2= 4= 2Total Error = ⅛ + ⅛ = **0.25**0 -> Perfect stump1 -> Bad stump|team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|1/8||28.5|12|0|1/8||40|18|1|1/8||25.0|20.0|0|1/8||37.5|14.0|1|1/8||30.0|16.0|0|1/8||42.0|19.5|1|1/8||33.5|21.0|0|1/8|= 0= 2= 4= 2|team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|1/8||28.5|12|0|1/8||40|18|1|1/8||25.0|20.0|0|1/8||37.5|14.0|1|1/8||30.0|16.0|0|1/8||42.0|19.5|1|1/8||33.5|21.0|0|1/8||team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|1/8||28.5|12|0|1/8||40|18|1|1/8||25.0|20.0|0|1/8||37.5|14.0|1|1/8||30.0|16.0|0|1/8||42.0|19.5|1|1/8||33.5|21.0|0|1/8||team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|1/8||28.5|12|0|1/8||40|18|1|1/8||25.0|20.0|0|1/8||37.5|14.0|1|1/8||30.0|16.0|0|1/8||42.0|19.5|1|1/8||33.5|21.0|0|1/8||team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|0.10||28.5|12|0|0.10||40|18|1|0.10||25.0|20.0|0|0.10||37.5|14.0|1|0.10||30.0|16.0|0|0.16||42.0|19.5|1|0.10||33.5|21.0|0|0.16||team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|0.1086||28.5|12|0|0.1086||40|18|1|0.1086||25.0|20.0|0|0.1086||37.5|14.0|1|0.1086||30.0|16.0|0|0.1739||42.0|19.5|1|0.1086||33.5|21.0|0|0.1739||team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||35|15|1|0.1086||28.5|12|0|0.1086||40|18|1|0.1086||25.0|20.0|0|0.1086||37.5|14.0|1|0.1086||30.0|16.0|0|0.1739||42.0|19.5|1|0.1086||33.5|21.0|0|0.1739||team1_3point|team2_turnover||---|---||35|15||28.5|12||40|18||25.0|20.0||37.5|14.0||30.0|16.0||42.0|19.5||33.5|21.0||team1_3point|team2_turnover||---|---||33.5|21.0||28.5|12||30.0|16.0||33.5|21.0||28.5|12||40|18||30.0|16.0||25.0|20.0||team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||33.5|21.0|0|1/8||28.5|12|0|1/8||30.0|16.0|0|1/8||33.5|21.0|0|1/8||28.5|12|0|1/8||40|18|1|1/8||30.0|16.0|0|1/8||25.0|20.0|0|1/8||team1_3point|team2_turnover|team1_won|sample weight||---|---|---|---||33.5|21.0|0|1/8||28.5|12|0|1/8||30.0|16.0|0|1/8||33.5|21.0|0|1/8||28.5|12|0|1/8||40|18|1|1/8||30.0|16.0|0|1/8||25.0|20.0|0|1/8|**team1_3point** **team2_turnover** **0.24**This is a limited example.You should instead expectto have 10,20, or 30 treeson a dataset **of thousands****if not millions of rows.**|team1_3point|team2_turnover||---|---||21|18||36|17||39|15|## **Boosting - Gradient Boosting**### **Gradient Boosting**## **End of Class Announcements**',\n",
       " '# **Shopping Dataset Case** **Study**### **Agenda - Goals** Apply basic and intermediate pandas methods to **explore a structured dataset** - Perform **univariate and bivariate analysis** on real-world shopping data Create visualizations using seaborn to support your findings Use grouping and aggregation techniques such as groupby(), pivot_table(), qcut(), andagg() Develop and **communicate insights clearly based on observed data patterns**, not justthe code used## **Shopping Dataset Case Study**You are a Data Analyst for *FlastFash*, a Budapest-based online clothingstore that\\'s looking to break into the American market.### **Shopping Dataset Case Study**Prepare a report for your manager by answering the listed reflectionquestions!## **Visualizing Data - Seaborn**### **Visualizing Data - Bar Graph**Notice that thesex-axis labels aren’teasy to read…#### **df.value_counts(“Color”).plot.bar()**We can quickly plot the frequencies of categories by specifying a**categorical column** in the **value_counts** method, and then by calling the**plot.bar** () method.#### **df.value_counts(“Color”).plot.barh()**### **Visualizing Data - Histogram**What can we do tobetter observe ourdistributions?#### **df[“Purchase Amount (USD)”].plot.hist()**By specifying a **numerical column** and then calling the **plot.hist()** method,we can plot a histogram on a numeric series to observe the distribution ofour dataset.#### **df[“Purchase Amount (USD)”].plot.hist(bins=30)**By **increasing the number of bins**, we can better observe the distributionsthat are apparent in our dataset. What kind of distribution do we see here?#### **sns.scatterplot(df, x=\"Age\", y=\"Purchase Amount (USD)\")**By specifying a **dataframe, and two numerical columns** in the **scatterplot**method, we can plot a scatter-plot to observe the relationship between twonumeric variables. **Do you notice any correlation between age and****purchase amount?**#### **corr** **df[[\"Age\", \"Purchase Amount (USD)\"]]. ()**As we see from the correlation matrix, there is no correlation between ageand purchase amount. However can you identify **clusters** of data whichmight be emerging between these two variables?### **Visualizing Data - Box Plot**#### **sns.boxplot(df, x=\"Review Rating\", y=\"Purchase Amount (USD)\")**By specifying a **dataframe, one categorical, and one numerical column** inthe **boxplot** method, we can plot a box-plot to observe how a distributionvaries across categories. **Do you notice any sizeable differences in median?**## **Shopping Dataset Case Study**Complete this analysis and meet back at 9:20 to answer analytical questionsvia the wheel.## **TLAB #3****Doing your Own EDA**',\n",
       " '# **SQL Review II**### **Agenda - Announcements**### **Agenda - Goals****●****Simulate the interview process by asking you to complete and present****technical challenges live.****●****Continue working on TLAB #3**## **LeetCode Q1**## **LeetCode Q2**## **LeetCode Q3**## **LeetCode Q4**## **TLAB #3**',\n",
       " '# **SQL Review**### **Agenda - Announcements**### **Agenda - Goals****●****Simulate the interview process by asking you to complete and present****technical challenges live.****●****Continue working on TLAB #3**## **LeetCode Q1**## **LeetCode Q2**## **LeetCode Q3**## **LeetCode Q4**## **TLAB #3**',\n",
       " \"# **A Quick Run-Through of** **Transformer** **Architecture**### **Agenda - Goals**#### **●** **Understand how LLMs work at a high level** **●** **Big idea behind Attention** **●** **Why Attention sparked the modern AI Boom**## **Text Prediction via Neural** **Networks**In more niche circles, we could even apply the transformer architecture to EEG wavesto text (aka mind-reading).## **LLMs and Attention**### **LLMs**For now we want you to think of LLMs as an advancedversion of autocomplete, given a prompt.Rather than providing options of words to complete a phrase,an LLMs output contains a probability distribution of thenext likely word.Instead of always selecting the most probable word however,we can adjust a parameter called **temperature**, such that wesee a bit of randomness in the next outputted word.The recognition of these traits were **learned independently by the neural network itself.**Similarly as the word embedded vectors pass through the transformer architecture, eachhead of attention learns different patterns within the body of text#### Innovations in hardware allow us to run these neural networks. Attention models can process all words at once. Without parallel hardware, LLMs would not work!Almost all of the technology behind this third AI boom has come from the transformerarchitecture! Although originally invented for text, (machine translation) it can be used onimage data, audio data, biological data (protein folding) and much more!In short, transformers aren't just good at reading, they're good at any problem where themodel needs to look at a lot of data and decide what's important.\",\n",
       " '# **Twitter Dataset Case** **Study**#### **Agenda - Goals** Perform time series exploration using pandas Extract key date-time features like hour and weekday Analyze and visualize patterns in tweet volume and sentiment Use string matching techniques to filter tweets by content Focus on developing insightful conclusions, not just writing code## **Twitter Dataset Case Study**You are a Data Scientist for *SuperEgo* an NYC-based research institutelooking to create a language model that closely emulates a twitter-user.#### **Twitter Dataset Case Study**Like yesterday, we will use the first-half of class to work on this case studytogether.After break, we will ask you to complete this case study in your groups.We will congregate back at 9:20 to discuss results (with the wheels help).## **Pandas Time Series Data**#### **Pandas Review - Time Bound Data****NOTE:** If it takes more than 2minutes to make your plot (and itcomes out looking like nonsense),you’ve made the **wrong plot.****Don’t make plots just to make plots.**##### **sns.lineplot(df, x=\"date\", y=\"sentiment\")****df[“Date”] = pd.to_datetime(df[“Date”])**Before we do ANYTHING! We must ensurethat our date column is being treated as a“datetime” column.We can do this by calling the “ **to_datetime** ()”method on our date column, and reassigning itback into our original column. Remember, if wedon’t save our changes, we lose them!|ID|Date|Amount||---|---|---||1|Mon Apr 17 20:30 2023|5.24||2|Mon Apr 17 20:31 2023|10.98||3|Mon Apr 17 20:35 2023|1.58||4|Mon Apr 17 23:35 2023|50.60||5|Tues Apr 18 04:20<br>2023|34.01||6|Tues Apr 18 07:50<br>2023|25.05||7|Thurs Apr 20 12:50<br>2023|5.63|For demonstration purposes, let’s look at a dataset of **transactions** in an online shoppingplatform.This dataset is not in our case study, but it will help us understand the resample method.**df.resample(“1D”, on=”Date”)**|ID|Date|Amount||---|---|---||1|Mon Apr 17 20:30 2023|5.24||2|Mon Apr 17 20:31 2023|10.98||3|Mon Apr 17 20:35 2023|1.58||4|Mon Apr 17 23:35 2023|50.60||5|Tues Apr 18 04:20<br>2023|34.01||6|Tues Apr 18 07:50<br>2023|25.05||7|Thurs Apr 20 12:50<br>2023|5.63|**df.resample(“1D”, on=”Date”)**|ID|Date|Amount||---|---|---||1|Mon Apr 17 20:30 2023|5.24||2|Mon Apr 17 20:31 2023|10.98||3|Mon Apr 17 20:35 2023|1.58||4|Mon Apr 17 23:35 2023|50.60||5|Tues Apr 18 04:20<br>2023|34.01||6|Tues Apr 18 07:50<br>2023|25.05||7|Thurs Apr 20 12:50<br>2023|5.63|**df.resample(“1D”, on=”Date”)[“Amount”].mean()**Note that we also getNaN values. These aredays that **don’t have****data**|ID|Date|Amount||---|---|---||1|Mon Apr 17 20:30 2023|5.24||2|Mon Apr 17 20:31 2023|10.98||3|Mon Apr 17 20:35 2023|1.58||4|Mon Apr 17 23:35 2023|50.60||5|Tues Apr 18 04:20<br>2023|34.01||6|Tues Apr 18 07:50<br>2023|25.05||7|Thurs Apr 20 12:50<br>2023|5.63|Just like with **groupby**, we can add a method to calculate some **summary****statistic** . This will select all rows that fall on **the same day…****df.resample(“1D”, on=”Date”)[“Amount”].mean()**Note that we also getNaN values. These aredays that **don’t have****data**|Date|Amount||---|---||Mon Apr 17 2023|17.1||Tues Apr 18 2023|29.53||Wednesday Apr 19 2023|NaN||Thurs Apr 20 2023|5.63|##### **df[\"date\"] = pd.to_datetime(df[\"date\"])** **df.resample(on=\"date\", rule=\"1D\")[\"sentiment\"].mean()**Let’s apply these same principles to our Twitter dataset to better visualizeour former line plot. First we will convert our “date” column to a date-timetype.##### **df[\"date\"] = pd.to_datetime(df[\"date\"])** **df.resample(on=\"date\", rule=\"1D\")[\"sentiment\"].mean()**Now we can resample our dataframe to calculate the average sentimentspers day. **While this is a good start**, how can we plot these values using aline plot?##### **df[\"date\"] = pd.to_datetime(df[\"date\"])** **df.resample(on=\"date\", rule=\"1D\")[\"sentiment\"].mean().plot.line()**###### **df.resample(on=\"date\", rule=\"1D\")[\"sentiment\"].mean().interpolate().plot.line()**## **Regex**As this is a Twitter dataset, we should probably utilize some sort oftext-based analysis. What have we learned about in the past which will helpus figure out what people are talking about?#### **Regular Expressions (Regex)****review**_Farukh is great__Where is Farukh?__Farrrrukh is terrible__I like Python27__@@@19586_|Regex Pattern|Col2||---|---||||_Farukh_**review**_Farukh is great__Where is Farukh?__Farrrrukh is terrible__I like Python27__@@@19586_For example, by just using the regex string “Farukh”, we will look for all rowsthat contain the string “Farukh.” Which rows will be matched?|Regex Pattern|Col2||---|---||||_Farukh_|Regex Pattern|Col2||---|---||||Remember, acomputer does notunderstand intent. Itwill only do exactlywhat you want it to do|Regex Pattern|Col2||---|---||||_Farukh_**review**_Farukh is great__Where is Farukh?__Farrrrukh is terrible__I like Python27__@@@19586_|Regex Pattern<br>^Far*ukh|review||---|---||Regex Pattern<br>_^Far*ukh_|_Farukh is great_||Regex Pattern<br>_^Far*ukh_|_Where is Farukh?_||Regex Pattern<br>_^Far*ukh_|_Farrrrukh is terrible_||Regex Pattern<br>_^Far*ukh_|_I like Python27_||Regex Pattern<br>_^Far*ukh_|_@@@19586_|By placing a caret at the front, we only find reviews that that begin with theword “Farukh” with an arbitrary number of r’s/|Regex Pattern|Col2||---|---|||||Regex Pattern|Col2||---|---||||Knowing regex will save you **hours of work** .#### **Regular Expressions (Regex)**Find all participants wholive in states startingwith “New”|age|age_spouse|State|income||---|---|---|---||32|35|New York|30,000||48|47|New Mexico|70,000||21|NA|California|20,0000|Find all participants wholive in states startingwith “New”|age|age_spouse|State|income||---|---|---|---||32|35|New York|30,000||48|47|New Mexico|70,000||21|NA|California|20,0000|Find all participants wholive in states startingwith “New”### **df[df.State.str.contains(“^New”)]**|age|age_spouse|State|income||---|---|---|---||32|35|New York|30,000||48|47|New Mexico|70,000||21|NA|California|20,0000||user|tweet||---|---||Daniiej|omg i\\'ve an economics test.||sensuoushel<br>p|FOX and the contestants won\\'t go about it<br>right||Taj_Milahi|good luck bro on the test||user|tweet||---|---||Daniiej|omg i\\'ve an economics test.||sensuoushel<br>p|FOX and the contestants won\\'t go about it<br>right||Taj_Milahi|good luck bro on the test||user|tweet||---|---||Daniiej|omg i\\'ve an economics test.||sensuoushel<br>p|FOX and the contestants won\\'t go about it<br>right||Taj_Milahi|good luck bro on the test|## **Twitter Dataset Case Study**Complete this analysis and meet back at 9:20 to answer analytical questionsvia the wheel.## **TLAB #3**',\n",
       " '# **Types of Visualizations** **Review**|“The existence of Comet NEOWISE (here depicted as a series|Col2||---|---||_of red dots) was discovered by analyzing astronomical survey_|_of red dots) was discovered by analyzing astronomical survey_||_data…”_||### **Agenda - Goals****●****Understand which visualizations to choose for your analysis****●****Learn how to make data visualizations in Python****●****Understand the fundamentals of matplotlib**## **Warm-Up**## **Review of Variables**### **Visualizing Data**### **Independent vs Dependent Variable**### **Quantitative vs Categorical Variables**Now that we’re equipped with these terms, which **variable is quantitative**and which **variable is categorical** ?Now that we’re equipped with these terms, which **variable is quantitative**and which **variable is categorical** ?Again, let’s continue to define these terms. Is our dependent variable**continuous** or **discrete** ?## **Visualizing Data****Univariate** **Bivariate** **Multivariate**### **Visualizing Data - Describing vs Prescribing**### **Visualizing Data - Descriptive Analytics**In descriptive analytics, we are:_**●**__**Exploring what occurred in the past**__**●**__**Identifying anomalies**__**●**__**Identifying relationships and patterns**_**Ex** :_Current users using our platform,__last-years sales, historical placement rates,__current flying conditions (wind, temp, etc)_### **Visualizing Data - Bar Graph**### **Visualizing Data - Histogram**### **Visualizing Data - Box Plot**### **Visualizing Data - More Visualizations**## **Creating Visualizations in** **Python**### **Matplotlib - General Form****import matplotlib.pyplot as plt****fig, ax = plt.subplots()****ax.plot([1,2,3,4,3,5,2,4])****ax.set_title(“Test Plot”)****ax.set_xlabel(“x-axis”)****ax.set_ylabel(“y-axis”)****fig.savefig(“test.png”)**Since matplotlib is not a built in package, you must first download it via pipand then import it to all subsequent code**ax.pie() # create pie chart****ax.bar() # create bar chart****ax.scatter() # create scatter plot****ax.set_ylim() # set y-axis range****fig.savefig() # save image****fig.show() # show image****fig.clear() # clear image**With this review of methods, let’s break down what these **axes** methods do.As well as what our **figure** method does. This creates a new image!Notice these are _almost_ the same as the implicit methods, except this timewe only use the **plt** package name to call of our methods.We can use the **bar()** plot to make bar graphs (2 lists, just like with ourline-plot)Often times when you do data analysis, you need to increase the number ofbins to capture capture the distribution of your dataset.Notice that by increasing the number of bins, the more “detail” we can see.At some point however, we get “diminishing” returns in understandability,**so don’t go too far here.****More polygons → More resolution**## **Common Matplotlib Problem**### **Common Matplotlib Problems**## **Wrap-Up**## **Glossary****population** - entire group you could possibly get data from**sample** - a subset of your population which you collect data from**feature** - an important component of your data**independent variable** - something that does not change when other features in your data change**dependent variable** - a value which changes when other features in your data change**discrete variable** - a variable which is measured in whole numbers (think integers)**continuous variable** - a variable which is measured with all real numbers, including decimals**categorical variable** - something that is describes things (e.g. color, type, class, etc;)**quantitative variable** - something that measures things (e.g. age, height, weight, etc;)**latent variable -** a variable that is not directly observable, but can be inferred from other variables that can bedirectly measured']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v=list(cleaned_dict.values())\n",
    "v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f410b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 768)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "embeddings = embedder.encode(v, normalize_embeddings=True) \n",
    "\n",
    "embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b7aa5720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.01199111e-02,  5.79908155e-02,  5.79888709e-02,  1.21406307e-02,\n",
       "       -1.52504947e-02, -7.15315789e-02, -6.39610272e-03,  6.43311674e-03,\n",
       "       -2.06810255e-02, -3.04760803e-02, -5.48784398e-02,  3.08148079e-02,\n",
       "        1.46815153e-02,  1.76919736e-02, -6.36905134e-02,  5.42941839e-02,\n",
       "       -3.74312252e-02, -4.14067274e-03, -3.16684917e-02,  9.28819086e-03,\n",
       "       -3.86417564e-03, -3.47059965e-02, -3.86697091e-02,  2.26820428e-02,\n",
       "        5.29700667e-02,  7.79013708e-02, -7.52211642e-03, -3.25701642e-03,\n",
       "       -2.43004430e-02,  4.95911762e-02, -1.28615811e-03, -4.83563123e-03,\n",
       "        3.47193703e-02, -4.53156903e-02, -1.59777771e-03, -1.30981673e-02,\n",
       "        4.53111753e-02,  8.45846981e-02,  4.79580872e-02,  6.32581264e-02,\n",
       "        2.03281287e-02, -3.87657210e-02,  4.67089489e-02,  2.05880729e-03,\n",
       "       -7.98193887e-02, -4.50933762e-02,  2.99833156e-03,  6.45070150e-02,\n",
       "        4.38071452e-02, -3.75853628e-02,  2.88260467e-02,  3.31792468e-03,\n",
       "        7.14617372e-02, -3.32412310e-03, -3.00017726e-02, -3.18897888e-02,\n",
       "        2.22511180e-02, -9.44394246e-02, -3.76481898e-02,  4.09649638e-03,\n",
       "       -7.15108737e-02,  7.24138785e-03,  3.14874873e-02, -2.49963384e-02,\n",
       "       -4.36721072e-02,  5.13971448e-02,  4.08058204e-02, -1.35327661e-02,\n",
       "       -9.99038890e-02, -1.85593478e-02,  4.03659418e-02, -3.66589166e-02,\n",
       "       -3.83624099e-02,  1.04500875e-02, -1.58992987e-02, -2.24248692e-02,\n",
       "        2.24889535e-02, -7.59380695e-04,  6.09182194e-02,  2.65667215e-02,\n",
       "       -3.72288339e-02,  4.20926325e-03,  2.68932208e-02,  1.82142146e-02,\n",
       "        5.41767143e-02, -1.28829693e-02,  2.74318960e-02,  1.48380185e-02,\n",
       "       -2.95372382e-02,  2.29955502e-02,  2.56370027e-02,  8.73086508e-03,\n",
       "        1.04064150e-02, -3.05830855e-02, -4.91180494e-02, -2.21477039e-02,\n",
       "        3.29300538e-02,  4.45026555e-04, -1.51487738e-02,  2.67543718e-02,\n",
       "       -5.29311411e-02, -1.37547292e-02, -5.30712232e-02, -2.94353403e-02,\n",
       "       -3.67463715e-02,  3.19682434e-02, -2.68230750e-03, -4.29942086e-02,\n",
       "       -5.14842235e-02,  5.21903001e-02,  3.23864594e-02, -3.06740031e-02,\n",
       "       -4.09650318e-02,  2.17014290e-02, -4.66192625e-02, -2.47588679e-02,\n",
       "       -1.18789710e-02,  2.25319471e-02,  5.01673222e-02,  2.84117907e-02,\n",
       "       -3.29947956e-02,  3.89843583e-02, -4.08347063e-02,  6.30879914e-03,\n",
       "        1.40625779e-02,  2.45058853e-02, -1.53456051e-02,  7.04560652e-02,\n",
       "       -3.52243520e-02, -2.67902762e-03,  4.82945181e-02,  3.97573337e-02,\n",
       "        3.49329822e-02, -1.63138527e-02,  6.33601053e-03,  2.80559026e-02,\n",
       "       -3.10990792e-02, -3.87109555e-02, -2.15491075e-02, -3.38646360e-02,\n",
       "        1.18917916e-02, -4.16390002e-02,  2.15888321e-02,  1.33490423e-02,\n",
       "       -6.89337542e-03, -6.53886348e-02, -5.36324829e-02, -3.10609452e-02,\n",
       "        2.06650514e-03,  2.99173668e-02, -4.89030294e-02,  2.20343843e-02,\n",
       "       -9.53092277e-02, -4.05678861e-02,  7.44412001e-03, -1.07837599e-02,\n",
       "       -9.63504165e-02, -4.76282761e-02,  1.49256550e-02,  4.26736474e-02,\n",
       "        1.14357499e-02,  6.52351826e-02, -8.77334327e-02,  4.02947739e-02,\n",
       "        3.42849307e-02, -4.68162671e-02, -1.57214701e-02, -6.48935065e-02,\n",
       "       -1.72020122e-02,  2.88572870e-02, -1.46279414e-03,  2.24191998e-03,\n",
       "        2.68874876e-02,  5.62966568e-03,  5.90267032e-02,  6.81883516e-03,\n",
       "        2.85271723e-02, -4.68042009e-02, -4.35808040e-02, -2.69720070e-02,\n",
       "        5.94889605e-03, -2.65482683e-02, -6.49966151e-02,  3.14295292e-02,\n",
       "        3.19412574e-02, -2.76590623e-02,  5.19889109e-02, -6.20672619e-03,\n",
       "        4.17252667e-02, -6.43557357e-03, -6.99497247e-03, -1.96109265e-02,\n",
       "        3.09277419e-02, -1.04673384e-02,  6.94002444e-03,  7.84027204e-03,\n",
       "       -6.26114896e-03,  6.78247809e-02,  2.51940098e-02,  4.79667448e-02,\n",
       "        5.65359741e-03,  6.31084293e-03,  5.71125224e-02, -2.22705267e-02,\n",
       "       -2.97067873e-02,  3.79278436e-02, -2.64340267e-02,  3.97083461e-02,\n",
       "       -4.74710129e-02, -7.40389619e-03, -4.33383547e-02,  4.19141576e-02,\n",
       "        1.94243360e-02,  1.95702929e-02,  5.13130203e-02,  4.30757459e-03,\n",
       "        5.52873611e-02, -8.32820684e-03,  5.36743440e-02,  3.39301191e-02,\n",
       "        6.30075485e-02, -2.39066239e-02, -1.43521084e-02,  3.12610492e-02,\n",
       "       -3.81988683e-03,  7.54495040e-02,  2.88385432e-02, -9.92566347e-03,\n",
       "        1.91373024e-02,  3.99885960e-02,  3.67345139e-02, -2.22155526e-02,\n",
       "        7.71852629e-03,  8.53304286e-03,  3.11405063e-02,  1.65280001e-03,\n",
       "       -1.65259913e-02,  2.99680582e-03,  4.01773155e-02, -3.29468250e-02,\n",
       "        1.73037481e-02,  3.03115081e-02, -6.33458840e-03, -9.02303681e-03,\n",
       "        3.10201570e-03, -2.45899167e-02,  2.01356858e-02, -2.48506330e-02,\n",
       "       -2.28175279e-02,  2.65114792e-02, -3.87921520e-02,  2.08582357e-03,\n",
       "        5.60161471e-02, -7.24918619e-02,  4.51748259e-02, -2.51560286e-02,\n",
       "        2.74047554e-02,  1.34954331e-02, -4.77239713e-02,  2.21924055e-02,\n",
       "        1.13009317e-02, -4.06526439e-02, -6.10096417e-02,  2.40315795e-02,\n",
       "        1.79754775e-02, -2.69579664e-02,  2.48657726e-02,  6.40531108e-02,\n",
       "       -8.82382598e-03,  9.62817483e-03, -4.66833077e-02, -3.50622237e-02,\n",
       "       -3.53845768e-02,  3.07974359e-03, -4.82669175e-02, -4.68125641e-02,\n",
       "       -2.12735981e-02,  1.15797482e-02,  5.23927622e-02, -5.07669225e-02,\n",
       "       -6.13658801e-02, -2.13054148e-03, -2.50912569e-02,  1.68142747e-02,\n",
       "        3.45229805e-02,  1.55837527e-02,  2.13599764e-02, -5.50432503e-02,\n",
       "       -8.05427507e-02,  1.85429696e-02,  2.94000916e-02, -2.72456910e-02,\n",
       "       -4.11329651e-03, -1.02859223e-03,  1.47594037e-02,  5.73122548e-03,\n",
       "        4.94047925e-02, -2.68509891e-02,  2.26104800e-02,  4.72763972e-03,\n",
       "       -9.72658221e-04,  5.65011567e-03, -9.42806751e-02,  1.30840586e-02,\n",
       "       -1.08186454e-02, -6.06983118e-02,  3.95519892e-03, -2.05912087e-02,\n",
       "        1.23455552e-02, -2.31418777e-02, -2.76849400e-02, -4.01769159e-03,\n",
       "        2.34307908e-02,  6.76696002e-02,  2.53562517e-02,  1.15754567e-02,\n",
       "       -6.57708524e-03,  3.40430662e-02, -6.86336905e-02, -5.64640686e-02,\n",
       "        1.48150511e-03, -6.61580730e-03,  1.54596912e-02,  5.07205613e-02,\n",
       "        6.69745822e-03, -2.31734831e-02,  1.48860933e-02, -1.65611468e-02,\n",
       "       -2.47802921e-02, -1.98177155e-02,  6.13477733e-03, -2.10845334e-04,\n",
       "        3.25372554e-02,  6.13161847e-02, -4.50816229e-02,  4.25695954e-03,\n",
       "       -4.83041964e-02,  4.39790189e-02,  4.96539176e-02,  4.84298496e-03,\n",
       "       -1.47189032e-02,  3.03833373e-02, -1.81896556e-02, -2.23136209e-02,\n",
       "        2.66161282e-02, -3.54833640e-02, -6.91781892e-03,  2.47511938e-02,\n",
       "        9.20720957e-03,  3.51961404e-02, -1.88393332e-02, -7.58374110e-02,\n",
       "        6.63237050e-02,  1.83793884e-02, -3.99918631e-02, -4.16302830e-02,\n",
       "       -3.64771150e-02,  2.58680210e-02, -6.84251264e-02, -1.43839279e-02,\n",
       "       -8.08518939e-03,  8.50358084e-02, -1.80437267e-02, -5.02093062e-02,\n",
       "        2.10509612e-03,  5.89131601e-02, -3.70660610e-02, -4.09511477e-02,\n",
       "        1.90675016e-02,  1.82881225e-02,  2.19205283e-02, -5.04083466e-03,\n",
       "       -7.02966452e-02,  6.17530104e-03, -4.62940224e-02, -1.08226063e-02,\n",
       "       -3.96547019e-02, -3.62997279e-02, -8.09447560e-03,  4.87236716e-02,\n",
       "       -2.35766340e-02, -1.46657890e-02,  2.91682109e-02, -3.63434143e-02,\n",
       "       -1.00385742e-02,  4.01845090e-02,  4.08013910e-03,  1.22838587e-01,\n",
       "        3.35775726e-02, -1.96220372e-02, -1.58604458e-02,  9.75032151e-03,\n",
       "       -3.06298137e-02, -5.08758388e-02,  4.51367423e-02, -2.94987336e-02,\n",
       "        1.65623054e-02, -1.36027113e-02, -7.16090128e-02, -4.30551590e-03,\n",
       "       -3.58247720e-02, -1.52075780e-03,  9.25682932e-02, -4.11738828e-02,\n",
       "        2.41485238e-03, -7.37256557e-03,  4.30188999e-02, -1.57357696e-02,\n",
       "        2.43801028e-02, -4.28318977e-02,  1.27477916e-02, -6.16237484e-02,\n",
       "        3.21011320e-02,  9.15835425e-03, -1.07430127e-02,  1.79095753e-02,\n",
       "       -5.63010108e-03, -1.21304980e-02, -8.82279202e-02,  2.47060955e-02,\n",
       "       -6.51600361e-02, -6.86381338e-03,  5.00551537e-02,  1.18482590e-03,\n",
       "        3.49965282e-02,  3.01433494e-03, -4.35033627e-02, -8.48351326e-03,\n",
       "       -8.52555558e-02,  1.59702431e-02,  1.76883116e-02,  4.22322862e-02,\n",
       "       -1.28285224e-02, -3.20094675e-02,  9.25515406e-03, -3.63752693e-02,\n",
       "        6.10694699e-02,  6.01380190e-04,  3.14918309e-02,  2.89484765e-02,\n",
       "       -2.64538778e-03, -4.38718162e-02,  3.97746414e-02, -2.15910785e-02,\n",
       "       -1.12068970e-02, -3.17984959e-03,  2.31688865e-03,  3.47329862e-02,\n",
       "        2.00990532e-02, -6.08191127e-03,  2.90727075e-02, -4.84774821e-03,\n",
       "        5.52584836e-03,  2.55749375e-02,  9.11086798e-03,  3.75860371e-02,\n",
       "       -2.13225856e-02, -2.52454672e-02, -4.30688970e-02, -4.08653095e-02,\n",
       "        4.28046100e-02,  1.80821568e-02,  3.61684300e-02,  1.63919590e-02,\n",
       "        5.81842251e-02,  6.55213967e-02, -6.48737624e-02, -1.40182646e-02,\n",
       "        4.99433093e-02, -3.26230638e-02,  5.13213128e-02,  3.14126979e-03,\n",
       "       -8.72294605e-03,  7.97408894e-02, -4.55399863e-02, -2.70762984e-02,\n",
       "       -2.10409127e-02, -6.56381063e-03, -2.11622175e-02,  6.00254685e-02,\n",
       "       -4.91450401e-03,  1.24704698e-02,  2.25286651e-03,  2.38246433e-02,\n",
       "        2.52687931e-03,  1.73788518e-02, -8.79127067e-03,  3.31978202e-02,\n",
       "        8.82728305e-03, -3.19625475e-02, -4.07385267e-02,  1.49988690e-02,\n",
       "       -6.40241848e-03, -2.41123084e-02,  3.12345717e-02, -9.48595162e-03,\n",
       "       -1.05531365e-02, -1.03656529e-02,  3.92877311e-03, -1.72041263e-02,\n",
       "        8.12497213e-02,  4.65816036e-02,  2.58172750e-02, -4.80301864e-02,\n",
       "        8.19049105e-02,  2.74391137e-02, -5.91675118e-02,  6.34129858e-03,\n",
       "       -5.47137335e-02,  3.81328836e-02, -7.38103539e-02, -1.93738341e-02,\n",
       "        4.81096841e-02,  7.27817137e-03,  3.23912427e-02, -3.20039503e-03,\n",
       "        4.19926876e-03, -1.37424078e-02, -6.69611916e-02, -2.83232221e-04,\n",
       "       -1.93064697e-02, -4.26965095e-02,  4.40032892e-02, -8.33615139e-02,\n",
       "       -9.66397673e-03,  1.01852985e-02,  2.28348803e-02,  2.63728797e-02,\n",
       "        3.26868594e-02, -2.34908964e-02,  2.03931704e-02,  2.07241122e-02,\n",
       "       -8.21036752e-03,  2.51472350e-02, -5.73041216e-02,  2.42485683e-02,\n",
       "       -5.73461019e-02, -9.84092150e-03, -4.48514521e-03, -2.91242041e-02,\n",
       "        3.65500636e-02,  1.38929747e-02,  2.26750434e-03, -1.49015784e-02,\n",
       "       -5.23399301e-02, -1.94030050e-02,  2.08856240e-02,  8.07917863e-03,\n",
       "       -4.01518121e-02, -3.07450201e-02, -2.22045984e-02, -1.99610498e-02,\n",
       "        2.96979155e-02,  9.84493271e-03, -4.08847891e-02, -1.46319065e-03,\n",
       "       -4.99302261e-02,  7.69469794e-03,  8.73711985e-03, -2.17310302e-02,\n",
       "        2.91678663e-02,  3.11214123e-02, -3.26263048e-02,  2.15331968e-02,\n",
       "       -3.22231948e-02, -4.07638848e-02,  4.72527836e-03, -3.43630128e-02,\n",
       "       -7.62950629e-02,  3.83950444e-03,  2.45366059e-02, -2.57070083e-02,\n",
       "        3.64518771e-03,  7.72486776e-02, -8.91152844e-02, -4.40079272e-02,\n",
       "       -1.13471011e-02, -2.12716684e-02,  5.31937694e-03, -6.18044112e-04,\n",
       "       -2.40105782e-02,  2.52822731e-02, -3.84292230e-02,  2.75130905e-02,\n",
       "       -5.00807213e-03,  1.58996042e-02, -6.50740461e-03,  2.11811569e-02,\n",
       "       -7.44663924e-03, -2.52820533e-02, -9.56500228e-03,  4.18481159e-06,\n",
       "        1.16155454e-04, -1.57231316e-02,  2.06223107e-03, -1.33930119e-02,\n",
       "        2.01830063e-02,  3.14357989e-02,  3.77953649e-02,  1.97851029e-03,\n",
       "        1.02336463e-02, -1.89723875e-02, -4.25273478e-02,  1.49853975e-02,\n",
       "        2.75506340e-02,  3.40677798e-03, -2.00169277e-03,  3.53896990e-02,\n",
       "       -4.77509499e-02, -6.88232854e-03, -2.12698318e-02, -6.62481487e-02,\n",
       "       -5.34188887e-03,  1.68316043e-03, -7.45524606e-03,  7.65520195e-03,\n",
       "       -3.18697840e-02, -1.61708929e-02, -1.80620477e-02, -7.75939459e-03,\n",
       "        4.82177781e-03,  3.43820639e-02, -3.63199748e-02, -4.24790308e-02,\n",
       "        3.57568450e-02, -3.27770337e-02,  3.58273508e-03,  1.56403857e-03,\n",
       "       -2.91321576e-02, -1.11822458e-02,  3.58746946e-02,  2.15418581e-02,\n",
       "       -8.02556705e-03,  2.28763930e-02,  3.39382254e-02,  5.39060421e-02,\n",
       "       -4.13247347e-02,  3.47295851e-02,  3.39432573e-03,  2.26916596e-02,\n",
       "       -2.44295485e-02,  2.45176759e-02,  1.25208916e-02, -8.22778121e-02,\n",
       "        1.50729185e-02, -9.98166297e-03, -5.47748851e-03,  3.48183140e-02,\n",
       "       -3.76810320e-02,  5.29778711e-02, -1.58966857e-03,  5.46683222e-02,\n",
       "        1.50641249e-02,  1.78597420e-02, -1.84267983e-02,  3.53789106e-02,\n",
       "        2.65327133e-02, -2.19306611e-02,  6.91059697e-03,  4.84528430e-02,\n",
       "       -6.55087549e-03,  4.27525584e-03,  3.91608849e-02,  3.09133697e-02,\n",
       "        7.85019398e-02,  7.86855072e-03,  2.18667891e-02,  3.02154049e-02,\n",
       "        3.78663093e-02, -4.35519628e-02,  1.28818974e-02,  7.35305250e-03,\n",
       "       -2.01671254e-02, -2.60706954e-02,  7.32353255e-02, -1.54959811e-02,\n",
       "        1.88835207e-02, -2.82456893e-02,  1.88674200e-02, -8.28095824e-02,\n",
       "       -7.29760304e-02, -4.37419899e-02, -4.39268537e-02, -7.56198838e-02,\n",
       "        1.62256006e-02,  4.29009087e-02, -3.43441330e-02,  6.68707816e-03,\n",
       "        5.34251742e-02,  9.90119353e-02,  2.94532347e-02, -2.91050002e-02,\n",
       "        2.01900601e-02,  7.47467857e-03, -2.07094345e-02, -1.63159135e-03,\n",
       "       -2.62293586e-04,  4.04647812e-02,  1.92472599e-02, -5.78107825e-03,\n",
       "       -1.75511856e-02,  5.35984188e-02,  6.70336559e-03, -4.30596471e-02,\n",
       "        1.58901494e-02,  4.18049730e-02,  4.15984131e-02, -3.70265767e-02,\n",
       "       -5.16457930e-02, -2.17858367e-02,  1.95014663e-02,  4.40504663e-02,\n",
       "        6.27809092e-02,  1.33528132e-02, -6.57661408e-02, -6.91113696e-02,\n",
       "        1.15935290e-02,  4.15651202e-02,  1.14170676e-02,  3.54875363e-02,\n",
       "       -6.62799599e-03,  3.16270664e-02, -4.00736891e-02, -5.54455332e-02,\n",
       "        7.43385125e-03, -3.24941315e-02,  3.51529010e-03, -1.93491764e-02,\n",
       "        1.41955717e-02, -3.84767391e-02,  5.50613776e-02, -3.78730260e-02,\n",
       "        3.54474806e-03,  3.80369723e-02, -5.34376735e-03, -3.84527980e-03,\n",
       "       -4.82890150e-03, -2.31261458e-02, -6.46207761e-03, -4.52378504e-02,\n",
       "        3.59696038e-02, -4.41477560e-02, -5.53413481e-02, -1.50651047e-02,\n",
       "        9.60742217e-03,  1.82113647e-02, -2.53788661e-02,  2.45936657e-03,\n",
       "       -1.70268733e-02,  4.97980835e-03, -3.15394811e-02, -7.51275718e-02,\n",
       "        1.31277181e-02,  8.59513432e-02, -1.38983261e-02,  2.78725917e-03,\n",
       "       -5.56046106e-02, -3.57736424e-02, -7.04389736e-02, -6.04411326e-02,\n",
       "       -9.62870345e-02, -6.64142668e-02, -2.72959750e-02, -3.58605869e-02,\n",
       "       -1.04999924e-02,  4.13042232e-02, -9.23620164e-03,  2.33521070e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain-core<2.0.0,>=0.3.75 (from langchain-community)\n",
      "  Downloading langchain_core-0.3.75-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting langchain<2.0.0,>=0.3.27 (from langchain-community)\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain-community)\n",
      "  Downloading sqlalchemy-2.0.43-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting requests<3,>=2.32.5 (from langchain-community)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting langsmith>=0.1.125 (from langchain-community)\n",
      "  Downloading langsmith-0.4.20-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain<2.0.0,>=0.3.27->langchain-community)\n",
      "  Downloading langchain_text_splitters-0.3.10-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.11.1)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<2.0.0,>=0.3.75->langchain-community)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (24.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.27.0)\n",
      "Collecting orjson>=3.9.14 (from langsmith>=0.1.125->langchain-community)\n",
      "  Downloading orjson-3.11.3-cp312-cp312-win_amd64.whl.metadata (43 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.125->langchain-community)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.1.125->langchain-community)\n",
      "  Downloading zstandard-0.24.0-cp312-cp312-win_amd64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from requests<3,>=2.32.5->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from requests<3,>=2.32.5->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from requests<3,>=2.32.5->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from requests<3,>=2.32.5->langchain-community) (2025.1.31)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain-community)\n",
      "  Downloading greenlet-3.2.4-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.14.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-community)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pip>=25.2 (from langchain-text-splitters<1.0.0,>=0.3.9->langchain<2.0.0,>=0.3.27->langchain-community)\n",
      "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.33.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 29.1 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 24.4 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.75-py3-none-any.whl (443 kB)\n",
      "Downloading langsmith-0.4.20-py3-none-any.whl (377 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading sqlalchemy-2.0.43-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 58.3 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.2.4-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.10-py3-none-any.whl (34 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading orjson-3.11.3-cp312-cp312-win_amd64.whl (131 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading zstandard-0.24.0-cp312-cp312-win_amd64.whl (505 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 31.7 MB/s eta 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: To modify pip, please run the following command:\n",
      "C:\\Users\\Casham2045\\miniconda3\\envs\\ds\\python.exe -m pip install langchain-community\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5c7f284e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain-core<2.0.0,>=0.3.75 (from langchain-community)\n",
      "  Using cached langchain_core-0.3.75-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting langchain<2.0.0,>=0.3.27 (from langchain-community)\n",
      "  Using cached langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain-community)\n",
      "  Using cached sqlalchemy-2.0.43-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting requests<3,>=2.32.5 (from langchain-community)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting langsmith>=0.1.125 (from langchain-community)\n",
      "  Using cached langsmith-0.4.20-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain<2.0.0,>=0.3.27->langchain-community)\n",
      "  Using cached langchain_text_splitters-0.3.10-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langchain<2.0.0,>=0.3.27->langchain-community) (2.11.1)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<2.0.0,>=0.3.75->langchain-community)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain-community) (24.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.27.0)\n",
      "Collecting orjson>=3.9.14 (from langsmith>=0.1.125->langchain-community)\n",
      "  Using cached orjson-3.11.3-cp312-cp312-win_amd64.whl.metadata (43 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.125->langchain-community)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.1.125->langchain-community)\n",
      "  Using cached zstandard-0.24.0-cp312-cp312-win_amd64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from requests<3,>=2.32.5->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from requests<3,>=2.32.5->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from requests<3,>=2.32.5->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from requests<3,>=2.32.5->langchain-community) (2025.1.31)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain-community)\n",
      "  Using cached greenlet-3.2.4-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.14.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain-community)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pip>=25.2 (from langchain-text-splitters<1.0.0,>=0.3.9->langchain<2.0.0,>=0.3.27->langchain-community)\n",
      "  Using cached pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain-community) (2.33.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Using cached langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Using cached langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_core-0.3.75-py3-none-any.whl (443 kB)\n",
      "Using cached langsmith-0.4.20-py3-none-any.whl (377 kB)\n",
      "Using cached pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached sqlalchemy-2.0.43-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "Using cached greenlet-3.2.4-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain_text_splitters-0.3.10-py3-none-any.whl (34 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached orjson-3.11.3-cp312-cp312-win_amd64.whl (131 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached zstandard-0.24.0-cp312-cp312-win_amd64.whl (505 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached pip-25.2-py3-none-any.whl (1.8 MB)\n",
      "Installing collected packages: zstandard, requests, pip, orjson, mypy-extensions, marshmallow, jsonpointer, httpx-sse, greenlet, typing-inspect, SQLAlchemy, requests-toolbelt, jsonpatch, pydantic-settings, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 25.0\n",
      "    Uninstalling pip-25.0:\n",
      "      Successfully uninstalled pip-25.0\n",
      "Successfully installed SQLAlchemy-2.0.43 dataclasses-json-0.6.7 greenlet-3.2.4 httpx-sse-0.4.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.27 langchain-community-0.3.29 langchain-core-0.3.75 langchain-text-splitters-0.3.10 langsmith-0.4.20 marshmallow-3.26.1 mypy-extensions-1.1.0 orjson-3.11.3 pip-25.2 pydantic-settings-2.10.1 requests-2.32.5 requests-toolbelt-1.0.0 typing-inspect-0.9.0 zstandard-0.24.0\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2fa7c72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path().resolve().parent\n",
    "slides = ROOT / \"data\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2b36a875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (6.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1d819b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9d42ee4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 0, 'page_label': '1'}, page_content='Starting up at 5:35'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 1, 'page_label': '2'}, page_content='(Re)-Introduction to Data \\nScience & Control Flow'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 2, 'page_label': '3'}, page_content='Agenda - Schedule\\n1. Warm Up\\n2. Canvas & Data Science Review \\n3. Docstrings in Functions\\n4. Control Flow & Truthiness\\n5. Nested if Statements \\n6. VSCode Lab \\nControl ﬂow diagram \\nhttps://runestone.academy/ns/books/published/csawesome/\\nUnit3-If-Statements/topic-3-2-ifs.html'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 3, 'page_label': '4'}, page_content='Agenda - Goals\\n● Get re-introduced to data science\\n● Understand how to document your functions\\n● Review basic conditionals and implement nested conditionals in Python'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 4, 'page_label': '5'}, page_content='Warm-Up'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 5, 'page_label': '6'}, page_content='def list_process(data: list, n: int) -> list:\\n    averages = []\\n    if len(data) <= 1 or n == 1:\\n        return averages \\n    window = data[:n]\\n    roll_average = sum(window ) / n \\n    averages.append(roll_average) \\n    return averages\\nprint(list_process([], 1))\\nprint(list_process([2, 1, 3, 4, 6, 5], 1))\\nprint(list_process([2, 1, 3, 4, 6, 5], 3))\\nEvaluate this chunk of code. Work together to ﬁgure out what will occur \\nwhen we run this code. Try not to run this code in your editor, and instead, \\nevaluate what occurs to the data at each step.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 6, 'page_label': '7'}, page_content='You are working as a data analyst at an online shopping platform.\\nYou are tasked with performing descriptive customer segmentation by \\nevaluating one dimension: age.\\nWhich visualization would be most appropriate to express the distribution \\nof the ages of your customers? Hint: are we performing predictive or \\ndescriptive analytics? Do we have one or multiple dimensions? Are our \\ndimensions quantitative or categorical?\\nJoin your pod groups and evaluate this statement. Work together to ﬁgure \\nout what the appropriate visualization would be.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 7, 'page_label': '8'}, page_content='Fellowship Purpose'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 8, 'page_label': '9'}, page_content='Course Goals - Abstract \\nIn the shallow sense of things, this fellowship aims to \\nteach you different skills that build off of each \\nother. In the abstract, the goals entail:\\nPhase 1: Learn how to engineer, pipeline, and \\ncollect\\nPhase 2: Learn how to analyze, predict, model, and \\ninnovate\\nPhase 3: Learn how to manage, collaborate, \\nvisualize, and inform'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 9, 'page_label': '10'}, page_content='Course Goals\\n“By the end of this fellowship, you will have a comprehensive suite of \\nprojects and a thorough foundation of data-science knowledge that will \\nallow you to succeed and grow in any job that uses a contemporary \\ntech stack to answer complex data-driven questions.”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 10, 'page_label': '11'}, page_content='Some Tips for the Upcoming Weeks\\n● T ake things slowly, and try not to worry about material we didn’t \\ncover yet. Focus on the now.\\n● We rarely understand things at ﬁrst glance. Revisit topics often. \\n● If you are feeling challenged, that is a good sign! Stay with that \\ndiscomfort. \\n● Keep your personal goals and intellectual curiosities in mind as you \\ncomplete this fellowship. Listen to podcasts, write, watch sci-ﬁ, etc. \\n● Make time to step away from the computer. \\n● Communicate early and often. It’s easy to let things slip in a remote \\nenvironment'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 11, 'page_label': '12'}, page_content='Fellowship Structure'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 12, 'page_label': '13'}, page_content='Schedule Overview\\nPhase Dates Assignments Quizzes Focus\\n1 03/10/2025 - 05/23/2025 1 End of Phase Project\\n3 TLABS\\n10 Quizzes Python, pandas, \\nComputational Thinking, \\nIntroductory Statistics, \\nWeb-Scraping, API, SQL\\n2 06/09/2025 - 08/29/2025 1 End of Phase Project\\n3 TLABS\\n10 Quizzes Supervised & \\nUnsupervised machine \\nlearning, SQL, Generative \\nAI \\n3 09/15/2025 - 12/05/2025 1 Capstone Project Group Capstone\\nPhase 3 will arguably be the most important \\nphase! You will work in your pods to create a \\ncomprehensive, end-to-end data science \\nproject.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 13, 'page_label': '14'}, page_content='Class Structure\\nEach week of class will entail the following content:\\n1. Week Overview & Lesson Plan\\n2. Post-class  Summary \\n3. Class Content\\n4. A long-term assignment or short-term quiz\\nAll together, we recommend that you spend 10-20 \\nhours/week outside of class working on material for \\nyour success.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 14, 'page_label': '15'}, page_content='Weekly Overview\\nThis page will inform you about incoming \\ncontent/assignments.\\nIn addition, it will also list all \\nresources/videos we would like for you to \\nwatch to “get ahead” of class material.\\nWhen the fellowship starts, this page will \\nalso entail a light 5-question quiz to \\nprepare you for the week, due before \\nMonday’s class.\\nNo quiz this week since its week 1.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 15, 'page_label': '16'}, page_content='Post-Class Summary\\nWe will also post a post-class summary to \\nwrap the week up.\\nThis will include:\\n● An AI “Podcast” summary on the \\nrespective weeks content\\n● Extra resources for those looking for \\nadditional challenges (highly highly \\nrecommended)\\n● Incoming assignments'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 16, 'page_label': '17'}, page_content='Class Content\\nThis page will inform you about the \\ndaily activity/resources that you need \\nto follow along with class material. \\nThis entails:\\n● Slides\\n● Readings\\n● Videos\\n● Exercises'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 17, 'page_label': '18'}, page_content='Stats Lab Content\\nEach Wednesday, we will switch gears \\nand solely focus on a statistics \\nmodule to complement your \\nprogramming knowledge. \\nThis will be run like a typical class day.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 18, 'page_label': '19'}, page_content='TLAB/Quiz\\nOnce every 3 weeks we will post a \\nlong-term TLAB which you will \\nwork on outside of class, as well as \\nduring the Thursday review \\nsessions.\\nBe sure to start early.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 19, 'page_label': '20'}, page_content='Class Structure\\nMonday, Tuesday, Wednesday\\n5:30 - 7:30 PM: Lecture & code-along\\n7:30 - 8:00 PM: Break\\n8:00 - 9:30 PM: Lab session\\nUnless the syllabus states otherwise, our days will entail the following \\nschedule:\\nThursday\\n5:30 - 7:30 PM: Open review session\\nI am a fairly long-winded person, so be sure to save \\nquestions for the Zoom chat/1:1 ofﬁce hours.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 20, 'page_label': '21'}, page_content='Canvas/Assignment Structure'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 21, 'page_label': '22'}, page_content='Assignment Structure\\nThis fellowship will follow a predictable format for phase 1 and phase 2.\\n● 3 TLAB’s (3 week due date)\\n○ 30% of grade\\n● 10 quizzes (1 week due date)\\n○ 20% of grade (lowest dropped)\\n● 1 End of Phase Project (4 week due date)\\n○ 50% of grade\\nOccasionally, you will have to look to outside resources to completes these assignments!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 22, 'page_label': '23'}, page_content='Assignment Structure - Resubmissions\\nEach TLAB  can be submitted twice before \\nthe due date (highest grade will be kept). \\nIf you submit within 1 week of the due date \\nyou will receive feedback .\\nFeedback is one of the most valuable things \\nyou can receive as a technologist, use it!!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 23, 'page_label': '24'}, page_content='Assignment Structure - Late Submissions\\nDuring each phase you get 3 “tokens” that \\nyou can use to submit an assignment 48 \\nhours late.\\nHowever you cannot “stack” tokens for one \\nassignment. \\nAny accommodation beyond these 3 needs \\nto be requested to the Instructor & Student \\nSuccess specialist.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 24, 'page_label': '25'}, page_content='(Re)-Introduction to Data \\nScience'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 25, 'page_label': '26'}, page_content='(Re)-Introduction to Data Science\\nWe’ve gone over the history, prospects, and importance of data science. \\nLet’s close out this discussion by talking about the ever-creeping future of \\ndata science and why your presence in this fellowship matters.\\nOnce again, we are not historians, political scientists, nor economists, but \\nwe can talk about atomic realities which reveal trends.\\nWhile these are harsh realities to acknowledge, they also prepare us for \\nwhich challenges we need to surmount.\\nThose who show up make the \\ndecisions.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 26, 'page_label': '27'}, page_content='(Re)-Introduction to Data Science : Market\\nCurrently we are in what we call a buyers market (employers favor) whereas \\nmost of the previous decade favored the sellers market (employees favor).\\nThis means:\\n● Lower starting salaries, with less room to negotiate. Stagnation.\\n● Starkly more competition for entry level roles.\\n● Less priority for companies to attract talent through beneﬁts. \\n● Also less priority for employers to match employee culture.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 27, 'page_label': '28'}, page_content='Using software engineer roles as a proxy, we see that salaries are growing \\nslower.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 28, 'page_label': '29'}, page_content='The hiring bubble of tech roles during COVID is gone (no more cheap \\ncapital) and open tech roles reﬂect a more tepid hiring market.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 29, 'page_label': '30'}, page_content='Part of this is political alignment and an assessment of what “America” \\nwants, but companies are deprioritizing initiatives to align themselves with \\nemployee culture.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 30, 'page_label': '31'}, page_content='(Re)-Introduction to Data Science : Future Products\\nIn addition to a deprioritization of culture alignment the data science \\nproducts of tomorrow might be direct implementations of the dystopian \\nsci-ﬁ movies of the past century. \\nI don’t have the data to prove this yet, and this might seem alarmist but \\ncheck out what’s being actively used and funded…\\nKeep in mind that none of these are inherently political statements. \\nI’m operating off of a simple pre-condition: “using algorithms to kill \\npeople & create a surveillance state is bad.”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 31, 'page_label': '32'}, page_content='In the lecture, the commander speaks about a new, sophisticated target machine used by \\nthe Israeli army that detects “dangerous people” based on their likeness to existing lists of \\nknown militants on which it was trained. \\nhttps://www.972mag.com/lavender-ai-israeli-army-gaza/'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 32, 'page_label': '33'}, page_content='“...that, since the country’s tech scene is historically a product of the national security state, \\nSilicon Valley executives and engineers should shed their compunctions about working with \\nthe military and dedicate themselves to ensuring another century of American hard-power \\nsupremacy.” https://newrepublic.com/article/191786/alex-karps-war-west-palantir'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 33, 'page_label': '34'}, page_content='Optifye says it’s building software to help factory owners know who’s working — and who isn’t — in “real-time” thanks to AI-powered security cameras it places on assembly lines, according to its YC profile. https://techcrunch.com/2025/02/25/y-combinator-deletes-posts-after-a-startups-demo-goes-viral/'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 34, 'page_label': '35'}, page_content='What all this Means For You\\nOnly time will truly tell what the future holds, but here’s what all of this \\nmeans for you and I: \\n● This tech crash has happened before, and has historically led to a \\nsellers market (power on employees side). You must be patient and your \\nmotivation for pursuing this role must go beyond money.\\n● If you pursue an attitude of “The destination matters, not the journey” , you \\nwill ﬁnd yourself working on the equivalent of SkyNet.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 35, 'page_label': '36'}, page_content='The market switched sides to where the employees had all the power, and due to \\nanother massive round of venture capital injection, money was ﬂowing freely. \\nhttps://ghuntley.com/screwed/'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 36, 'page_label': '37'}, page_content='DocStrings'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 37, 'page_label': '38'}, page_content='Documentation\\nLet’s revisit the concept of documenting our \\ncode.\\nDocumentation comes in two forms when \\nprogramming:\\n● README ﬁle: A ﬁle that encapsulates the \\nusage and purpose of your project.\\n● Code comments: “Comments” that describe \\ndiscrete pieces of code.\\nAnother aspect to “code comments” is something \\ncalled the ‘docstring. ’\\nRemember, documentation is the backbone to \\na maintainable codebase. We will be grading \\nyou on your ability to document as well.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 38, 'page_label': '39'}, page_content='When you consult the documentation of builtin functions, you may notice \\nthat there is a quick blurb describing the function, as well as motivating \\nexamples. This is called the docstring, and you will do the same for the \\nfunctions that you deﬁne as well.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 50, 'page_label': '51'}, page_content='There are many different standards of docstrings across languages, \\norganizations, and teams. For assignments, we will specify which standard \\nyou should follow. Mostly this will be the numpy standard.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 51, 'page_label': '52'}, page_content='More Control Flow'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 52, 'page_label': '53'}, page_content='More Control Flow - “Truthiness”\\nYou may have noticed that occasionally, we don’t use explicit boolean \\nexpressions to evaluate if a statement is true or false. For example\\nif num: …\\nif num % 2: …\\nWe call this the concept of truthiness'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 73, 'page_label': '74'}, page_content='Nested If’s'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 95, 'page_label': '96'}, page_content='In-Class Lab'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 96, 'page_label': '97'}, page_content='Lab - GitHub Module\\nFor the remaining lab time, break into your pod groups and complete the \\nfollowing modules:\\n● VSCode Unit 3: Lesson 1 - Lesson 4\\n● VSCode Unit 2: Lesson 6 - Lesson 8'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 97, 'page_label': '98'}, page_content='Wrap-Up'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 98, 'page_label': '99'}, page_content='Lab (Due 03/28)\\nThe company you work for, Seng-Links, aims to identify periods when a user \\nsleeps or exercises using their varying recorded heart rates. \\nYour company has provided you a data folder (data/) of 5 ﬁles that contain \\nheart-rate samples from a participant. The participants device records heart \\nrate data every 5 minutes (aka sampling rate). \\nYou are tasked with writing code that processes each data ﬁle. You will \\nutilize test-driven development in order to complete this project.\\nTaipei City, Taiwan'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 99, 'page_label': '100'}, page_content=\"Tuesday…\\nOn Tuesday we will expand our exploration of \\ncontrol ﬂow in Python to include:\\n● Logical conditional patterns\\n● For loops\\n● For loop common patterns\\nJupyter: scratchpad of the data \\nscientist\\nIf you understand what you're doing, you're \\nnot learning anything. - Anonymous\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': '(Re)-Introduction to Data Science & Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\(Re)-Introduction to Data Science & Control Flow.pptx.pdf', 'total_pages': 102, 'page': 100, 'page_label': '101'}, page_content='Glossary'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 0, 'page_label': '1'}, page_content='AB Testing'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 1, 'page_label': '2'}, page_content='Agenda - Schedule\\n1. Pandas Warm-Up\\n2. Hypothesis T esting Review\\n3. T-T esting & AB-T esting\\n4. Break\\n5. TLAB #3'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 2, 'page_label': '3'}, page_content='Agenda - Goals\\n● Explain the purpose of a two-sample t-test and when it’s appropriate to use\\n● Calculate a t-score using sample means, variances, and sample sizes\\n● Interpret a p-value and explain what it tells us about statistical signiﬁcance\\n● Identify key real-world considerations when applying t-tests in A/B testing, \\nsuch as sample size'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 3, 'page_label': '4'}, page_content='Announcements\\n● Review Session on 5/1 \\n● TLAB #3 due 5/14\\n“be-leaf in yourself!”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 4, 'page_label': '5'}, page_content='Pandas Leetcode Warm-Up'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 5, 'page_label': '6'}, page_content='T ake 10 minutes to work on the “Customer Placing the Largest Number of Orders” Leetcode problem: https://leetcode.com/problems/customer-placing-the-largest-number-of-orders/description/?envType=study-plan-v2&envId=30-days-of-pandas&lang=pythondata \\nThis will not be \\nsubmitted, but don’t \\nforget… the wheel is \\nwatching.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 6, 'page_label': '7'}, page_content='Hypothesis Testing Review'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 7, 'page_label': '8'}, page_content='In week 5, we discussed the concept of hypothesis testing via our ESP \\nexperiment. Recall that we ﬁrst assumed that ESP did not exist. This formed \\na binomial distribution. Does anyone recall what we call this hypothesis?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 8, 'page_label': '9'}, page_content='This was our distribution under the null hypothesis. This is the distribution \\nthat we expect our test-metric to follow assuming that there is no effect in \\nour dataset.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 9, 'page_label': '10'}, page_content='This distribution allowed us to identify the critical regions of our distribution. If we get a test-metric that falls into one of these areas, we can assuredly reject this distribution. The probability that this metric does not belong to this distribution is too high for us to tolerate!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 10, 'page_label': '11'}, page_content='Going back to our experiment, we got test-metric of 49 (49 out of 95 of you \\ncorrectly chose the cat). Does this fall within our critical region?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 11, 'page_label': '12'}, page_content='No! This means that we cannot reject this null distribution. We will see in \\nlater slides how this translates to a value we call the p-value. This tells us \\nthe probability that we will observe this value given the null hypothesis.\\nFor this \\ntest-metric, we get \\na p-value of 0.83 \\n(83% probability \\nof us getting this \\ntest-metric given \\nour null)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 12, 'page_label': '13'}, page_content='Notice that as we get a smaller p-value, we become more conﬁdent that \\nour null hypothesis is false. This means that we most likely do have some \\neffect in our dataset! \\nHowever, if we got \\nX=67 we would \\nget a p-value of \\n0.000039 \\n(0.0039% of \\ngetting this metric \\ngiven the null).\\nWould you be \\nwilling to put \\nmoney down on \\nsomething that \\nhas a 0.0039% \\nchance of being \\ntrue?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 13, 'page_label': '14'}, page_content='We start with nothing (Null)\\nLet’s review our hypothesis testing terminology\\nnull hypothesis (H0) - this is the base case, what our dataset would \\nshow if there is no effect\\nalternative hypothesis (H1) - this is what we think could be a possibility, \\nthis is what the dataset would look like if there is an effect\\nprobability (p) value - the probability of obtaining the result which \\noccurred assuming the null is true'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 14, 'page_label': '15'}, page_content='Null vs Alternative Hypothesis\\nImagine our question about whether caffeine affects our appetite.\\nH0 (null): caffeine does not have an effect on our appetite\\nH1 (alternative): caffeine does have an effect on our appetite\\nNote, H1 in this case does not say decrease or increase, just whether \\nthere is an effect period.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 15, 'page_label': '16'}, page_content='Null vs Alternative Hypothesis Examples\\nDoes a new medication improve the recovery time of a patient?\\nH0: \\nH1: \\nDoes the new banner ad we create improve the click-through rate?\\nH0:\\nH1:\\nLet’s try to formulate our own null and \\nalternative hypotheses.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 16, 'page_label': '17'}, page_content='Null vs Alternative Hypothesis Examples\\nDoes a new medication improve the recovery time of a patient?\\nH0: The new medication does not improve recovery time (𝛍0 = 𝛍1)\\nH1: The new medication does improve the recovery time of a patient (𝛍1 \\n< 𝛍0)\\nDoes the new banner ad we create improve the click-through rate?\\nH0: The new banner does not improve click-through rate (𝛍0 = 𝛍1)\\nH1:The new banner does improve click-through rate (𝛍1 > 𝛍0)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 17, 'page_label': '18'}, page_content='p-values\\nA small p-value gives us a level of confidence that differences between \\ntwo groups are due to differences between the groups instead of just \\nrandom chance\\ngenerally we use a value of p < 0.05 as a cut-off for rejecting the null \\nhypothesis\\nHowever, some researchers (especially in medicine) argue for even \\nstricter p-values (0.005, 0.0005).'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 18, 'page_label': '19'}, page_content='p-values - Type of Error\\nIf we reject the null hypothesis and are wrong, this is a false positive \\n(Type I error)\\nIf we do not reject the null hypothesis and are wrong, this is a false \\nnegative (Type II error)\\nWe use a small p-value to reduce false positives (Type I error)\\nReducing Type II error involves increasing the sample size (aka \\nincreasing the power of your dataset).'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 19, 'page_label': '20'}, page_content='By performing hypothesis testing in this fashion we are attempting to \\nminimize our chances of making a type I error, where the Null is true (there \\nis no effect in your dataset), but you erroneously assume there is an effect.\\nWe also control for this error using something called signiﬁcance level.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 20, 'page_label': '21'}, page_content='Two Sample T-Test'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 21, 'page_label': '22'}, page_content='calculating p-values\\nTo calculate p-values, we will choose a few different methods depending \\non what we are researching:\\n● T-test: used to compare the averages between 2 groups\\n● ANOVA: used to compare the averages between more than 2 groups\\n● Chi-Square Test: used to check for dependence between \\ncategorical variables\\nWe will discuss the T-test today and how we apply this concept to \\nperforming AB tests.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 22, 'page_label': '23'}, page_content='Fun fact, the t-test was invented by William Sealy Gosset to compare yeast \\ncells between batches of Guinness beer. Never underestimate human \\ncapacity for inventing mathematical formulas for the purpose of drinking, \\ngambling, video games, and other vices.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 23, 'page_label': '24'}, page_content='This is the formula which William Sealy Gosset developed to calculate if \\nthere is a signiﬁcant difference between groups. There’s a lot going on here \\nat once, so let’s break down  these steps.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 24, 'page_label': '25'}, page_content='Two Sample T-Test\\nThe formula describes the steps below:\\n1. Calculate the mean for both groups and take the difference between the means for \\neach group   \\n2. Calculate the pooled variance\\n3. Multiple the pooled variance with harmonic mean of group sizes, take the square \\nroot\\n4. Divide the difference between means, with the result of the previous step\\n5. Calculate the degrees of freedom and define the critical value alpha\\n6. Find the p-value based on whether you care about one tail (one direction) or two tail \\n(either direction)\\nIt might seem overwhelming, but let’s walk through each step!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 25, 'page_label': '26'}, page_content='Group A Group B\\n5 1\\n4 3\\n5 2\\n6 3\\n3 2\\nLet’s say we made a change to the TKH website and we want to see if our \\nusers spend more or less time on our website due to this change. We will \\ngive group A the original TKH website, and group B the new version. We \\nrecord the number of minutes they spend on our site.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 26, 'page_label': '27'}, page_content='Group A Group B\\n5 1\\n4 3\\n5 2\\n6 3\\n3 2\\nFirst we iron out our null and alternative hypotheses. Our null will state: \\nboth groups will spend an equalamount of time on the site. Our alternative \\nwill state: group A and group B will spend an unequal amount of time on the \\nsite  (more or less). What will be our ﬁrst step?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 27, 'page_label': '28'}, page_content='Group A Group B\\n5 1\\n4 3\\n5 2\\n6 3\\n3 2\\nLet’s calculate the mean between groups: Group A spends an average of 4.6 \\nminutes on our website. Group B spends an average of 2.2 minutes on the site. \\nObviously there appears to be a difference, but is this difference actually due to \\nthis change or are we observing random variance in our data?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 28, 'page_label': '29'}, page_content='Numerator = (5-4.6)^2 + (4-4.6)^2 + (5-4.6)^2 + (6-4.6)^2+ (3-4.6)^2 + (1-2.2)^2 + (3-2.2)^2 + \\n(2-2.2)^2 + (3-2.2)^2  + (2-2.2)^2 \\n              = 5.2 +  2.8\\n= 8\\nDenominator =5 + 5 - 2 \\n     = 10 - 2 \\n     = 8\\ns^2 = 8/8 \\n         = 1\\nNext, we calculate pooled variance. Notice that is simply a modiﬁed \\nvariance formula that takes into account the variance of both groups (hence \\nthe name pooled).'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 29, 'page_label': '30'}, page_content='Denominator = 1 ( ⅕ + ⅕) \\n                               = 1 * 0.4\\n                               = 0.4\\nt = 4.6 - 2.2/ (sqrt(0.4)) \\n   = 2.4 / 0.632 = 3.79\\nSo we are given a ﬁnal t-score of 3.79\\nWhat does that mean?\\nNext we multiply the pooled variance with the harmonic mean of sample \\nsizes. While this sounds like a high-minded formula, just keep in mind that \\nthis is the reciprocal of each groups sample size (1/n) added together.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 30, 'page_label': '31'}, page_content='The t-score by itself is meaningless, we have to ﬁrst decide at what value are \\nwe willing to reject the null hypothesis, this is known as the “alpha value”\\n-2.306 2.306'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 31, 'page_label': '32'}, page_content='The exact t-score value needed to “beat” the alpha changes depending on \\nthe size of your dataset and the alpha score.  For this two-sided t-test, and \\nan alpha of 0.05 the t-score should be at least 2.306\\nBecause we are doing a \\ntwo-sided t-test, we must \\nconsider both tails of the \\ndistribution. Because of this we \\nuse 0.05/2 (0.025) as our \\nsigniﬁcance level for both tails.\\n-2.306 2.306'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 32, 'page_label': '33'}, page_content='An Aside - P-value\\nWe usually state that our alpha (or \\nsigniﬁcance level) is 0.05. That is, if we \\ncalculate a p-value less than this \\nalpha, we state that our p-value is \\nsigniﬁcant and we must reject the \\nnull hypothesis.\\nThe smaller the alpha, the more \\nconﬁdent that you are not making a \\nType I error.\\nhttps://www2.psych.ubc.ca/~schaller/52\\n8Readings/CowlesDavis1982.pdf'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 33, 'page_label': '34'}, page_content='In this case, since our t-score > 2.306 we can immediately state that our p-value is \\nsigniﬁcant (we reject our null hypothesis that these two groups are the same).\\nWe can state that our p-value is less than 0.5.\\nt=3.79\\n-2.306 2.306'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 34, 'page_label': '35'}, page_content='You might be wondering where we got this critical value from. Back in “the \\nday” we would look up the critical score table and ﬁnd what critical score we \\nneed to “beat” in order for our t-score to be signiﬁcant (and subsequently \\nreject the null hypothesis)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 35, 'page_label': '36'}, page_content='However you are most likely going to ﬁnd yourself automatically calculating \\nthis value via some Python method or through a calculator. Is our p-value \\nless than our alpha of 0.05?\\nfrom scipy import stats\\ngroup1 = [5, 4, 5, 6, 3]\\ngroup2 = [1, 3, 2, 3, 2]\\nt, p = stats.ttest_ind(group1, group2, alternative=\\'two-sided\\')\\nprint(\"T-statistic:\" , t)\\nprint(\"P-value:\" , p)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 36, 'page_label': '37'}, page_content='However you are most likely going to ﬁnd yourself automatically calculating \\nthis value via some Python method or through a calculator. Is our p-value \\nless than our alpha of 0.05? Undoubtedly yes!\\nfrom scipy import stats\\ngroup1 = [5, 4, 5, 6, 3]\\ngroup2 = [1, 3, 2, 3, 2]\\nt, p = stats.ttest_ind(group1, group2, alternative=\\'two-sided\\')\\nprint(\"T-statistic:\" , t)\\nprint(\"P-value:\" , p)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 37, 'page_label': '38'}, page_content='Group A Group B\\n5 1\\n4 3\\n5 2\\n6 3\\n3 2\\nSo now that we’ve discovered that the difference between these two groups is signiﬁcant, we must \\nreject the null hypothesis that these two groups behave similarly.\\nThe change in our website appears to have caused a drop in average usage of our website. Can you \\nthink of any downsides to our collected data? Could we improve this experiment?\\nGroup A Avg = 4.6 Group B Avg = 2.2'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 38, 'page_label': '39'}, page_content='Applications to AB Testing'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 39, 'page_label': '40'}, page_content='AB Testing\\nWhat we just walked through is something called AB T esting. We do this when we \\nwant to check if a change to our website/product will lead to better “outcomes. ”\\nThis is where we split a sample of our users into two groups: the control (Group A) \\nand the experimental (Group B). We introduce Group B to a new iteration/version \\nof our website or product, while we keep Group A on the same platform.\\nWe then select one speciﬁc metric to measure such as click-through rate, amount \\npurchased, amount spent on website, or some other KPI which our \\nmanagers/stakeholders care about.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 40, 'page_label': '41'}, page_content='AB Testing\\nJust like in this previous example, we perform a t-test on these two groups \\nto check if the difference between these groups are statistically signiﬁcant.\\nHowever, just like we observed, we don’t want to just state that an update \\nto our product is preferable because the change is signiﬁcant. \\nWhat else must we be on the lookout for? Think back to our TKH Website \\nexample.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 41, 'page_label': '42'}, page_content='AB Testing - Additional Considerations\\nWe must be aware of many things when performing real-world \\nconﬁrmatory data analysis:\\n● In which direction is our change (positive or negative)? If this is a \\nbeneﬁcial change, is this effect large enough to spend $$$ on rolling \\nout this change?\\n● Have we run this A/B T est multiple times to account for false positives?\\n● Are we just observing the novelty effect?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 42, 'page_label': '43'}, page_content='Novelty Eﬀect\\nThe novelty effect describes a temporary boost or drop in metrics simply \\nbecause something is new.\\nPeople could just be spending more/exploring our website more because:\\n● They are getting used to the new interface (confused)\\n● A small change introduces some unpredictability which they look at \\nlonger (excited).\\nFor example, let’s say in order to boost Zoom engagement…'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 43, 'page_label': '44'}, page_content='… we make staff wear fun hats during the Zoom lecture. At ﬁrst you guys \\nmight say to yourselves “Woah whats this guys deal? I wonder what else he has \\nup his sleeve.” and we get a massive uptick in Zoom chat participation.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 44, 'page_label': '45'}, page_content='I might be tempted to bring this to my managers and state “Look, fun hats \\nboost engagement!” But after the second week, everyone gets bored of the \\nfun hats and Zoom chats drops down to previous levels. TKH’s investment \\nof $45 (4.99 * 9 staff) into the fun-hat fund has just been wasted.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 45, 'page_label': '46'}, page_content='Novelty Eﬀect - Patches \\nT o offset the novelty effect, we might want to consider:\\n● Run the test for a long-enough time to offset novelty \\n● Segment earlier results to check which results reﬂect novelty\\nT alk is cheap though, and experience is AB testing is only done through AB \\ntesting.\\nWe might try to run our own AB test in Phase 2…'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 46, 'page_label': '47'}, page_content='TLAB #3'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 47, 'page_label': '48'}, page_content=\"Lab (Due 5/14)\\nYou are a data engineer at a Brazil-based weather prediction startup called \\nCuru-Sight. The goal of this startup is to analyze weather trends in Brazil \\nand predict the output of non-durable consumer goods at harvest time.\\nYou will analyze a dataset that contains averages calculated based on \\nrainfall, temperature, humidity, and wind metrics collected during the coffee \\ngrowing season.\\nYou will also analyze a dataset that contains Minas Gerais' crop output. You \\nwill then combine these two datasets to explore how the weather \\ninﬂuences coffee growth.\\nMinas Gerais, Brazil\\nPlease ensure that your \\nEDA is completed \\nindependently.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'AB Testing', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\AB Testing.pdf', 'total_pages': 49, 'page': 48, 'page_label': '49'}, page_content='Thursday\\nOn Thursday we will be meeting for our review \\nsession. We will:\\n● Review GitHub \\n● Review TLAB #3\\n● Work together on TLAB #3\\nRemember!  Make this EDA your own. You can \\ndiscuss ﬁndings & documentation, but you \\ncannot share code.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Abstraction.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Abstraction.pptx.pdf', 'total_pages': 66, 'page': 0, 'page_label': '1'}, page_content='Advanced Abstraction'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Abstraction.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Abstraction.pptx.pdf', 'total_pages': 66, 'page': 1, 'page_label': '2'}, page_content='Agenda - Schedule\\n1. Warm-Up\\n2. OOP\\n3. Dataclasses\\n4. TLAB Rediscover the lost art of ﬁnding jobs on forums.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Abstraction.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Abstraction.pptx.pdf', 'total_pages': 66, 'page': 2, 'page_label': '3'}, page_content='Agenda - Goals\\n● Learn about the different coding paradigms and the utility of OOP\\n● Implement data classes in Python\\n● Learn about the distinction between classes and objects'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Abstraction.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Abstraction.pptx.pdf', 'total_pages': 66, 'page': 3, 'page_label': '4'}, page_content='Warm-Up'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Abstraction.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Abstraction.pptx.pdf', 'total_pages': 66, 'page': 4, 'page_label': '5'}, page_content='def modify(prices: dict, adjusted: ﬂoat) -> list:\\n    former = []\\nfor k in prices:\\n    former.append(prices[k])\\n    prices[k] *= (1 + adjusted)\\nreturn former \\nimports = {\\n    “RTX 3060”: 299.99,\\n    “1 kg coffee”: 6.102,\\n    “1 lb avocados”: 2.01,\\n    “Thinkpad X13”: 889.01,\\n}\\nresult = modify(imports, -0.06)\\nprint(imports)\\nJoin your pod groups and evaluate this chunk of code. Work together to \\nﬁgure out what will occur when we run this code.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Abstraction.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Abstraction.pptx.pdf', 'total_pages': 66, 'page': 5, 'page_label': '6'}, page_content='Phase 1 Recap'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Abstraction.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Abstraction.pptx.pdf', 'total_pages': 66, 'page': 6, 'page_label': '7'}, page_content='Course Goals - Abstract \\nIn the shallow sense of things, this fellowship aims to \\nteach you different skills that build off of each \\nother. In the abstract, the goals entail:\\nPhase 1: Learn how to engineer, pipeline, and \\ncollect\\nPhase 2: Learn how to analyze, predict, model, and \\ninnovate\\nPhase 3: Learn how to manage, collaborate, \\nvisualize, and inform'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Abstraction.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Abstraction.pptx.pdf', 'total_pages': 66, 'page': 7, 'page_label': '8'}, page_content='Stack & Heap'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Abstraction.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Abstraction.pptx.pdf', 'total_pages': 66, 'page': 8, 'page_label': '9'}, page_content='An Aside - Stack vs Heap\\nOften times, we have shown you this diagram \\nwithout an explanation. Let’s rectify this and \\nformally deﬁne a “stack” and “heap” , and \\nfurthermore deﬁne their differences. \\nStack: Memory set dedicated for local variables \\nand function calls.\\nHeap: Dynamic memory set with no deﬁned \\npattern of memory allocation/deallocation.\\nBoth the stack and heap exist in \\nyour RAM (random access \\nmemory).'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Abstraction.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Abstraction.pptx.pdf', 'total_pages': 66, 'page': 9, 'page_label': '10'}, page_content='An Aside - Stack\\nOur program utilizes the stack to keep \\ntrack of the order of function calls and \\ninitialize local variables that exist in \\nspeciﬁc function bodies.\\nNotice that each stack frame deﬁnes \\nvariables, their value, and which scope \\nthe variables are instantiated in.\\nThe name, “stack” , deﬁnes the \\nFirst-in-Last-out (FILO) structure \\nof this memory concept.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Abstraction.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Abstraction.pptx.pdf', 'total_pages': 66, 'page': 10, 'page_label': '11'}, page_content='An Aside - Heap\\nThe heap, on the other hand, does not use any \\nintrinsic pattern to “allocate/deallocate” \\n(create/delete) memory. \\nPython handles interaction with the heap \\nautomatically, so we do not have to worry about \\nthings like memory size or freeing up memory.\\nHowever, we should understand this concept to \\nhandle issues involving copies vs deep copies.\\nThe name, “heap” , deﬁnes the \\nunstructured nature of this \\nmemory concept.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Abstraction.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Abstraction.pptx.pdf', 'total_pages': 66, 'page': 11, 'page_label': '12'}, page_content='Abstraction'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Abstraction.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Abstraction.pptx.pdf', 'total_pages': 66, 'page': 12, 'page_label': '13'}, page_content='Conceptual OOP\\nNow that we’ve learned about various ways to store data, a challenge that you should \\nbe considering is “how do we associate and label these bits of data”? For example, \\nlet’s say we are developing an applicant tracking system. This will entail the storage of \\na variety of data-types whose purpose might get lost without sufﬁcient context.\\nfname = “Gustavo”\\njob = “Data Analyst”\\nreferences = [“Farukh” , “Mickal”]\\nWhile we could use data-structures to \\nsatisfy this, could you think how this \\ncould introduce its’ own complexity?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Abstraction.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Abstraction.pptx.pdf', 'total_pages': 66, 'page': 13, 'page_label': '14'}, page_content='Conceptual OOP - data_intake.py\\nInstead what we want to do is bundle all this \\ninformation in a neat package. We want to \\nabstract and encapsulate. AKA we want to \\ncreate a class.\\nBefore we get into this however, let’s go over \\nthe different types of programming \\nparadigms.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Abstraction.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Abstraction.pptx.pdf', 'total_pages': 66, 'page': 14, 'page_label': '15'}, page_content='Programming Paradigms\\nIt turns out that there are many different “styles” of programming aka programming \\nparadigms\\nImperative (aka von Neumann) \\n● Procedural: instructions are executed in strict order\\n● Object-Oriented: groups of objects change state\\nDeclarative  \\n● Functional: series of functional applications\\n● Logical: query-based programming\\n● Reactive: based on data streams and change \\n John von Neumann'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Abstraction.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Abstraction.pptx.pdf', 'total_pages': 66, 'page': 15, 'page_label': '16'}, page_content='Programming Paradigms - OOP\\nThe concept of abstraction (hide all \\nirrelevant details) and \\nencapsulation (bundling all data \\nand functions into one unit) using \\nclasses, objects, and methods.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Abstraction.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Abstraction.pptx.pdf', 'total_pages': 66, 'page': 16, 'page_label': '17'}, page_content='Dataclasses'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Abstraction.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Abstraction.pptx.pdf', 'total_pages': 66, 'page': 43, 'page_label': '44'}, page_content='Dataclass Operations'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Abstraction.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Abstraction.pptx.pdf', 'total_pages': 66, 'page': 60, 'page_label': '61'}, page_content='Lab'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Abstraction.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Abstraction.pptx.pdf', 'total_pages': 66, 'page': 61, 'page_label': '62'}, page_content='Lab - GitHub Module\\nFor the remaining lab time, break into your pod \\ngroups and complete the VSCode Unit 4: Lesson \\n1 - Lesson 3\\nWhen you complete this modules, work on your \\nTLAB with your pod.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Abstraction.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Abstraction.pptx.pdf', 'total_pages': 66, 'page': 62, 'page_label': '63'}, page_content='Wrap-Up'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Abstraction.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Abstraction.pptx.pdf', 'total_pages': 66, 'page': 63, 'page_label': '64'}, page_content='Lab (Due 03/28)\\nThe company you work for, Seng-Links, aims to identify periods when a user \\nsleeps or exercises using their varying recorded heart rates. \\nYour company has provided you a data folder (data/) of 4 ﬁles that contain \\nheart-rate samples from a participant. The participants device records heart \\nrate data every 5 minutes (aka sampling rate). \\nYou are tasked with writing code that processes each data ﬁle. You will \\nutilize test-driven development in order to complete this project.\\nTaipei City, Taiwan'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Abstraction.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Abstraction.pptx.pdf', 'total_pages': 66, 'page': 64, 'page_label': '65'}, page_content='Announcements\\nA couple of assignment-related announcements: \\n● Week 2 Pre-Class Quiz \\n○ Cohort B: due 3/22\\n○ Cohort A: due 3/19\\n● OOP Quiz (both cohorts due 3/22)\\n● Fellows waiting on loaner laptops: please monitor Slack\\n● Ofﬁce Hours are Open after class: Please bring questions!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Abstraction.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Abstraction.pptx.pdf', 'total_pages': 66, 'page': 65, 'page_label': '66'}, page_content=\"Tuesday\\nT omorrow will entail:\\n● Further exploration of OOP .\\nJupyter: scratchpad of the data \\nscientist\\nIf you understand what you're doing, you're \\nnot learning anything. - Anonymous\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Control Flow.pptx.pdf', 'total_pages': 93, 'page': 0, 'page_label': '1'}, page_content='Advanced Control Flow'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Control Flow.pptx.pdf', 'total_pages': 93, 'page': 1, 'page_label': '2'}, page_content='Agenda - Schedule\\n1. Warm-Up\\n2. Conditional Patterns\\n3. Loops\\n4. Loop Patterns\\n5. VSCode Lab \\nData engineering is the art of ingesting data without error.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Control Flow.pptx.pdf', 'total_pages': 93, 'page': 2, 'page_label': '3'}, page_content='Agenda - Goals\\n● Understand common logical patterns in Python\\n● Understand how to implement for loops\\n● Integrate for-loops with data structures'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Control Flow.pptx.pdf', 'total_pages': 93, 'page': 3, 'page_label': '4'}, page_content='Warm-Up'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Control Flow.pptx.pdf', 'total_pages': 93, 'page': 4, 'page_label': '5'}, page_content='def sleep_classiﬁer(length: ﬂoat, avg_bpm: int) -> str:\\nif length > 14 or avg_bpm > 100:\\n return “right-fence outliers”\\nelif length < 3 or avg_bpm < 30:\\n return  “left-fence outliers”\\nif length >= 6 and avg_bpm <= 70:\\nif avg_bpm >= 45 and avg_bpm <= 55:\\n return  “excellent”\\nelif avg_bpm > 55 and avg_bpm <= 65:\\n return  “good”\\nelse:\\n return  “fair”\\nelse:\\nif length < 6 and length >= 5:\\n return  “poor”\\nelse:\\n return  “abysmal”\\nreturn “unknown”\\nprint(sleep_classiﬁer(6.5, 66)) \\nprint(sleep_classiﬁer(2.3, 59)) \\nprint(sleep_classiﬁer(4.5, 61)) \\nJoin your pod groups and evaluate this chunk of code. Work together to \\nﬁgure out what will occur when we run this code.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Control Flow.pptx.pdf', 'total_pages': 93, 'page': 5, 'page_label': '6'}, page_content='def sleep_classiﬁer(length: ﬂoat, avg_bpm: int) -> str:\\nif length > 14 or avg_bpm > 100:\\n return “right-fence outliers”\\nelif length < 3 or avg_bpm < 30:\\n return  “left-fence outliers”\\nif length >= 6 and avg_bpm <= 70:\\nif avg_bpm >= 45 and avg_bpm <= 55:\\n return  “excellent”\\nelif avg_bpm > 55 and avg_bpm <= 65:\\n return  “good”\\nelse:\\n return  “fair”\\nelse:\\nif length < 6 and length >= 5:\\n return  “poor”\\nelse:\\n return  “abysmal”\\nreturn “unknown”\\nprint(sleep_classiﬁer(6.5, 66)) \\nprint(sleep_classiﬁer(2.3, 59)) \\nprint(sleep_classiﬁer(4.5, 61)) \\nIs it possible for this return expression to be evaluated? If so, which value \\nwill accomplish this?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Control Flow.pptx.pdf', 'total_pages': 93, 'page': 6, 'page_label': '7'}, page_content='You are a data analyst for a local state gov’t. \\nYou are tasked with reporting the outcome of a new piece of legislation \\nthat provides decreased taxes for businesses that open and hire at least \\n100 new positions within certain towns that have experienced population \\nloss.\\n4 years have passed since this tax break went into effect, and your team is \\ntasked with analyzing its outcome on population growth. You calculate \\ndifferences of 2020 and 2024 population in counties whose businesses \\nparticipated in this measure.\\nWhen calculating the descriptive statistics of this dataset, you discover \\nthat median == mode, while median < mean. What does this indicate about \\nthe distribution of outcomes?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Control Flow.pptx.pdf', 'total_pages': 93, 'page': 7, 'page_label': '8'}, page_content='Culture Contract'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Control Flow.pptx.pdf', 'total_pages': 93, 'page': 8, 'page_label': '9'}, page_content='Culture Contract \\nBefore we continue with DS technical content, we just want to brieﬂy direct \\nyour attention to the Culture Contract that we’re operating off of within \\nthis fellowship.\\nA major part of your success in this fellowship and your professional career \\nhinges on your ability to be a good team player.\\nWe want you to think of us as your coworkers. Therefore we will hold you to \\nthe same standards as we hold our coworkers and ourselves.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Control Flow.pptx.pdf', 'total_pages': 93, 'page': 9, 'page_label': '10'}, page_content='Culture Contract \\nBefore tomorrow, (if not today) take 10 minutes to read the Culture \\nContract and consider its implications for what communication looks like \\nfor us to you, you to us, and you to your peers.\\nThe successful technical workspace is as much a social enterprise as it is an \\nintellectual one.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Control Flow.pptx.pdf', 'total_pages': 93, 'page': 10, 'page_label': '11'}, page_content='Culture Contract  - Core Principles\\nWe ask for you to abide by the following principles:\\n● Be approachable, kind, and resolution-oriented\\n● Develop your capability to be an authority in the knowledge you hold\\n● Be driven by curiosity\\nAny behavior that contradicts this will be pointed out. Continued disregard \\nfor chieﬂy the ﬁrst principle can result in dismissal.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Control Flow.pptx.pdf', 'total_pages': 93, 'page': 11, 'page_label': '12'}, page_content='Culture Contract  - Example 1\\nY ou are working with disagrees with your analysis plan and proposes an \\nalternative. Do you…\\nA) Immediately call for their dismissal from the team/program\\nB) Ignore them and continue with your plan\\nC) Challenge them to duel by virtual combat\\nD) Consider and discuss the reasons one plan should be preferred over \\nanother'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Control Flow.pptx.pdf', 'total_pages': 93, 'page': 12, 'page_label': '13'}, page_content='Culture Contract  - Example 2\\nY ou are working with disagrees with your analysis plan and proposes an \\nalternative. Do you…\\nA) Immediately call for their dismissal from the team/program\\nB) Ignore them and continue with your plan\\nC) Challenge them to duel by virtual combat\\nD) Consider and discuss the reasons one plan should be preferred over \\nanother\\nRemember, you are not your code. You \\nare not your projects, you are you.\\nA rejection of your thought-stuff is not \\na rejection of your character.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Control Flow.pptx.pdf', 'total_pages': 93, 'page': 13, 'page_label': '14'}, page_content='Logical Patterns'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Control Flow.pptx.pdf', 'total_pages': 93, 'page': 41, 'page_label': '42'}, page_content='For Loops'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Control Flow.pptx.pdf', 'total_pages': 93, 'page': 42, 'page_label': '43'}, page_content='For Loops\\nWe introduced the concept of controlling the \\n“ﬂow” of your program by introducing \\nbranches via conditionals.\\nAnother concept that is fundamental to \\nprocessing data is iteration or looping.\\nPrograms cannot interact with more than one \\npiece of data at a time. Therefore, we must \\nintroduce syntax which can iterate over a \\nsequence of data.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Control Flow.pptx.pdf', 'total_pages': 93, 'page': 61, 'page_label': '62'}, page_content='For Loop Patterns'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Control Flow.pptx.pdf', 'total_pages': 93, 'page': 62, 'page_label': '63'}, page_content='Coding Patterns\\nAs we continue to learn more about various \\nsyntax, we will always follow it up with \\npatterns.\\nThere are many different ways to accomplish \\nthe same task in programming, however more \\noften than not, there is usually one speciﬁc \\n(and efﬁcient) pattern that we should follow.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Control Flow.pptx.pdf', 'total_pages': 93, 'page': 86, 'page_label': '87'}, page_content='In-Class Lab'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Control Flow.pptx.pdf', 'total_pages': 93, 'page': 87, 'page_label': '88'}, page_content='Lab - GitHub Module\\nFor the remaining lab time, break into your pod \\ngroups and complete the following modules:\\n● VSCode Unit 5: Lesson 1 - Lesson 3'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Control Flow.pptx.pdf', 'total_pages': 93, 'page': 88, 'page_label': '89'}, page_content='Wrap-Up'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Control Flow.pptx.pdf', 'total_pages': 93, 'page': 89, 'page_label': '90'}, page_content='Lab (Due 03/28)\\nThe company you work for, Seng-Links, aims to identify periods when a user \\nsleeps or exercises using their varying recorded heart rates. \\nYour company has provided you a data folder (data/) of 5 ﬁles that contain \\nheart-rate samples from a participant. The participants device records heart \\nrate data every 5 minutes (aka sampling rate). \\nYou are tasked with writing code that processes each data ﬁle. You will \\nutilize test-driven development in order to complete this project.\\nTaipei City, Taiwan'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Control Flow.pptx.pdf', 'total_pages': 93, 'page': 90, 'page_label': '91'}, page_content=\"Wednesday…\\nOn Wednesday we will go over:...\\n● How to ingest text data via Python.\\n● How to navigate your computer via both \\nrelative and full paths.\\n● Additional for loop patterns.\\n Jupyter: scratchpad of the data \\nscientist\\nIf you understand what you're doing, you're \\nnot learning anything. - Anonymous\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Control Flow.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Control Flow.pptx.pdf', 'total_pages': 93, 'page': 91, 'page_label': '92'}, page_content='Glossary'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 0, 'page_label': '1'}, page_content='Advanced Data \\nProcessing'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 1, 'page_label': '2'}, page_content='Agenda - Schedule\\n1. Warm-Up\\n2. Hierarchy of Data Needs\\n3. Data Formats & JSON\\n4. Break\\n5. Lab\\nJavaScript Object Notation (JSON) is an open-standard data \\nformat or interchange for semi-structured data. It is \\ntext-based and readable by humans and machines. \\nhttps://www.snowﬂake.com/guides/what-is-json'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 2, 'page_label': '3'}, page_content='Agenda - Goals\\n● Review the different data formats you will work with during the \\nfellowship\\n● Understand how to interpret a JSON ﬁle\\n● Get introduced to working with JSON ﬁles in Python'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 3, 'page_label': '4'}, page_content='Warm-Up'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 4, 'page_label': '5'}, page_content='def evaluate(obj) -> int:\\ncount = 0 \\nfor d in obj:\\ncount += 1\\nreturn count\\nobj = open(\"data.txt\")\\nprint(evaluate(obj))\\nWork together to ﬁgure out what will occur when we run this code.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 5, 'page_label': '6'}, page_content='Hierarchy of Data Needs - \\nReview'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 6, 'page_label': '7'}, page_content='Hierarchy of Data Needs\\nLet’s see how what we’ve learned \\n(and what we will learn) applies to \\nthis pyramid.\\nFirst let’s list off the hierarchies \\nagain…'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 7, 'page_label': '8'}, page_content='Hierarchy of Data Needs\\nThe data science process involves:\\n● Collecting data:\\n● Storing data:\\n● Exploring data:\\n● Aggregating data:\\n● Learning about data:\\nWe’ve learned about many different technologies/concepts. Can you name \\ntheir appropriate categories?\\nSQL\\nPython\\nsklearn keras\\nword2vec \\npandas'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 8, 'page_label': '9'}, page_content='Hierarchy of Data Needs\\n● Collecting data: Python\\n● Storing data: SQL\\n● Exploring data: pandas, SQL\\n● Aggregating data: pandas, SQL\\n● Learning about data: sklearn, keras, word2vec \\nRoughly speaking, these are the categories that each tool ﬁts into. For the \\nremainder of this fellowship, we will explore ways we can collect data using \\nthe base Python language.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 9, 'page_label': '10'}, page_content='Hierarchy of Data Needs\\nT ools are not the focus of this \\nfellowship. \\nThe tools you use might change from job \\nto job. \\nThe concepts however, will not change.\\nThe only way you can learn these \\nconcepts is by writing your own code.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 10, 'page_label': '11'}, page_content='https://madnight.github.io/githut/#/pull_requests/2023/4 This graph is a bit more applicable to web development than data science, however the idea remains the same: T echnologies are replaceable, skills are not.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 11, 'page_label': '12'}, page_content='Data engineering as it applies to basic data formats is an essential skill of \\ndata science (as we see above). Let’s get to know a few of these formats.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 12, 'page_label': '13'}, page_content='Data  Formats'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 13, 'page_label': '14'}, page_content='Data Formats\\nSo far, we’ve been loading in our data via the open() function.\\nHowever, are text ﬁles the only data format? \\nIf not, can you think of any examples of other forms of data? \\nThink about the forms of data you observe when browsing the internet.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 14, 'page_label': '15'}, page_content='Data Formats\\nData can exist in many different forms and \\nstructures. \\nThis includes websites, geo-data, and Web API’s.\\nAs data scientists, we should be able to ingest and \\nrestructure these forms of data.\\nOnly then can we easily apply statistical analysis & \\nmachine learning algorithms.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 15, 'page_label': '16'}, page_content='Most of our development work will entail ﬁguring out how we express the \\nconcept of a dog into a CSV ﬁle.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 16, 'page_label': '17'}, page_content='Data Formats\\nBefore learning about the different ways we \\ncan work with these data-ﬁles, let’s review \\nsome broad categories of data-formats\\n● Structured\\n● Semi-Structured\\n● Unstructured \\nWhat do you think is the difference amongst \\nthese 3 formats?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 17, 'page_label': '18'}, page_content='Data Formats\\n● Structured\\n○ Data adheres to a ﬁxed structure \\n● Semi-Structured\\n○ Structure varies, but is mostly \\nconsistent \\n● Unstructured \\n○ Data abides by no structure\\nCan you think of any examples of these 3 \\nformats?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 18, 'page_label': '19'}, page_content='Structured Data\\nIf your format is consistent across different ﬁles, \\nthis format is structured.\\nThis is the most convenient format, and often what \\nwe strive for in our work.\\nThis includes relational databases, \\ncomma-separated-value (CSV) ﬁles, \\ntab-separated-value (TSV) ﬁles'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 19, 'page_label': '20'}, page_content='All csv ﬁles are guaranteed to have structures (such as rows & columns), \\nregardless of the data it captures.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 20, 'page_label': '21'}, page_content='Semi-structured Data\\nIf your format is somewhat \\npredictable, but varies across ﬁles, this \\nformat is semi-structured.\\nWeb-data is often in this format.\\nThis includes JSON, Emails, XML, and \\nlog ﬁles.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 21, 'page_label': '22'}, page_content='JSON ﬁles have a predeﬁned set of objects, but there is no guarantee that \\nall these objects will appear in every ﬁle or if they will appear in the same \\norder.\\nNotice the difference between these two \\nﬁles…'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 22, 'page_label': '23'}, page_content='You might also be surprised to know that websites are a form of \\nsemi-structured data.\\nWebsites are just a stylized form of data!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 23, 'page_label': '24'}, page_content='Unstructured Data\\nLastly, if your format is completely \\nunpredictable, and is expressed in \\nbinary, this format is unstructured.\\nComplex objects are often in this \\nformat.\\nThis includes images, videos, BLOB \\nﬁles, etc'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 24, 'page_label': '25'}, page_content='Binary data that expresses some complex object is usually speciﬁc to some \\napplication. This data is usually not designed to interface with humans!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 25, 'page_label': '26'}, page_content='You might be thinking: “why do we need to bother ﬁguring out how to interact \\nwith other forms of data if we can only do stats on structured data-ﬁles.”\\nGuess what is the most common form of data format in the workplace: \\nstructured, semi-structured, or unstructured data?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 26, 'page_label': '27'}, page_content='The majority of data in the world is unstructured: \\nhttps://mitsloan.mit.edu/ideas-made-to-matter/tapping-power-unstructured-dat\\na \\nLimiting yourself to CSV ﬁles limits your ability to apply data science concepts.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 27, 'page_label': '28'}, page_content='You should be able to operate (and learn how to operate) in multiple \\nmediums'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 28, 'page_label': '29'}, page_content='JSON'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 29, 'page_label': '30'}, page_content='JSON Files\\nOne popular data format that we often use \\nwhen requesting data over the web are JSON \\nﬁles. \\nThe JavaScript-Object-Notation ﬁle is a way \\nto programmatically express information that \\ncan be easily interpreted by computers & \\nhumans.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 30, 'page_label': '31'}, page_content='In the most basic form, JSON ﬁles are pairings of keys and values.\\nWhich Python data-structure does this look like?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 31, 'page_label': '32'}, page_content='JSON ﬁles are composed of JSON objects which are denoted via the curly \\nbrackets “{}” . Note that objects can exist inside of keys!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 32, 'page_label': '33'}, page_content='As we’ve mentioned already, JSON objects are semi-structured. While there is some predictability regarding the ﬁle, structure can vary greatly.Notice that we can also have arrays in our JSON ﬁles as well.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 33, 'page_label': '34'}, page_content=\"The easy part is loading in the ﬁle. Notice that this syntax is largely the same as your File I/O syntax. We have an added structure called the “context manager” , however this does nothing new. Think of this as a convenient way to open your ﬁles without needing to explicitly close the ﬁle after opening.\\nimport json\\nwith open('spotify-api.json') as j:\\n    d = json.load(j)\\nprint(d)\\n    \\nContext manager.\\nUse this to replace:\\nj = open(“ ... ”)\\nj.close()\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 34, 'page_label': '35'}, page_content=\"Once we load in our JSON object, this is simply expressed as a Python \\ndata-structure.\\nLook at the outermost brackets, which data structure does this appear to \\nbe?\\nimport json\\nwith open('spotify-api.json') as j:\\n    d = json.load(j)\\nprint(d)\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 35, 'page_label': '36'}, page_content=\"A dictionary! \\nAnd since we can express this JSON object as a dictionary, we can also \\naccess it like a dictionary as well (using named keys). Let’s practice doing this \\nin the next few slides.\\nimport json\\nwith open('spotify-api.json') as j:\\n    d = json.load(j)\\nprint(d)\\n    \\nAccessing JSONs as \\ndictionaries could prove \\nchallenging as they are \\nusually multi-dimensional.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 36, 'page_label': '37'}, page_content='JSON Files\\nHowever, it’s also important to note that \\nJSON objects have slight differences from \\nPython objects:\\n● No comments allowed\\n● No single-quoted strings\\n● No trailing commas'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 37, 'page_label': '38'}, page_content='{\\n  \"added_at\": \"2024-11-19T02:31:08Z\",\\n  \"track\": {\\n  \"album\": {\\n    \"album_type\": \"album\",\\n    \"artists\": [\\n      {\\n        \"external_urls\": { \"spotify\": \"https://open.spotify.com/artist/7G1GBhoKtEPnP86X2PvEYO\"},\\n        \"href\": \"https://api.spotify.com/v1/artists/7G1GBhoKtEPnP86X2PvEYO\",\\n        \"id\": \"7G1GBhoKtEPnP86X2PvEYO\",\\n        \"name\": \"Nina Simone\",\\n        \"type\": \"artist\",\\n        \"uri\": \"spotify:artist:7G1GBhoKtEPnP86X2PvEYO\"\\n      }\\n    ],\\n    \"uri\": \"spotify:album:4bGiPtwVEKcXbXs7oKCMqD\"\\n}\\n     }\\n}\\nLet’s say we have the following JSON object loaded in as a Python dictionary (in a variable called songs). How can we access the value of added_at?\\nsongs[...]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 38, 'page_label': '39'}, page_content='{\\n  \"added_at\": \"2024-11-19T02:31:08Z\",\\n  \"track\": {\\n  \"album\": {\\n    \"album_type\": \"album\",\\n    \"artists\": [\\n      {\\n        \"external_urls\": { \"spotify\": \"https://open.spotify.com/artist/7G1GBhoKtEPnP86X2PvEYO\"},\\n        \"href\": \"https://api.spotify.com/v1/artists/7G1GBhoKtEPnP86X2PvEYO\",\\n        \"id\": \"7G1GBhoKtEPnP86X2PvEYO\",\\n        \"name\": \"Nina Simone\",\\n        \"type\": \"artist\",\\n        \"uri\": \"spotify:artist:7G1GBhoKtEPnP86X2PvEYO\"\\n      }\\n    ],\\n    \"uri\": \"spotify:album:4bGiPtwVEKcXbXs7oKCMqD\"\\n}\\n     }\\n}\\nWe simply utilize the name of the key itself inside of our square brackets. \\nThis gives us a value of \"2024-11-19T02:31:08Z\"\\nsongs[“added_at”]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 39, 'page_label': '40'}, page_content='{\\n  \"added_at\": \"2024-11-19T02:31:08Z\",\\n  \"track\": {\\n  \"album\": {\\n    \"album_type\": \"album\",\\n    \"artists\": [\\n      {\\n        \"external_urls\": { \"spotify\": \"https://open.spotify.com/artist/7G1GBhoKtEPnP86X2PvEYO\"},\\n        \"href\": \"https://api.spotify.com/v1/artists/7G1GBhoKtEPnP86X2PvEYO\",\\n        \"id\": \"7G1GBhoKtEPnP86X2PvEYO\",\\n        \"name\": \"Nina Simone\",\\n        \"type\": \"artist\",\\n        \"uri\": \"spotify:artist:7G1GBhoKtEPnP86X2PvEYO\"\\n      }\\n    ],\\n    \"uri\": \"spotify:album:4bGiPtwVEKcXbXs7oKCMqD\"\\n}\\n     }\\n}\\nWhat if we want to access the value of album_type? Can we simply use one \\nkey name to access this value, or do we need to write additional syntax?\\nsongs[...]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 40, 'page_label': '41'}, page_content='{\\n  \"added_at\": \"2024-11-19T02:31:08Z\",\\n  \"track\": {\\n  \"album\": {\\n    \"album_type\": \"album\",\\n    \"artists\": [\\n      {\\n        \"external_urls\": { \"spotify\": \\n\"https://open.spotify.com/artist/7G1GBhoKtEPnP86X2PvEYO\"},\\n        \"href\": \"https://api.spotify.com/v1/artists/7G1GBhoKtEPnP86X2PvEYO\",\\n        \"id\": \"7G1GBhoKtEPnP86X2PvEYO\",\\n        \"name\": \"Nina Simone\",\\n        \"type\": \"artist\",\\n        \"uri\": \"spotify:artist:7G1GBhoKtEPnP86X2PvEYO\"\\n      }\\n    ],\\n    \"uri\": \"spotify:album:4bGiPtwVEKcXbXs7oKCMqD\"\\n}\\n     }\\n}\\nFirst off, let’s note, does the album_type value simply exist in the top-most \\nkey-value pairs of this dictionary, is it nested?\\nsongs[...]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 41, 'page_label': '42'}, page_content='{\\n  \"added_at\": \"2024-11-19T02:31:08Z\",\\n  \"track\": {\\n  \"album\": {\\n    \"album_type\": \"album\",\\n    \"artists\": [\\n      {\\n        \"external_urls\": { \"spotify\": \"https://open.spotify.com/artist/7G1GBhoKtEPnP86X2PvEYO\"},\\n        \"href\": \"https://api.spotify.com/v1/artists/7G1GBhoKtEPnP86X2PvEYO\",\\n        \"id\": \"7G1GBhoKtEPnP86X2PvEYO\",\\n        \"name\": \"Nina Simone\",\\n        \"type\": \"artist\",\\n        \"uri\": \"spotify:artist:7G1GBhoKtEPnP86X2PvEYO\"\\n      }\\n    ],\\n    \"uri\": \"spotify:album:4bGiPtwVEKcXbXs7oKCMqD\"\\n}\\n     }\\n}\\nNotice that this value exists inside of a dictionary that is inside of our \\ndictionary. This means that we must use multiple key accesses to get to this \\nnested value!\\nsongs[“track”]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 42, 'page_label': '43'}, page_content='{\\n  \"added_at\": \"2024-11-19T02:31:08Z\",\\n  \"track\": {\\n  \"album\": {\\n    \"album_type\": \"album\",\\n    \"artists\": [\\n      {\\n        \"external_urls\": { \"spotify\": \"https://open.spotify.com/artist/7G1GBhoKtEPnP86X2PvEYO\"},\\n        \"href\": \"https://api.spotify.com/v1/artists/7G1GBhoKtEPnP86X2PvEYO\",\\n        \"id\": \"7G1GBhoKtEPnP86X2PvEYO\",\\n        \"name\": \"Nina Simone\",\\n        \"type\": \"artist\",\\n        \"uri\": \"spotify:artist:7G1GBhoKtEPnP86X2PvEYO\"\\n      }\\n    ],\\n    \"uri\": \"spotify:album:4bGiPtwVEKcXbXs7oKCMqD\"\\n}\\n     }\\n}\\nNext, we need to access the value of “album” which gives us the nested \\ndictionary. However, how can we need to dive deeper. How can we access \\nthe keys of the album dictionary?\\nsongs[“track”][“album”]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 43, 'page_label': '44'}, page_content='{\\n  \"added_at\": \"2024-11-19T02:31:08Z\",\\n  \"track\": {\\n  \"album\": {\\n    \"album_type\": \"album\",\\n    \"artists\": [\\n      {\\n        \"external_urls\": { \"spotify\": \"https://open.spotify.com/artist/7G1GBhoKtEPnP86X2PvEYO\"},\\n        \"href\": \"https://api.spotify.com/v1/artists/7G1GBhoKtEPnP86X2PvEYO\",\\n        \"id\": \"7G1GBhoKtEPnP86X2PvEYO\",\\n        \"name\": \"Nina Simone\",\\n        \"type\": \"artist\",\\n        \"uri\": \"spotify:artist:7G1GBhoKtEPnP86X2PvEYO\"\\n      }\\n    ],\\n    \"uri\": \"spotify:album:4bGiPtwVEKcXbXs7oKCMqD\"\\n}\\n     }\\n}\\nWe can add another level of bracket notation to access the keys of the \\nalbum dictionary. Which additional key should we use in order to get the \\nvalue of the “album_type” key? \\nsongs[“track”][“album”][...]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 44, 'page_label': '45'}, page_content='{\\n  \"added_at\": \"2024-11-19T02:31:08Z\",\\n  \"track\": {\\n  \"album\": {\\n    \"album_type\": \"album\",\\n    \"artists\": [\\n      {\\n        \"external_urls\": { \"spotify\": \"https://open.spotify.com/artist/7G1GBhoKtEPnP86X2PvEYO\"},\\n        \"href\": \"https://api.spotify.com/v1/artists/7G1GBhoKtEPnP86X2PvEYO\",\\n        \"id\": \"7G1GBhoKtEPnP86X2PvEYO\",\\n        \"name\": \"Nina Simone\",\\n        \"type\": \"artist\",\\n        \"uri\": \"spotify:artist:7G1GBhoKtEPnP86X2PvEYO\"\\n      }\\n    ],\\n    \"uri\": \"spotify:album:4bGiPtwVEKcXbXs7oKCMqD\"\\n}\\n     }\\n}\\nBy specifying album_type in the next key level, we can now ﬁnally extract \\n“album”\\nsongs[“track”][“album”][“album_type”]\\nConsider the workﬂow we just took:\\n● Note the top-most object we need to \\naccess\\n● Note the next layers we need to \\naccess to eventually get to our value \\n(this might be more than 1!)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 45, 'page_label': '46'}, page_content='{\\n  \"added_at\": \"2024-11-19T02:31:08Z\",\\n  \"track\": {\\n  \"album\": {\\n    \"album_type\": \"album\",\\n    \"artists\": [\\n      {\\n        \"external_urls\": { \"spotify\": \"https://open.spotify.com/artist/7G1GBhoKtEPnP86X2PvEYO\"},\\n        \"href\": \"https://api.spotify.com/v1/artists/7G1GBhoKtEPnP86X2PvEYO\",\\n        \"id\": \"7G1GBhoKtEPnP86X2PvEYO\",\\n        \"name\": \"Nina Simone\",\\n        \"type\": \"artist\",\\n        \"uri\": \"spotify:artist:7G1GBhoKtEPnP86X2PvEYO\"\\n      }\\n    ],\\n    \"uri\": \"spotify:album:4bGiPtwVEKcXbXs7oKCMqD\"\\n}\\n     }\\n}\\nLet’s see if we can work together to get the name value from this dictionary. \\nFirst off, what is the top-most object we need to access to start this process?\\nsongs[...]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 46, 'page_label': '47'}, page_content='{\\n  \"added_at\": \"2024-11-19T02:31:08Z\",\\n  \"track\": {\\n  \"album\": {\\n    \"album_type\": \"album\",\\n    \"artists\": [\\n      {\\n        \"external_urls\": { \"spotify\": \"https://open.spotify.com/artist/7G1GBhoKtEPnP86X2PvEYO\"},\\n        \"href\": \"https://api.spotify.com/v1/artists/7G1GBhoKtEPnP86X2PvEYO\",\\n        \"id\": \"7G1GBhoKtEPnP86X2PvEYO\",\\n        \"name\": \"Nina Simone\",\\n        \"type\": \"artist\",\\n        \"uri\": \"spotify:artist:7G1GBhoKtEPnP86X2PvEYO\"\\n      }\\n    ],\\n    \"uri\": \"spotify:album:4bGiPtwVEKcXbXs7oKCMqD\"\\n}\\n     }\\n}\\nJust like before, we need to ﬁrst access the track object and then album. \\nWhat is the next object that contains our name value?\\nsongs[“track”][“album”][...]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 47, 'page_label': '48'}, page_content='{\\n  \"added_at\": \"2024-11-19T02:31:08Z\",\\n  \"track\": {\\n  \"album\": {\\n    \"album_type\": \"album\",\\n    \"artists\": [\\n      {\\n        \"external_urls\": { \"spotify\": \"https://open.spotify.com/artist/7G1GBhoKtEPnP86X2PvEYO\"},\\n        \"href\": \"https://api.spotify.com/v1/artists/7G1GBhoKtEPnP86X2PvEYO\",\\n        \"id\": \"7G1GBhoKtEPnP86X2PvEYO\",\\n        \"name\": \"Nina Simone\",\\n        \"type\": \"artist\",\\n        \"uri\": \"spotify:artist:7G1GBhoKtEPnP86X2PvEYO\"\\n      }\\n    ],\\n    \"uri\": \"spotify:album:4bGiPtwVEKcXbXs7oKCMqD\"\\n}\\n     }\\n}\\nWe must then access artists. However notice that artists is not a dictionary \\nobject. T ake a look at the types of brackets that we’re using instead. What \\nkind of data structure is this?\\nsongs[“track”][“album”][“artists”]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 48, 'page_label': '49'}, page_content='{\\n  \"added_at\": \"2024-11-19T02:31:08Z\",\\n  \"track\": {\\n  \"album\": {\\n    \"album_type\": \"album\",\\n    \"artists\": [\\n      {\\n        \"external_urls\": { \"spotify\": \"https://open.spotify.com/artist/7G1GBhoKtEPnP86X2PvEYO\"},\\n        \"href\": \"https://api.spotify.com/v1/artists/7G1GBhoKtEPnP86X2PvEYO\",\\n        \"id\": \"7G1GBhoKtEPnP86X2PvEYO\",\\n        \"name\": \"Nina Simone\",\\n        \"type\": \"artist\",\\n        \"uri\": \"spotify:artist:7G1GBhoKtEPnP86X2PvEYO\"\\n      }\\n    ],\\n    \"uri\": \"spotify:album:4bGiPtwVEKcXbXs7oKCMqD\"\\n}\\n     }\\n}\\nThis is a list that could potentially store multiple artists. Since we have only \\none artist in this list, how do we access this one and only artist using bracket \\nnotation?\\nsongs[“track”][“album”][“artists”][...]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 49, 'page_label': '50'}, page_content='{\\n  \"added_at\": \"2024-11-19T02:31:08Z\",\\n  \"track\": {\\n  \"album\": {\\n    \"album_type\": \"album\",\\n    \"artists\": [\\n      {\\n        \"external_urls\": { \"spotify\": \"https://open.spotify.com/artist/7G1GBhoKtEPnP86X2PvEYO\"},\\n        \"href\": \"https://api.spotify.com/v1/artists/7G1GBhoKtEPnP86X2PvEYO\",\\n        \"id\": \"7G1GBhoKtEPnP86X2PvEYO\",\\n        \"name\": \"Nina Simone\",\\n        \"type\": \"artist\",\\n        \"uri\": \"spotify:artist:7G1GBhoKtEPnP86X2PvEYO\"\\n      }\\n    ],\\n    \"uri\": \"spotify:album:4bGiPtwVEKcXbXs7oKCMqD\"\\n}\\n     }\\n}\\nWe input the index value of 0 to access the ﬁrst and only dictionary in this \\nlist. Now that we’ve ﬁnally accessed the last dictionary object, how can we \\nget the name of this artist?\\nsongs[“track”][“album”][“artists”][0][...]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 50, 'page_label': '51'}, page_content='{\\n  \"added_at\": \"2024-11-19T02:31:08Z\",\\n  \"track\": {\\n  \"album\": {\\n    \"album_type\": \"album\",\\n    \"artists\": [\\n      {\\n        \"external_urls\": { \"spotify\": \"https://open.spotify.com/artist/7G1GBhoKtEPnP86X2PvEYO\"},\\n        \"href\": \"https://api.spotify.com/v1/artists/7G1GBhoKtEPnP86X2PvEYO\",\\n        \"id\": \"7G1GBhoKtEPnP86X2PvEYO\",\\n        \"name\": \"Nina Simone\",\\n        \"type\": \"artist\",\\n        \"uri\": \"spotify:artist:7G1GBhoKtEPnP86X2PvEYO\"\\n      }\\n    ],\\n    \"uri\": \"spotify:album:4bGiPtwVEKcXbXs7oKCMqD\"\\n}\\n     }\\n}\\nNow we can ﬁnally use the “name” key to get the value of Nina Simone.\\nsongs[“track”][“album”][“artists”][0][“name”]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 51, 'page_label': '52'}, page_content='JSON Files - Multidimensional Objects\\nRemember not to get lost in the complexity of \\ntrying to look at the entire object.\\nBreak the object down piece by piece and \\nnote which data-structure you are looking at \\nby observing the syntax of your brackets.\\n● Square-brackets: list, index position\\n● Curly-brackets: dictionary, key'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 52, 'page_label': '53'}, page_content='In today’s lab you will be interacting with a JSON object with multiple nested objects inside of an array. Let’s assume the code above gives us a list of dictionaries. If I wanted to programmatically loop through this list, which syntax should I write?\\nsongs[“items”]\\nHow will this for-loop look like?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 53, 'page_label': '54'}, page_content='We could implement a for-loop! Each “song” iterator variable will be \\nassigned to a dictionary object. How could we access the nested keys inside \\nof each dictionary we iterate through?\\nfor song in songs[“items”]:\\n…'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 54, 'page_label': '55'}, page_content='Conda/JSON Lab'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 55, 'page_label': '56'}, page_content='Lab - Conda\\nComplete your conda installation with the \\nremaining lab time.\\nThank you Dontaye & Lubna for pointing this \\nout. There is a 1-line error with the Conda \\nenvironment: please delete the “json” package \\nfrom the environment.yml ﬁle.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 56, 'page_label': '57'}, page_content='Lab - JSON\\nAfter completing the conda installation, \\ncomplete the JSON Lab.\\nWhile you will not be submitting this, we will call \\non random groups to answer some of the most \\nchallenging questions.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 57, 'page_label': '58'}, page_content='Wrap-Up'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 58, 'page_label': '59'}, page_content='Lab (Due 03/28)\\nThe company you work for, Seng-Links, aims to identify periods when a user \\nsleeps or exercises using their varying recorded heart rates. \\nYour company has provided you a data folder (data/) of 4 ﬁles that contain \\nheart-rate samples from a participant. The participants device records heart \\nrate data every 5 minutes (aka sampling rate). \\nYou are tasked with writing code that processes each data ﬁle. You will \\nutilize test-driven development in order to complete this project.\\nTaipei City, Taiwan'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 59, 'page_label': '60'}, page_content='Stats Quiz (Due 03/28)\\nPlease complete this quiz by 03/28.\\nThis is a 10-question quiz that will test \\nyour knowledge of statistics concepts.\\n2 attempts allowed.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced Data Processing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced Data Processing.pptx.pdf', 'total_pages': 61, 'page': 60, 'page_label': '61'}, page_content=\"Wednesday\\nWednesday will entail:\\n● A review of visualizing data\\n● How to use Matplotlib\\n● TLAB Work\\n Jupyter: scratchpad of the data \\nscientist\\nIf you understand what you're doing, you're \\nnot learning anything. - Anonymous\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 0, 'page_label': '1'}, page_content='Advanced SQL I'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 1, 'page_label': '2'}, page_content='Agenda - Schedule\\n1. SQL Leetcode Q\\n2. Window Functions\\n3. Break\\n4. COVID-19 SQL Lab\\n Database systems of the past'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 2, 'page_label': '3'}, page_content='Agenda - Announcements \\n● No pre-class quiz\\n● TLAB #3 due 5/14\\n○ Early grade due date: 5/7\\n○ Extension due date: 5/13\\n● In-class end of phase project is being released THIS THURSDAY! (We \\nrecommend attending this review session)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 3, 'page_label': '4'}, page_content='Agenda - Goals\\n● Use SQL window functions (ROW_NUMBER, RANK, DENSE_RANK, NTILE) to \\nanalyze and rank data within partitions.\\n● Apply LAG() and LEAD() functions to compare rows across a sequence.\\n● Use subqueries to calculate differences between values (e.g., current vs. \\nprevious order amounts).'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 4, 'page_label': '5'}, page_content='SQL Leetcode Q'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 5, 'page_label': '6'}, page_content='T ake 5-10 minutes to complete Customers Who Visited but Did Not Make Any Transactions: \\nhttps://leetcode.com/problems/customer-who-visited-but-did-not-make-any-transactions/description/?\\nenvType=study-plan-v2&envId=top-sql-50'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 6, 'page_label': '7'}, page_content='SQL Review'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 7, 'page_label': '8'}, page_content='SQL Overview/Review\\nEach column can have different types, here are some of the main ones:\\nINTEGER\\nVARCHAR(length) - this is equivalent to a Python string but we can set a maximum length\\nFLOAT\\nBOOL'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 8, 'page_label': '9'}, page_content='SQL Overview/Review\\nIn order to get data from our table we MUST \\nSELECT columns\\nFROM table\\nWhen it is just one table, we don’t need to specify \\nthe name\\nWhen we do joins, we need to specify the name if \\nthe columns names are shared\\nHowever, every table must be explicitly named'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 9, 'page_label': '10'}, page_content='SQL Overview/Review\\nWe can also alias columns and tables, so on the \\nright we could o\\nSELECT ﬁrst_name AS ﬁrst, \\n     last_name AS last\\nFROM Customers AS c'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 10, 'page_label': '11'}, page_content='SQL GROUP BY\\nWe use GROUP BY to combine (group) on column variables to get a result\\nThe below query could be\\nSELECT genre, \\nSUM(qty)\\nFROM books\\nGROUP BY genre\\nNote how the genre\\ncolumn “collapses”\\ninto the unique values\\nand that is added\\ntogether'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 11, 'page_label': '12'}, page_content='SQL Filtering\\nHAVING must be used with a GROUP BY \\nstatement, if we try to use HAVING\\nwithout GROUP BY we will get an error'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 12, 'page_label': '13'}, page_content='SQL JOINS'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 13, 'page_label': '14'}, page_content='SQL JOINS\\nWe join by using a Primary Key from one table \\nthat is stored as a Foreign Key in another table\\nHere - the Customers T able has a customer_id, this \\nis the primary key because it uniquely identiﬁes \\neach User\\nThe Orders table has the foreign key customer \\nbecause it relates to a foreign table: customer\\nWe connect the primary key ID on Customers to \\nOrders to get Customer Info on the order'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 14, 'page_label': '15'}, page_content='Window Functions'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 15, 'page_label': '16'}, page_content='Window Functions\\nThe idea behind window functions is that they look at our data in sliding \\n“windows”\\nThese windows can be time, categories, or more\\nThe general concept is:\\n- decide on what we want to do: SUM, RANK, etc;\\n- decide on group(s) to partition (group) on: state, user id, etc;\\n- decide on feature(s) to order by: time, amount, etc;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 16, 'page_label': '17'}, page_content='Notice that while this is similar to group-by, this is fundamentally a different \\nconcept!\\nGroup by squashes rows. Window functions keep individual rows!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 17, 'page_label': '18'}, page_content='Window Functions\\nWindow functions are one of the more \\ncomplicated parts of SQL but very \\npowerful\\nLet’s talk about their overall syntax ﬁrst:\\nPARTITION BY = group by, this is the \\ncategory we are interested in measuring\\nORDER BY = the sorting order, very \\nimportant! this will determine the order \\nof data\\nSELECT * ,\\nCOUNT(customer_id)  OVER (PARTITION BY country \\nORDER BY age) AS running_total \\nFROM Customers;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 18, 'page_label': '19'}, page_content='Window Functions\\nWe want the total customers by \\ncountry, as we order by customer_id\\nthis gives us a running total of \\ncustomers over as we move forward in \\nthe age column\\nNote that we usually do this over a \\ndate column to calculate a “running \\ntotal. ”\\nSELECT * ,\\nCOUNT(customer_id)  OVER (PARTITION BY country \\nORDER BY age) AS running_total \\nFROM Customers;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 19, 'page_label': '20'}, page_content='Example Window Functions'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 20, 'page_label': '21'}, page_content='ORDER BY vs PARTITION BY\\nWe can treat ORDER BY and PARTITION BY as our “windows”\\nThe partition window says “I am interested in the change by category”\\nThe order by window says “I am interested in the change by order”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 21, 'page_label': '22'}, page_content='ORDER BY vs PARTITION BY\\nThe partition window says “I am interested in the change by category”\\n- It works similar to a group by function\\n- by itself, it is not super powerful but we combine this with order by\\nThe order by window says “I am interested in the change by order”\\n- do this calculator in a speciﬁc way\\n- by start date/time is common as well as by value amount'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 22, 'page_label': '23'}, page_content='Ranking Window Functions'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 23, 'page_label': '24'}, page_content='Ranking Functions\\nThe power of window functions also lies in ranking functions\\nThings like ROW_NUMBER, RANK, DENSE_RANK, and so on\\nThese functions allow us to know how our data is distributed, attach ranks \\nto them, and use them in creative ways\\nWe can now rank our data by our partition in a particular order which can let \\nus answer questions like\\n“What is the longest ride by station?”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 24, 'page_label': '25'}, page_content='Diﬀerent Ranking Functions\\nWe’ll cover the main functions:\\nROW_NUMBER()\\nRANK()\\nDENSE_RANK()\\nNTILE()'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 25, 'page_label': '26'}, page_content='Diﬀerent Ranking Functions\\nWe’ll cover the main functions:\\nROW_NUMBER()\\n- every time has a unique row \\nnumber with no gaps or \\nduplicates\\nRANK()\\nDENSE_RANK()\\nNTILE()'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 26, 'page_label': '27'}, page_content='Diﬀerent Ranking Functions\\nWe’ll cover the main functions:\\nROW_NUMBER()\\nRANK()\\n- Items are ranked and we are \\nallowing ties\\n- we will skip numbers in the \\nevent of ties\\nDENSE_RANK()\\nNTILE()'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 27, 'page_label': '28'}, page_content='Diﬀerent Ranking Functions\\nWe’ll cover the main functions:\\nROW_NUMBER()\\nRANK()\\nDENSE_RANK()\\n- similar to rank where we \\nallow for ties \\n- we do not skip numbers \\nhowever, even in the event of \\na tie\\n- once tie ends, we go to the \\nnext number\\nNTILE()'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 28, 'page_label': '29'}, page_content='Diﬀerent Ranking Functions\\nWe’ll cover the main functions:\\nROW_NUMBER()\\nRANK()\\nDENSE_RANK()\\nNTILE(n)\\n- will divide the data into n \\neven groups\\n- will provide rank based on \\norder of aggregation (1 is \\nalways ﬁrst so choose ORDER \\nBY DESC/ASC appropriately)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 29, 'page_label': '30'}, page_content='Diﬀerent Ranking Functions\\nNotice that when you do a rank \\ncombined with a PARTITION it will \\nrank each individual partition \\nSo it is important to properly deﬁne \\nyour partitions\\nGenerally, you will not ORDER BY a \\ngroup that you are partitioning by\\nSELECT Studentname,\\n   Subject,\\n   Marks,\\n   RANK() OVER(PARTITION BY Studentname ORDER BY Marks DESC) Rank\\nFROM ExamResult\\nORDER BY Studentname,\\n     Rank;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 30, 'page_label': '31'}, page_content='LAG/LEAD Window Function'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 31, 'page_label': '32'}, page_content='LAG and LEAD\\nLAG and LEAD are some of the more complicated window functions\\nThe idea is we are now interested in getting the data to interact with each other\\nMaybe we have data on a week-by-week basis and we want to calculate change\\nWe would do a LAG function where we subtract our current row with the row prior\\nLet’s ﬁrst talk about how LAG/LEAD functions look then how we might implement'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 32, 'page_label': '33'}, page_content='LAG and LEAD\\nSELECT ID, value, sale_year,\\n  LAG(value)\\n    OVER(\\n      PARTITION BY ID\\n      ORDER BY year\\n    ) AS prev_value\\nFROM sales;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 33, 'page_label': '34'}, page_content='LAG and LEAD\\nSELECT\\n   toy_name, month, \\nsale_value,\\n   LEAD(sale_value) \\nOVER(PARTITION BY toy_name \\nORDER BY month)\\n     AS next_month_value\\nFROM toys_sale;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 34, 'page_label': '35'}, page_content='LAG and LEAD\\nWhen it comes to lag and lead, the limit is really your creativity\\nJust understand that it looks at periods before or periods after\\nThere are a number of use cases like differences, averages, comparisons, etc;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 35, 'page_label': '36'}, page_content='For example, let’s say we want to compare differences in order size across \\neach order id. We could potentially implement the following. While we \\ncannot perform additional arithmetic, which SQL operation can we \\nintroduce to perform additional manipulation of this resultant table?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 36, 'page_label': '37'}, page_content='As we learned last week, we could introduce this query as a subquery of a \\nanother query to quickly calculate the difference between the current \\namount and the previous order amount column.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 37, 'page_label': '38'}, page_content='Window Function Nuance'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 38, 'page_label': '39'}, page_content='ROWS PRECEDING AND ROWS FOLLOWING\\nSomething to note is you may see something like “ROWS PRECEDING” and “ROWS \\nFOLLOWING”\\nThis is used to determine larger sliding windows\\nYou may also see “ROWS BETWEEN UNBOUNDED PRECEDING AND 2 FOLLOWING”\\nor “ROWS BETWEEN 2 PRECEDING AND UNBOUNDED FOLLOWING”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 39, 'page_label': '40'}, page_content='ROWS PRECEDING AND ROWS FOLLOWING\\nThis simply determines our sliding window\\nThis could be useful if we’re doing things like \\nmoving averages\\nSee how this impacts our partition:'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 40, 'page_label': '41'}, page_content='Window Functions - SQL \\nCOVID-19'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 41, 'page_label': '42'}, page_content='SQL\\nT o practice using LAG functions, check out the following COVID-19 Case \\nStudy'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf', 'total_pages': 43, 'page': 42, 'page_label': '43'}, page_content='Tuesday\\nSQL + Python\\n● How do we design a database?\\n● How do we use SQLite in the command \\nline?\\n● How do we use SQLite in Python?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 0, 'page_label': '1'}, page_content='Advanced SQL II'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 1, 'page_label': '2'}, page_content='Agenda - Schedule\\n1. SQL Leetcode Q\\n2. Understanding Entity Relationship Diagrams\\n3. Using SQLite in Python\\n4. Break\\n5. SQLite Lab\\nDatabase systems of the past'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 2, 'page_label': '3'}, page_content='Agenda - Announcements \\n● No pre-class quiz\\n● TLAB #3 due 5/14\\n○ Early grade due date: 5/7\\n○ Extension due date: 5/13\\n● In-class end of phase project is being released THIS THURSDAY! (We \\nrecommend attending this review session)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 3, 'page_label': '4'}, page_content='Agenda - Goals\\n● Interpret ERD Diagrams.\\n● Connect to a SQLite database using Python.\\n● Create a table and insert data into it.\\n● Run simple SQL queries from Python to explore data.\\n● Print and interpret results returned by the database.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 4, 'page_label': '5'}, page_content='SQL Leetcode Q'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 5, 'page_label': '6'}, page_content='T ake 10 minutes to complete “Find Customer Referee”: \\nhttps://leetcode.com/problems/ﬁnd-customer-referee/description/?envTy\\npe=study-plan-v2&envId=top-sql-50'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 6, 'page_label': '7'}, page_content='Entity Relationship Diagrams\\n(ERDs)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 7, 'page_label': '8'}, page_content='Entity Relationship Diagram (ERD)\\nThis previous week, we learned that we often store \\nmultiple tables in one database. \\nLike we discussed, we abide by this structure due to \\nthe principles of normalization to ensure that we have \\ndata integrity.\\nOne way to visualize the relationship of these tables is \\nthrough an Entity Relationship Diagram\\nWhy might we want to keep \\ntrack of the structure of our \\ndatabase visually? What might \\nthis help us with?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 8, 'page_label': '9'}, page_content='What is an ERD?\\nAn Entity Relationship Diagram (ERD) is a visual representation of the \\nrelationships among entities in a database. Let’s iron out some deﬁnitions of an \\nERD:\\n● Entities: Represented by rectangles and are the objects we are interested \\nin keeping information on (e.g., Customer, Product, Student). Rows of a table.\\n● Attributes: Characteristics of entities (e.g., CustomerID, ProductName). \\nColumns of a table.\\n● Relationships: Connections between entities, indicating how they are \\nrelated.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 9, 'page_label': '10'}, page_content='Note how attributes are listed under an entity, and we connect entities via \\ndifferent types of relationships.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 10, 'page_label': '11'}, page_content='ERD Relationships/Cardinality\\nWhile notation for these types of relationships vary, they \\ngenerally describe the following:\\n● One-to-One (Zero or one): One entity is strictly associated \\nwith one entity (ex: one SSN per person, and one person per \\nSSN)\\n● One-to-Many: One object can be associated with many \\nother objects (ex: one person can have multiple orders, but \\none order can only have one person)\\n● Many-to-Many: Multiple objects can be associated with \\nmultiple other objects (ex: one student can take multiple any \\ncourses, and one course can have multiple students)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 11, 'page_label': '12'}, page_content='For example, in this diagram the User to UserStatsPicks entities is one (or \\nzero) to many. In other words, one user can have many stats picks, but one \\nstats picks can only have one user.\\nSee if you could interpret the \\nrelationship between other \\nentities, such as \\nHockeyT eam to \\nHockeyGame; GameScores \\nto HockeyGame; \\nHockeyT eam to \\nHockeyT eamPlayer.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 12, 'page_label': '13'}, page_content='ERD Keys\\nT o sufﬁciently discuss ERD diagrams, we should also \\ncontinue our discussion of primary/foreign keys.\\nPrimary Keys are a unique identiﬁer for each object in a \\ntable. It distinguishes one record from another within the \\nsame relation.\\nForeign Keys are a column in a database table that is used \\nto establish a link between two tables. It creates a \\nrelationship by referencing the primary key of another \\ntable.\\nNote that TrackID shows up as a Primary Key \\nin the “Track” table and a foreign key in the \\n“Race” table.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 13, 'page_label': '14'}, page_content='ERD Diagrams allow us to document and understand the structure of a database. Additionally it also \\nallows us to anticipate the types of JOINS that we will perform when we are querying our database.\\nFor example, let’s take a look at the ERD diagram above. If we would like to get all available \\ninformation on a Book and its Author, which tables should we join and on which columns should we \\nbe performing this join?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 14, 'page_label': '15'}, page_content='We can join the Book and Author table on the “b.AuthorName” foreign key \\nand “a.Name” primary key. Using the ERD diagram relationship symbols, we \\ncan also state the relationship between these two tables. Can one author \\nhave more than one book?\\nSELECT *\\nFROM Book b JOIN Author a\\nON b.AuthorName = a.Name\\n;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 15, 'page_label': '16'}, page_content='Yes! But also, note that an author can have zero books as well. If we want to \\npreserve authors who have zero books in this query, what kind of join can \\nwe use?\\nSELECT *\\nFROM Book b JOIN Author a\\nON b.AuthorName = a.Name\\n;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 16, 'page_label': '17'}, page_content='As we discussed in previous lessons, the LEFT JOIN ensures that we keep \\nAuthors who have not published any books (aka rows that result in null \\nvalues). \\nSELECT *\\nFROM Book b LEFT JOIN Author a\\nON b.AuthorName = a.Name\\n;'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 17, 'page_label': '18'}, page_content='Using SQLite in Python'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 18, 'page_label': '19'}, page_content='SQLite + Python\\nLike we established last week, relational database management is tantamount for \\ncontemporary tech-stacks as they provide a central system for storing & \\nquerying data. This includes:\\n● Storage of massive amounts of data\\n● Access via a query language\\n● Durability even during power failures\\n● Allow multiple users to interact with data\\nBut how do we actually go about implementing this technology in the context of \\neverything we’ve learned so far? T o accomplish this, we will use SQLite.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 19, 'page_label': '20'}, page_content='Like we established, there exist different ﬂavors of SQL. We might opt for \\nPostgreSQL for vector-database support, MySQL for typical LAMP \\napplications. However SQLite is a perfect package for non-server database \\nbased approaches.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 20, 'page_label': '21'}, page_content='SQLite + Python\\nWhile almost all other SQL approaches require you to set up a database \\nserver, SQLite is special in the sense that is natively supported in Python \\nand stores the database within a lightweight local ﬁle.\\nSimply import the sqlite3 package in your Python module to get started!\\nBefore we run through an example, let’s consider if a Python module or \\nJupyter notebook is appropriate for this exercise…'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 21, 'page_label': '22'}, page_content='Choosing the Right Tool\\nRemember! Part of being a good technologist is being able to discern which tools \\nare right for a speciﬁc task.\\nFollow this rule of thumb: \\n● Python Modules: Any functionality that should be run automatically (on a \\nschedule) or integrated into a larger system.\\n● Jupyter Notebooks: Making tutorials, reports, or code that you will share \\nwith a non-technologist stakeholder.\\nGiven these slides from “ Applied Rest APIs I” , which tool should we opt for in this \\ncase?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 22, 'page_label': '23'}, page_content='We will often integrate SQL -adjacent packages in our ETL pipelines which \\nshould be run on a scheduled and consistent basis. Therefore, let’s utilize \\nPython modules for this exercise.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 23, 'page_label': '24'}, page_content='Within the sqlite_intro folder let’s access query_db.py to ﬁnd out how we \\ncan run SQL in Python.\\nimport sqlite3\\nconn = sqlite3.connect(\"Fellowship.db\")\\ncursor = conn.cursor()\\ncursor.execute(“SELECT * FROM fellows;”)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 24, 'page_label': '25'}, page_content='We establish our connection to the database using the connect() method. \\nWe supply the path to an already created database ﬁle called \\n“Fellowship.db. ”\\nimport sqlite3\\nconn = sqlite3.connect(\"Fellowship.db\")\\ncursor = conn.cursor()\\ncursor.execute(“SELECT * FROM fellows;”)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 25, 'page_label': '26'}, page_content='Even though we established a connection, we still cannot read from the \\ndatabase until we create a cursor. This object allows us to execute SQL \\nstatements and fetch results from the database itself.\\nimport sqlite3\\nconn = sqlite3.connect(\"Fellowship.db\")\\ncursor = conn.cursor()\\ncursor.execute(“SELECT * FROM fellows;”)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 26, 'page_label': '27'}, page_content='Finally, we can begin sending SQL statements in the form of a string to our database via the execute() method. Note that this requires a bit of context-switching (sort of like inserting Russian statements in the middle of an essay written in English). This is generally considered a bad-practice, but we will opt for this for lack of better tools (for now). \\nimport sqlite3\\nconn = sqlite3.connect(\"Fellowship.db\")\\ncursor = conn.cursor()\\ncursor.execute(“SELECT * FROM fellows;”)\\nAdditionally note that you \\nmust be conﬁdent that \\nyour SQL statement is \\ncorrect before writing out \\nyour query. This adds an \\nadditional challenge to \\nour development.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 27, 'page_label': '28'}, page_content='We can make our SQL statements look like idiomatic SQL by introducing \\ntriple-quoted strings. This allows us to write strings across multiple lines.\\ncursor.execute(“””\\nSELECT *\\nFROM fellows;\\n“””)\\nrows = cursor.fetchall()\\nprint(rows)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 28, 'page_label': '29'}, page_content='More importantly however, let’s focus on the output that is provide from our the statement that we just executed. Note that we get the entire output using the fetchall() method. We can have the result of this method call in a variable and print it out. What kind of data-structure does this provide?\\ncursor.execute(“””\\nSELECT *\\nFROM fellows;\\n“””)\\nrows = cursor.fetchall()\\nprint(rows)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 29, 'page_label': '30'}, page_content='Note that we have a list of tuples! Printing out the entire list is insufﬁcient \\nto properly view the data. If we wanted to iterate through each element of \\nthe list, and print out each tuple on a separate line, what kind of Python \\nsyntax can we write?\\ncursor.execute(“””\\nSELECT *\\nFROM fellows;\\n“””)\\nrows = cursor.fetchall()\\nprint(rows)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 30, 'page_label': '31'}, page_content='Since we save our list to a variable, we could instead iterate through this list \\nusing a for loop to cleanly print out our data!\\ncursor.execute(“””\\nSELECT *\\nFROM fellows;\\n“””)\\nrows = cursor.fetchall()\\nfor r in rows:\\nprint(r)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 31, 'page_label': '32'}, page_content='Now that we understand the syntax of running SQL statements in Python, let’s try a few exercises out! How can we output all fellows who spent less than 10 hours on Canvas using a SQL statement? Look to the triple-quoted string in the Python module above to ﬁnd out more about the columns.\\ncursor.execute(“””\\n…\\n“””)\\nrows = cursor.fetchall()\\nprint(rows)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 32, 'page_label': '33'}, page_content='Making Changes to a DB in \\nPython'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 33, 'page_label': '34'}, page_content='Making Changes\\nWhile we went over running simple DML queries using sqlite3, how can we \\neffectively commit a change to our database from Python?\\nBefore we go over this syntax, let’s recall the types of DDL queries that we \\ncan make, starting with the CREATE clause.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 34, 'page_label': '35'}, page_content='T aken from the Azure DP-900 prep'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 35, 'page_label': '36'}, page_content='SQL - Logical Groups - DDL\\n CREATE TABLE Product (\\nID INT PRIMARY KEY ,\\nNAME VARCHAR(20) NOT NULL,\\nPRICE DECIMAL DEFAUL T 0.0\\n);\\nPRIMARY_KEY: uniquely \\nidentiﬁes the sample (row)\\nFOREIGN_KEY: this row is \\nconnected to another table\\nNOT NULL means the value \\nmust NOT be empty (null)\\nDEFAULT gives a default value \\nif nothing is put in during \\ninsertion'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 36, 'page_label': '37'}, page_content='Given the previous DDL statement, we can simply include the CREATE \\nTABLE clause in a triple-quoted string within the execute method, but note \\nthat we did not actually make any changes to our database just yet!\\ncursor.execute(“””\\nCREATE TABLE IF NOT EXISTS staff (\\n    stafﬁd INTEGER PRIMARY KEY,\\n    ﬁrst_name TEXT,\\n    last_name TEXT,\\n    trackid INTEGER,\\n    age INTEGER\\n);\\n“””)\\nconn.commit()'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 37, 'page_label': '38'}, page_content='Just like with git, we must commit any DDL query to the connection if we \\nwould like these changes to be reﬂected! Without a commit the database is \\nleft unmodiﬁed. \\ncursor.execute(“””\\nCREATE TABLE IF NOT EXISTS staff (\\n    stafﬁd INTEGER PRIMARY KEY,\\n    ﬁrst_name TEXT,\\n    last_name TEXT,\\n    trackid INTEGER,\\n    age INTEGER\\n);\\n“””)\\nconn.commit()'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 38, 'page_label': '39'}, page_content='SQLite Lab'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 39, 'page_label': '40'}, page_content='SQL\\nComplete the module lab_part1.py and lab_part2.py modules for the \\nremainder of the lab time'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Advanced SQL II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL II.pptx.pdf', 'total_pages': 41, 'page': 40, 'page_label': '41'}, page_content='Wednesday\\nSQL Leetcode Review\\n● Another Leetcode day! (pray that it \\ndoesn’t go down)\\n● We’ll hold off on Machine Learning until \\nPhase 2'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 0, 'page_label': '1'}, page_content='Review of Applied Large \\nLanguage Models'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 1, 'page_label': '2'}, page_content=\"Agenda - Schedule\\n1. Kahoot\\n2. Vector DB + RAG Review\\n3. Fine-Tuning Review\\n4. Break\\n5. Agents Introduction\\n “It's not enough to learn a lot; one \\nalso has to manage what one learns.”\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 2, 'page_label': '3'}, page_content='Agenda - Goals\\n● Understand what AI Agents are and how they differ from standalone \\nLLMs. \\n● Explain how RAG enhances factual accuracy by grounding responses in \\nexternal knowledge. \\n● Demonstrate how agents can orchestrate between direct generation and \\nRAG-based  retrieval. \\n● Implement a simple agent that decides when to query a vector database. \\n● Recognize the advantages of combining agents with RAG (ﬂexibility, \\naccuracy,  extensibility).'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 3, 'page_label': '4'}, page_content='Kahoot'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 4, 'page_label': '5'}, page_content='Let’s begin todays Kahoot'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 5, 'page_label': '6'}, page_content='Practical Considerations of AI \\nImplementations in Today’s \\nWorkplace'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 6, 'page_label': '7'}, page_content='Transformer Shortcomings\\nLet’s identity and recap the central ideas of the auxiliary technologies we discussed \\nlast week. Namely we demonstrated how we could implement:\\n● Vector databases: …\\n● Retrieval Augmented Generation: …\\n● Fine-Tuning: …\\nCan anyone summarize what these technologies actually do? Picture this being an \\ninterview question.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 7, 'page_label': '8'}, page_content='Transformer Shortcomings\\nLet’s identity and recap the central ideas of the auxiliary technologies we discussed \\nlast week. Namely we demonstrated how we could implement:\\n● Vector databases: A database of vector embeddings to efﬁciently extract semantic \\ninformation from some unstructured ﬁle.\\n● Retrieval Augmented Generation: Adding context to a basic prompt to inform \\nanswers.\\n● Fine-Tuning: updating the models weights to point answers towards sentiment, \\nanswers, and format.\\nBut why? What did these tools add to basic LLMs that augmented their capabilities? \\nFirst let’s identify the shortcomings of transformers.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 8, 'page_label': '9'}, page_content='Transformer Shortcomings\\nAs we identiﬁed in W9D2, the innate structure of transformers lead to the \\nfollowing issues:\\n● Because attention is distributed across tokens, vague or lengthy \\nprompts dilute relevance. Longer prompts -> worse outcome.\\n● Context windows are ﬁnite. LLMs can’t “remember” an unlimited \\nnumber of past interactions. \\n● Be mindful that attention cannot \"reason\" step-by-step unless guided.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 9, 'page_label': '10'}, page_content='Transformer Shortcomings\\nThese architectural limitations lead to the following problems:\\nDistributed Attention\\n● Answers become generic or unfocused.\\n● Irrelevant parts of the prompt may get over-weighted leading to hallucinations.\\nFinite Context Windows\\n● In long conversations, the model may contradict earlier statements (to the detriment of individuals \\nusing LLMs as romantic partners)\\n● Long documents or transcripts can’t be fully processed without chunking/summarization.\\n● Limits the model’s usefulness for tasks that require persistent memory.\\nAttention Can’t Step-by-Step Reason\\n● Math, logic puzzles, or multi-step problem solving often fail without structured prompting.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 10, 'page_label': '11'}, page_content='Notably these leads to issues surrounding tasks that require long-term \\nplanning such as running a business or even playing text-adventure games.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 11, 'page_label': '12'}, page_content='Transformer Shortcomings - Potential Solutions\\nWhile the transformer was a huge progression in artiﬁcial intelligence, we \\ncan state that just using this architecture to reason and automate problems \\nis insufﬁcient. \\nIn fact, there is quite a lot of contemporary ﬁndings that state…\\n● …95% of AI enterprise projects fail (Fortune)\\n● …80% of companies using AI don’t experience productivity gains \\n(NY-Times)\\n● …AI projects that do get deployed to software teams lead to 19% \\ndecrease in efﬁciency (Metr)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 12, 'page_label': '13'}, page_content='Transformer Shortcomings - Potential Solutions\\nHowever, this doesn’t mean that AI is totally useless, this might just indicate \\nwe’re not taking practical considerations seriously (which tends to happen \\nduring any hype-cycle).\\nFundamentally, complex data science projects have historically always seen \\nmassive failure rate. “87% of data science projects never make it into \\nproduction” - VentureBeat AI (2019).\\nIn fact, if we look closely at the previous links, we can see stories of success.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 13, 'page_label': '14'}, page_content='We should be cautious when going off of anecdotal evidence, but there are a \\nfew throughlines in these reported success stories: focus on an ideal metric, \\naugment (but don’t replace) human autonomy'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 14, 'page_label': '15'}, page_content='Transformer Shortcomings - Potential Solutions\\nFor today’s class, we will hone in on how we can utilize last weeks \\ntechnologies to ideally solve one these issues:\\n● Vector databases: A database of vector embeddings to efﬁciently extract semantic \\ninformation from some unstructured ﬁle.\\n● Retrieval Augmented Generation: Adding context to a basic prompt to inform \\nanswers.\\n● Fine-Tuning: updating the models weights to point answers towards sentiment, \\nanswers, and format.\\nBefore we review these topics, let’s do a little forward-thinking to see what other AI \\nprogressions are actually on the horizon.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 15, 'page_label': '16'}, page_content='Post Transformer Research\\nA couple of potentially big ideas (with varying levels of implementation) that are catching on within \\nmassive multi-billion dollar companies include:\\n● Quantized Models: Shrink AI models by storing numbers in fewer bits, making them faster \\nand cheaper to run with only a small drop in accuracy. (Bitnet)\\n● Diffusion Language models: Already the backbone of generating images, sounds, or text by \\nstarting with random noise and gradually “denoising” it until a realistic output appears. \\nUtilize for text generation. (Mercury)\\n● Hierarchical Reasoning Model: Break down complex problems into smaller steps or layers \\nof reasoning, a bit like solving a puzzle one piece at a time. (Sapient Intelligence)\\n● Fine-Tuned Small Models: T ake an open-weight language model and ﬁne-tune it to perform \\none (and only one) speciﬁc task to beat performance on general models (T ensor Zero)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 16, 'page_label': '17'}, page_content='(Phase 1 Callback) Healthy Scepticism \\nThis space is new and exciting. However, we encourage you to \\nhave healthy scepticism of any new tool you come across. \\nIf a consultant/company/ceo/venture capitalist tells you that\\n● you need a product \\n● you will get left behind without it\\n● their product is eternal\\n● include an appeal to higher ideas (God, gov’t, history)\\n● the anticipated usage you need is just on the horizon\\nThey are usually clueless to what they’re talking about or (and) \\ntrying to sell you something.\\nAbsolute nonsense, but \\ngood cash-grab.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 17, 'page_label': '18'}, page_content='But on a deeper level of criticism, also consider if these gigantic models truly reﬂect \\nthe “intelligence” needed to control human-focused systems \\nhttps://nearlyright.com/how-ai-researchers-accidentally-discovered-that-everything\\n-they-thought-about-learning-was-wrong/'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 18, 'page_label': '19'}, page_content='AI Implementations'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 19, 'page_label': '20'}, page_content='AI Implementations\\nWe have a few options for “intervention-points” when introducing techniques to solve \\nthese issues of limited distributed attention, limited context windows, and limited \\niterative reasoning. \\nThese intervention points include:\\n● The Application Layer: These involve the high-level modiﬁcation and orchestration of \\nmodel inputs, outputs, and tools. Shape the end-user experience.\\n● The Data Layer: These involve the system-level speciﬁcations of how an LLM \\ninteracts with datasets. Handle how an LLM communicates with data. \\n● The Model Layer: These involve the modiﬁcation of the core LLM model & its’ \\nweights. Adapt the model’s underlying knowledge & abilities.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 20, 'page_label': '21'}, page_content='AI Implementations - The Application Layer\\nThe application layer entails no modiﬁcation to the \\nbase neural network (LLM).\\nInstead, we focus on modifying the prompts and tools \\nthat an LLM can use when providing a response to \\nsome user query or action.\\nThis often entails the least computational cost, but for \\na poorly trained model, also potentially provides the \\nleast gains in accuracy.\\nThis includes tools like: RAGs, Agents, Guardrails, and \\nChain of Thought Reasoning.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 21, 'page_label': '22'}, page_content='AI Implementations - The Data Layer\\nThe data layer also entails no modiﬁcation to the \\nbase neural network (LLM).\\nInstead, we focus on providing a suite of dynamic \\nresources and formats for our model to use when \\nbeing queried for information. \\nThis also often entails the least computational cost, \\nbut for a poorly trained model, also potentially \\nprovides the least gains in accuracy.\\nThis includes tools like: Model Context Protocol, API \\nGateways, & Vector DB’s/Stores.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 22, 'page_label': '23'}, page_content='AI Implementations - The Model Layer\\nThe model layer entails modiﬁcation to the base \\nneural network (LLM).\\nWe take a pre-trained model (unless we have millions of \\ndollars for pre-training) and modify the internal \\ntransformer weights to improve the models \\nknowledge and abilities.\\nThis also often entails the most computational cost, \\nbut for a poorly trained model, also potentially \\nprovides the greatest gains in accuracy.\\nThis includes tools like: ﬁne-tuning, reinforcement \\nlearning, and quantization.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 23, 'page_label': '24'}, page_content='Vector DB Review'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 24, 'page_label': '25'}, page_content='Word Embeddings - Data Representations\\nLet’s recap what a vector embedding is:\\nA vector embedding is a deep learning \\ntechnique that takes an unstructured data \\nformat (such as a word) and translates it into \\nnumerical representation in order to extract \\nsemantic meaning out of it!\\nThis, in effect, allows a computer to \\n“understand” the meaning of an audio-ﬁle, \\nparagraph, etc.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 25, 'page_label': '26'}, page_content='Of course, there is no such a thing as magic in computer science. You should always feel \\nlike you could implement a bottom-up implementation of any algorithm you work with. \\nHowever, the results of these techniques “feel” like magic. Notice how training a neural \\nnetwork on text data embeds an “understanding” that the word dog is similar to the word \\n“cat” , “animal” , and “horse. ”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 26, 'page_label': '27'}, page_content='Vector Database Review\\nWe iterate upon the idea of vector embeddings by generating a specialized database \\nthat stores our vector embeddings. This is a data-layer implementation of LLMs.\\nThis database comes with a few key features which make it specialized for vector \\nsearch:\\n● Nearest-neighbor search to ﬁnd semantically related ﬁles\\n● Random projection to reduce the number of dimensions in our vectors (similar \\nto PCA or t-sne)\\n● Indexing to efﬁciently store vectors\\nCheck out pinecone.io for more info. See W10D1 for applicable code on this concept.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 27, 'page_label': '28'}, page_content='Vector Databases\\nUsage\\nStore and index embeddings so LLMs can retrieve \\nsemantically similar content. Not often deployed \\nindividually, part of a larger system\\nPros \\n● Scalable search over large data corpus\\n● Semantic search instead of keyword search\\nCons\\n● Requires well-prepped embeddings\\n● Retrieval of quality is dependent on data curation'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 28, 'page_label': '29'}, page_content='RAG Review'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 29, 'page_label': '30'}, page_content='RAG Review\\nOnce we’ve established some sort of data-layer approach to interacting with our \\nrelevant data, we can then implement an application-layer approach such as \\nretrieval augmented generation.\\nRecall that this entails NO modiﬁcation to the base LLM!\\nWe simply “inform” LLMs by adding contextual information to the user prompt. \\nThink of this as giving our LLM an “open-textbook” exam where it is allowed to \\nconsult with resources before answering.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 30, 'page_label': '31'}, page_content='In W10D1, we created a RAG using a vector database. However the data \\nsource can also be Google, or some other specialized data source.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 31, 'page_label': '32'}, page_content='RAGs\\nUsage\\nCombine LLMs with a retriever (often a vector DB) to inject \\nexternal knowledge at runtime.\\nPros \\n● Provides up-to data & focused answers\\n● Reduces hallucations\\n● Vector db acts as a run-time persistent memory\\nCons\\n● Can still hallucinate answers if retrieved data is too \\nbroad or irrelevant\\n● Retrieval slows down answers'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 32, 'page_label': '33'}, page_content='Fine-tuning Review'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 33, 'page_label': '34'}, page_content='Fine-Tuned Models\\nLastly, we also explored how we can modify LLM output by implementing the \\nmodel-layer application of ﬁne-tuning a model.\\nAs we established, this is computationally expensive, however allows our model to be \\nbetter-aligned with intended output format, tone, and knowledge. \\nWe train LLMs just like any machine learning model by updating its’ weights based on \\nthe error that it makes. Think of this as making our LLM study until it can successfully \\nanswer all questions in an exam.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 34, 'page_label': '35'}, page_content='In W10D2, we created a ﬁne-tuned model by providing a training set of \\nintended outputs. We then measured the models’ accuracy of responses on \\na testing set.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 35, 'page_label': '36'}, page_content='“Weights” clariﬁcation\\nRemember that the concept of a “weight” or \\ncoefﬁcient is by no means new. A “weight” is the \\nnumeric value that our model “learns” in order to \\npredict some value. \\n● Coefﬁcients/Weights (W)\\n● Inputs (X)\\nWe express these as vectors which we take the \\ndot-product of.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 36, 'page_label': '37'}, page_content='Hours Exercise a week\\nCups of \\nCoffee a \\nWeek\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n42 3 51 6 7 8 9\\n         = Insomnia \\n         = No Insomnia \\ny1 = 0.3 - 0.7(1) + 1.3(3) = 3.5 → 1\\ny2 = 0.3 - 0.7(2) + 1.3(4) = 4.1 → 1\\ny3 = 0.3 - 0.7(3) + 1.3(6) = 6 → 1\\ny4 = 0.3 - 0.7(3) + 1.3(1) = -0.5 → 0\\ny5 = 0.3 - 0.7(4) + 1.3(3) = 1.4 → 1\\nNote this hyperplane is calculated by \\nsetting our equation greater than 0\\nBy solving the inequality b/w x1 & x2 we \\nget the following hyperplane\\nWe calculate our weights by performing gradient descent & \\nbackpropagation.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 37, 'page_label': '38'}, page_content='Fine-Tuned Models\\nUsage\\nAdapt an LLM to a domain, style, or task by training on \\nspecialized datasets.\\nPros \\n● No slow-down of retrieval, fast inference \\n● Answers become focused and domain-speciﬁc\\nCons\\n● Expensive in time and $$$ to train\\n● Becomes outdated without retraining'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 38, 'page_label': '39'}, page_content='Agents'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 39, 'page_label': '40'}, page_content='Agents\\nOne issue with LLMs that we still haven’t addressed is the \\ninability to reason through multi-step problems.\\nOne potential solution to this drawback are agents.\\nThis boils down to creating an LLM agent that can:\\n● Call external tools\\n● Interact with other LLM agents\\n● Utilize RAGs to inform answers\\nThink of this as combining multiple LLM tools together to create \\na system of well-informed answers and self-management.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied LLMs & Agents', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied LLMs & Agents.pdf', 'total_pages': 41, 'page': 40, 'page_label': '41'}, page_content='Agents\\nUsage\\nLLMs augmented with reasoning loops that can decide \\nwhen and how to call tools, APIs, or other systems.\\nPros \\n● Supports complex reasoning workﬂows\\n● When used in conjunction with RAGs/Fine-tuned \\nmodels, all former pros of tools included\\nCons\\n● Expensive in time to orchestrate\\n● More points of failure (vs just one)\\n● Requires robust data management'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 0, 'page_label': '1'}, page_content='Applied Rest APIs I'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 1, 'page_label': '2'}, page_content='Agenda - Schedule\\n1. Jupyter Notebook Preview\\n2. Requests Module\\n3. API Calls - Code Along\\n4. TLAB JavaScript Object Notation (JSON) is an open-standard data \\nformat or interchange for semi-structured data. It is \\ntext-based and readable by humans and machines. \\nhttps://www.snowﬂake.com/guides/what-is-json'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 2, 'page_label': '3'}, page_content='Agenda - Announcements \\n● Week 4 Pre-Class Quiz due 4/1\\n● TLAB #2 Due 4/21\\n● Ofﬁce hours posted'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 3, 'page_label': '4'}, page_content='Agenda - Goals\\n● Learn how to request data programmatically over the web\\n● Learn how to transform JSON ﬁles into structured data\\n● Get introduced to Jupyter notebooks'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 4, 'page_label': '5'}, page_content='Fellowship Reminders'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 5, 'page_label': '6'}, page_content='Fellowship Reminders\\nNow that we’re on week 4, we just want to go through a few reminders \\nrelated to what you should expect each week\\n● Weekly Pre-Class Quizzes\\n● Slack Usage\\n● Requesting extensions\\n● Ofﬁce Hours'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 6, 'page_label': '7'}, page_content=\"Weekly Pre-Class Quizzes\\nYou will have a pre-class quiz each week that will \\nbe due on the following Tuesday of each week.\\nFor example,the Week 4 Pre-Class Quiz was \\nannounced last Wednesday and will be due this \\nTuesday.\\nUnless you’ve requested a 48-extension on this \\nquiz, it will close on Tuesday 11:59 PM and will \\nnot be able to be re-opened. \\nLook at the “assignments” tab of this \\nweek's module to see what's due.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 7, 'page_label': '8'}, page_content='Slack Usage - General Usage\\nWe want you to use Slack for collaboration/communication, but we should also \\ntry to direct messages to proper parties.\\nFirst let’s iron out general guidelines:\\n● Don’t use \"@here\" since it pings everyone that is currently on Slack. \\nGenerally staff will use this to make announcements.\\n● Any messages regarding your grade, your scheduled ofﬁce hours, or \\nanything that’s directed to staff, should be sent directly to us \\n● You cannot ask for direct answers on your TLAB. This includes bugs. Don’t \\ntreat errors as a problem, treat them as challenges you must solve \\nyourself.\\nWe’ll start trying to keep the Slack space \\norganized by redirecting you if you send a \\nmessage that might be out of this scope.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 8, 'page_label': '9'}, page_content='How to Reach out for Help\\nRemember, you will not learn a topic just by getting the answer. Treat your \\ngrade as a secondary objective. At no point will an employer ask you for \\nyour TKH GPA. We understand that stipend requirements have a GPA \\nthreshold, but you will make this threshold if you understand the topics.\\nAsk yourself 3 questions before reaching out to a human on coding help:\\n● What does my error message tell me?\\n● Did I look at the notes/recordings for assistance?\\n● Did I read the documentation/instructions?\\nWe will ask you these questions \\nas we go further into this \\nfellowship during debugging \\nsessions.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 9, 'page_label': '10'}, page_content='Slack Usage - Channel Purposes\\nFor the remaining slack channels, please try to keep the messages focused on \\ntheir intended usage:\\n● data-science-fellowship-instructor-announcements: Announcements \\nregarding content, labs, and due dates (don’t miss messages from this channel)\\n● data-science-fellowship-all: Track wide collaboration, outreach between \\ncohorts; group study sessions,  installation help\\n● data-science-fellowship-a/b: Questions during class, support needed to get to \\nright zoom session, study sessions, installation help\\n● random: memes, resources, etc'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 10, 'page_label': '11'}, page_content='Requesting Extensions\\nIf you’d like to request an extension email your student success specialist, \\nyour instructor, and your TA a quick 1-2 sentence email.\\nCould be as simple as “I would like to use my extension, thanks!”\\nWe will respond with a conﬁrmation email. Going forward, all requests \\nmust be made before the due date.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 11, 'page_label': '12'}, page_content='Oﬃce Hours\\nStaff within your own cohort will only be able to hold ofﬁce hours with you. \\nThis is to keep our availability consistent.\\n● Cohort A: Farukh & Malachi\\n● Cohort B: Anil & Maurice\\nCohort A, please check out our ofﬁce hours and book with Malachi and \\nme(Farukh).'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 12, 'page_label': '13'}, page_content='Fellowship Non-Reminders\\nLastly, we just want to end this batch of reminders with some words of \\nencouragement:\\n● Only use yourself as a reference point for progress. If you start playing \\nthe comparison game with other people, it can quickly hinder your \\nefforts.\\n● You are all learning a lot in a short period of time! As a self-taught \\nlearner, this progression of topics represents months if not years of \\ncontent reduced down to a concentrated fellowship.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 13, 'page_label': '14'}, page_content='Jupyter Notebooks'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 14, 'page_label': '15'}, page_content='Intro to Jupyter Notebooks\\nAs we get closer to performing data analysis, we should become familiar with \\ntools that we can use to generate reports and observe intermediate output from \\nPython code.\\nJupyter Notebook is one of those tools. We can directly create jupyter notebooks \\nin our VSCode in order to run code piece by piece and also present visualizations!\\nWe will demonstrate how to begin working with jupyter notebooks. We won’t be \\npausing for debugging help, so please just observe and then try this process \\nyourself during lab (looking back to the slides).'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 15, 'page_label': '16'}, page_content='Since we’ve already created a conda environment, we do not need to worry \\nabout installing the notebooks package. Instead, we should ﬁrst enable the \\nJupyter widget on VSCode.\\n1) Type in \\n“Jupyter” in \\nyour \\n“Widgets” \\nsearch bar in \\nVSCode \\n2) Then \\ninstall the \\nJupyter \\nwidget will \\nenable you \\nto create \\nnotebooks  \\nstraight from \\nVSCode'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 16, 'page_label': '17'}, page_content='From there, we can create a Jupyter notebook by simply creating a new ﬁle \\nin VSCode and give this an extension of .ipynb.\\nHowever since we’re working off of requests.ipynb we can simply open this \\nﬁle.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 17, 'page_label': '18'}, page_content='Before we go about running this code, let’s note the structure. We can modify text \\nin the markdown boxes by double clicking anywhere we see text.\\nThis is where Jupyters power as a reporting tool is revealed. We can type in \\nprescriptions/explanations for data analysis in these boxes.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 18, 'page_label': '19'}, page_content='Below our markdown box we have a code-block. We can insert Python code \\ninto this code block, run our code by clicking on the “play button” on the \\nleft-hand side, and our outputs will be presented in the space below!\\nYou must run \\ncode \\nsequentially (i.e. \\nrun the code \\nblock by block) \\nor else your \\nnotebook might \\nnot work'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 19, 'page_label': '20'}, page_content='Note the top-menu as well. We invite you to explore these options. One of \\nthe best habits you can start forming is the ability to experiment with novel \\nsystems. Click around and see what happens, don’t be afraid to ruin the ﬁle, \\nwe can always redownload it.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 20, 'page_label': '21'}, page_content='Let’s point our attention to the button at the top-right that states “Select \\nKernel.” Think of this as the engine of Python. Without a selected kernel \\nyour code will not work.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 21, 'page_label': '22'}, page_content='By clicking on “Select Kernel” we will be brought to a drop down menu that \\ngives us two categories of environments. Let’s select “Python \\nEnvironments. ”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 22, 'page_label': '23'}, page_content='Finally we will be brought to a selection of conda and global environments. \\nSelect the environment that you’ve created last week “ds. ”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 23, 'page_label': '24'}, page_content='Verify that you see “ds” in the top-right and you’re done! Let’s get coding.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 24, 'page_label': '25'}, page_content='Choosing the Right Tool\\nRemember! Part of being a good technologist is being able to discern which \\ntools are right for a speciﬁc task.\\nFor now, we will guide you through what kind of ﬁles you should be using, \\nbut eventually (Phase 2) you will have to be able to make this selection \\nyourself. Follow this rule of thumb: \\n● Python Modules: Any functionality that should be run automatically \\n(on a schedule) or integrated into a larger system.\\n● Jupyter Notebooks: Making tutorials, reports, or code that you will \\nshare with a non-technologist stakeholder.\\nYou should not be creating notebooks \\nunless you are doing data science (EDA, \\nML) which will be shared with us (or your \\nfuture stakeholders).'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 25, 'page_label': '26'}, page_content='Requests Module'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 26, 'page_label': '27'}, page_content='Requests Module\\nWe’ve already discussed how we can \\naccess data that is local to our \\ncomputer.\\nWhile this is important, this isn’t the full \\npicture.\\nWhere do you think a large subset of \\ndata exists in the real world?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 27, 'page_label': '28'}, page_content='Requests Module\\nWe’ve already discussed how we can \\naccess data that is local to our \\ncomputer.\\nWhile this is important, this isn’t the full \\npicture.\\nWhere do you think a large subset of \\ndata exists in the real world?\\nIf it’s not on a private server, then on \\nthe internet.\\nBut how do we actually go about \\nrequesting data over the internet?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 28, 'page_label': '29'}, page_content='Requests Module\\nAs it turns out, getting data over the internet is actually quite simple!\\nAll we need is the appropriate package to handle HTTP requests. Access \\nthe requests.ipynb notebook and run the ﬁrst code-block.\\nr = requests.get(\"https://www.scrapethissite.com/pages/simple/\")'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 29, 'page_label': '30'}, page_content='The ‘get’ function itself is an HTTP method that “gets” resources located in a speciﬁc URL.Note that this URL could be any resource that you want! \\nr = requests.get(\"https://www.scrapethissite.com/pages/simple/\")\\nprint(r.encoding)\\nprint(r.status_code)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 30, 'page_label': '31'}, page_content='For example, if you’re doing knowledge extraction on wikipedia, you could \\npotentially throw in a wikipedia article.\\nr = requests.get(\"https://en.wikipedia.org/wiki/Akira_T oriyama\")\\nprint(r.encoding)\\nprint(r.status_code)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 31, 'page_label': '32'}, page_content='Or, as you will see later on, an API resource.\\nr = requests.get(\"https://pokeapi.co/api/v2/pokemon/pikachu\")\\nprint(r.encoding)\\nprint(r.status_code)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 32, 'page_label': '33'}, page_content='“Get” is not the only method available to us, however, for our purposes, we will strictly focus on this method as we are not able to modify resources that do not belong to us.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 33, 'page_label': '34'}, page_content='When running the following code-block, what do you notice gets printed?\\nr = requests.get(\"https://www.scrapethissite.com/pages/simple/\")\\nprint(r.encoding)\\nprint(r.status_code)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 34, 'page_label': '35'}, page_content='In the ﬁrst print statement we get some sort of encoding (something akin to \\nthe language this website is in).\\nBut what about that code “200” , what exactly does this indicate? \\nr = requests.get(\"https://www.scrapethissite.com/pages/simple/\")\\nprint(r.encoding)\\nprint(r.status_code)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 35, 'page_label': '36'}, page_content='Whenever we access a web-page, we receive a status code which signiﬁes what was result of our request.Since we got “200” , what does that indicate about our request?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 36, 'page_label': '37'}, page_content='Success\\n200 indicates that the website \\nhonored our request, and \\ngave us back the information \\nwe wanted.\\nIf we ever get a 400 error, this \\nusually indicates that we \\nwere blocked\\nA 500 error usually indicates \\nthat there’s an internal \\nproblem with your DNS \\nprovider or the website itself.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 37, 'page_label': '38'}, page_content='Just like yesterday, we are not primarily interested in the metadata of this object, \\nbut rather the data itself.\\nT o access this, we utilize the “text” attribute. What do you notice gets printed out?\\nr = requests.get(\"https://www.scrapethissite.com/pages/simple/\")\\nprint(r.text)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 38, 'page_label': '39'}, page_content='We get a string that represents the websites HTML ﬁle.\\nNote: this is semi-structured data! Accessing what we want will be difﬁcult. \\nWe will explore ways to parse this data next week.\\nr = requests.get(\"https://www.scrapethissite.com/pages/simple/\")\\nprint(r.text)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 39, 'page_label': '40'}, page_content='Instead of trying to parse this HTML, let’s shift our attention to API calls and \\nutilize the requests module to programmatically access an external \\ndatabase.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 40, 'page_label': '41'}, page_content='Requesting Data'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 41, 'page_label': '42'}, page_content='Requests & API’s - ETL/ELT Pipelines\\nIn a classic data analysis/engineering workﬂow, we usually set up pipelines \\nin order to create a database for analysis/learning.\\nWhile classic pipeline tools are usually located on some cloud environment, \\nwe can still begin discussing the process of creating a dataset from a local \\nenvironment.\\nRemember, our goal is to get from semi/unstructured data formats to \\nstructured formats. Only then can we begin data analysis!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 42, 'page_label': '43'}, page_content='One classic format that we will learn about is the extract-transform-load \\n(ETL) pipeline. We will skip details for now, but think of this as the process of \\ncollecting data, applying transformations, and ﬁnally, saving it.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 43, 'page_label': '44'}, page_content='This brings up a fundamental question however… how do we extract data \\noutside of basic CSV ﬁles?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 44, 'page_label': '45'}, page_content='As we discussed yesterday, data is usually not readily available to us in a convenient and structured format. Instead, we usually have to purchase/access/collect our own data. This data is usually accessed over the internet via API calls.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 45, 'page_label': '46'}, page_content='More speciﬁcally, the RESTful Web APIs. This describes a programmatic \\nway to “ask respectfully” for data. \\nThe term “API” can be \\nused in multiple contexts:\\npandas API:\\nAn interface to use when \\ncoding in pandas\\nREST API:\\nAn interface when \\nrequesting data over the \\nweb'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 46, 'page_label': '47'}, page_content='Let’s take a look at an example of a simple web API to request Pokemon data: https://pokeapi.co/.Notice that we get some data about our pokemon located in a JSON object.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 47, 'page_label': '48'}, page_content='If you’d like to see the raw JSON object, access the following link: https://pokeapi.co/api/v2/pokemon/pikachu Notice the pattern of this link “https://apiname.co/api/v2/info”We will see this applied to ﬁnancial data later.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 48, 'page_label': '49'}, page_content='Requests & APIs\\nAn API call is basically a website URL that points us to a speciﬁc resource.\\nWhile all API calls contain individual URL patterns  they all follow a general \\npattern.\\nFor example, let’s take a look at the Pokemon API URL.\\nhttps://pokeapi.co/api/v2/pokemon/pikachu'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 49, 'page_label': '50'}, page_content='API Calls'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 50, 'page_label': '51'}, page_content='An Aside - The “REST” API\\nThere are different types of API protocols and \\narchitectures, however, we will only focus on the REST \\n(Representational State Transfer) API as its the most \\ncommon architecture for requesting data over the \\nweb.\\nThe REST architecture transfers a representation of \\nthe state of the resource to the requester. \\nThis information comes in several formats: JSON, \\nHTML, XML, or plain text.\\nA client is the party making the \\nrequest, whereas the server is the \\nparty that resolves this request  \\n(ATM -> Bank;  Computer -> Gmail)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 51, 'page_label': '52'}, page_content='An Aside - The “REST” API\\nYou can also design your own REST APIs! However, for \\nit to truly be considered RESTful, it must conform to \\nthe following criteria:\\n● Client-Server architecture with requests \\nmanaged through HTTP\\n● Stateless communication, meaning no client \\ninformation is stored between requests\\n● Cached data streamlines communication\\n● Uniform interface that describes resources and \\nerrors\\n● Layered system to efﬁciently retrieve data\\nA client is the party making the \\nrequest, whereas the server is the \\nparty that resolves this request  \\n(ATM -> Bank;  Compter -> Gmail)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 52, 'page_label': '53'}, page_content='Notice that we ﬁrst specify the API that we are requesting data from.\\nhttps://pokeapi.co/api/v2/pokemon/pikachu'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 53, 'page_label': '54'}, page_content='Afterwards, we indicate what “kind” of resource we want. In this case, it is \\nthe data on speciﬁc pokemon.\\nhttps://pokeapi.co/api/v2/pokemon/pikachu'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 54, 'page_label': '55'}, page_content='And ﬁnally, we specify which speciﬁc “entity” do we want information about.Once again, all API calls will have their own unique URLs (just like all websites have their own URL), however there is a pattern to this call!\\nhttps://pokeapi.co/api/v2/pokemon/pikachu'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 55, 'page_label': '56'}, page_content='For example, take a look at this stock data API where we can make requests for live ﬁnancial data. Compare it to the pokemon API that we just used.Notice the similarities!\\nhttps://api.polygon.io/v1/open-close/AAPL/2022-11-08?adjusted=True\\nhttps://pokeapi.co/api/v2/pokemon/pikachu \\nWhile our stock data is a lot more granular, notice that it is fundamentally the \\nsame structure: API/DB/resource'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 56, 'page_label': '57'}, page_content='Let’s shift our focus back to the actual data however.\\nSo now that we have a handle on how to “request” data using an API call, \\nwhere do we actually put this URL? (think back to the requests module)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 57, 'page_label': '58'}, page_content='In this case we can simply extract this data format using the requests module!\\nExcept this time, it would be insufﬁcient to save this as a “text” ﬁle\\nr = requests.get(\"https://pokeapi.co/api/v2/pokemon/pikachu\")\\ndata = r.text\\nprint(data[0]) {\\nNotice that treating this like a \\n“string” will not allow us to \\naccess individual objects!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 58, 'page_label': '59'}, page_content='Instead, we utilize the .json() method in order to convert this into an \\nobject which we can then access like a regular Python data-structure.\\nr = requests.get(\"https://pokeapi.co/api/v2/pokemon/pikachu\")\\ndata = r.json()\\nprint(data[“abilities”])\\nNow we can access data \\nprogrammatically.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 59, 'page_label': '60'}, page_content='r = requests.get(\"https://pokeapi.co/api/v2/pokemon/pikachu\")\\ndata = r.json()\\nfor ab in data[\"abilities\"]:\\n    print(ab)\\nNote that challenge of interacting with this \\nobject is a test of your ability to code.\\nUs just showing you lines of code on how to \\nwork with a JSON object will not be sufﬁcient. \\nInstead let’s take a look at a real exercise on \\nsome stock data.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 60, 'page_label': '61'}, page_content='API Access Exercise'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 61, 'page_label': '62'}, page_content='API Exercise\\nMore often than not, API requests are only authorized via some API-key \\nthat was either bought for you through your company or was offered freely.\\nLet’s go through an exercise where we request “privileged” information \\nusing an API key.\\nSpeciﬁcally, we will be using a website that collects ﬁnancial data: \\nhttps://polygon.io'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 62, 'page_label': '63'}, page_content='Before beginning this exercise, let’s sign up for a free API key in order to \\nrequest ﬁnancial data from the https://polygon.io/ API'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 63, 'page_label': '64'}, page_content='By clicking on “Sign Up” , you will be redirected to a page where you can use \\nyour GitHub account to sign up for a free account.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 64, 'page_label': '65'}, page_content='It will ask you to authorize your account (just basically view your email \\naddress), go ahead and click “Authorize”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 65, 'page_label': '66'}, page_content='We will then be redirected to a “dashboard” page where we can request \\ndata. By default we will be in the free tier.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 66, 'page_label': '67'}, page_content='By hovering over the “Dashboard” menu you will see the “API Keys” button. \\nGo ahead and click on this.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 67, 'page_label': '68'}, page_content='Finally, you will observe some randomly generated key. Copy and paste this \\ncode into the following string'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 68, 'page_label': '69'}, page_content='NOTE: You should always keep your key a secret. For now, we are working \\nwith the free tier so this isn’t too important, however for future reference, \\nexposing your key is basically the same as exposing sensitive company \\ninformation.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 69, 'page_label': '70'}, page_content='Once we get this API key copied, let’s access our respective dashboard and \\nclick on “RESTful Documentation”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 70, 'page_label': '71'}, page_content='From there, we will access the “Aggregates” menu option and scroll down to \\nthe respective URL.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 71, 'page_label': '72'}, page_content='Notice that we are given a respective URL with speciﬁed parameters that will give us a JSON object.That is, if we just use this URL in our requests.get() method, we will get back this object!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 72, 'page_label': '73'}, page_content='Using this idea, complete the following API exercise as a group. Before \\nbeginning be sure to set you kernel!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 73, 'page_label': '74'}, page_content='Wrap-Up'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 74, 'page_label': '75'}, page_content='Lab (Due 04/21)\\nYou are a growth analyst at a Vancouver-based consulting ﬁrm called \\nMonica Group. Your manager is spearheading the completion of a a new \\nanalytical tool which will automatically label if a review is positive, neutral, \\nnegative, or irrelevant. \\nYou will be kicking off completion of this milestone by independently \\nimplementing a minimal-viable-product. This will be a Python pipeline that \\ningests a text-ﬁle of review data and interfaces with the Open AI API in \\norder to automatically label each review.\\nWe will release API keys on 4/1\\nVancouver, Canada'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs I.pdf', 'total_pages': 76, 'page': 75, 'page_label': '76'}, page_content=\"Tuesday\\nTuesday will entail:\\n● More API calls!\\n● Interacting with the OpenAI API\\nJupyter: scratchpad of the data \\nscientist\\nIf you understand what you're doing, you're \\nnot learning anything. - Anonymous\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 0, 'page_label': '1'}, page_content='Applied Rest APIs II'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 1, 'page_label': '2'}, page_content='Agenda - Schedule\\n1. REST APIs Review\\n1. OpenAI API Intro\\n2. Break\\n3. OpenAI API Lab JavaScript Object Notation (JSON) is an open-standard data \\nformat or interchange for semi-structured data. It is \\ntext-based and readable by humans and machines. \\nhttps://www.snowﬂake.com/guides/what-is-json'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 2, 'page_label': '3'}, page_content='Agenda - Announcements \\n● Week 4 Pre-Class Quiz due 4/1\\n● TLAB #2 Due 4/21\\n● Ofﬁce hours posted'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 3, 'page_label': '4'}, page_content='Agenda - Goals\\n● Review Rest API usage\\n● Get introduced to LLM technology\\n● Learn how to use the OpenAI API\\n● Discover the principles of effective requests'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 4, 'page_label': '5'}, page_content='Web APIs Review'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 5, 'page_label': '6'}, page_content='As we discussed, one typical pipeline that in the data engineering process is \\nthe extract-transform-load (ETL) pipeline.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 6, 'page_label': '7'}, page_content='This week, we will go over various ways to extract data via Web APIs and \\nWeb Scraping. Afterwards, we will go over techniques we can use to \\ntransform data for easy analysis and prediction.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 7, 'page_label': '8'}, page_content='T oday, we will review the RESTful Web API. This describes a programmatic \\nway to “ask respectfully” for data. \\nThe term “API” can be \\nused in multiple contexts:\\npandas API:\\nAn interface to use when \\ncoding in pandas\\nWeb API:\\nAn interface when \\nrequesting data over the \\nweb'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 8, 'page_label': '9'}, page_content='Requests & APIs\\nLet’s review our REST API terminology. Can anyone identify the \\ncomponents of this URL?\\nhttps://pokeapi.co/api/v2/pokemon/pikachu'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 9, 'page_label': '10'}, page_content='Requests & APIs\\nThe base URL (aka the Request URL) is the URL that points to your API. \\nThis serves as your initial entry-point.\\nhttps://pokeapi.co/api/v2/pokemon/pikachu \\nAccess the pokemon Web API…'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 10, 'page_label': '11'}, page_content='Requests & APIs\\nNext, we have the endpoint which describes where the data that you want \\nto interact with is located. \\nNotice the similarities between the endpoint and ﬁle-paths… (e.g. \\nTLAB2/data/averages.png)\\nhttps://pokeapi.co/api/v2/pokemon/pikachu \\n…and give me information on the \\npokemon named pikachu'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 11, 'page_label': '12'}, page_content='But keep in mind, you will  always use the API documentation to structure your URL: https://pokeapi.co/.Which points back to the importance of good documentation: https://www.ncei.noaa.gov/support/access-data-service-api-user-documentation'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 12, 'page_label': '13'}, page_content='Requests & APIs\\nThe previous example describes a simple public API which entails a minimal \\nURL. \\nThis is rarely the type of URL you will be accessing for your projects, instead \\nyou will be accessing URLs that have complex queries, such as the following \\nAPI:\\nhttps://api.polygon.io/v2/aggs/ticker/AAPL/range/1/day/2023-01-09/2023-02-10?adjusted=true&sort=asc&apiKey=123456'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 13, 'page_label': '14'}, page_content='Requests & APIs\\nWe still have our base URL…\\nhttps://api.polygon.io/v2/aggs/ticker/AAPL/range/1/day/2023-01-09/2023-02-10?adjusted=true&sort=asc&apiKey=123456 \\nAccess the polygon Web API…'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 14, 'page_label': '15'}, page_content='Requests & APIs\\nAs well as the endpoint…\\nhttps://api.polygon.io/v2/aggs/ticker/AAPL/range/1/day/2023-01-09/2023-02-10?adjusted=true&sort=asc&apiKey=123456 \\n…and give me aggregates on the AAPL \\nticker from Jan 1 2023 to Feb 10 2023'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 15, 'page_label': '16'}, page_content='Requests & APIs\\nBut this additional section describes the query, which provides additional \\nparameters that allows you to retrieve a modiﬁed version of the resource \\nthat you are requesting, as well as provide required access information (for \\nexample API keys) \\nWe combine multiple queries using the &:\\nhttps://api.polygon.io/v2/aggs/ticker/AAPL/range/1/day/2023-01-09/2023-02-10?adjusted=true&sort=asc&apiKey=123456'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 16, 'page_label': '17'}, page_content='Requests & APIs\\nThe following queries provide the following parameters:\\n● adjusted=true: Return the adjusted price\\n● sort=asc: Sort these dates in descending order\\n● apiKey=123456: Here’s my secret key\\nhttps://api.polygon.io/v2/aggs/ticker/AAPL/range/1/day/2023-01-09/2023-02-10?adjusted=true&sort=asc&apiKey=123456'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 17, 'page_label': '18'}, page_content='Once again you are not expected to construct these queries yourself. Instead, you will  always use the API documentation: https://polygon.io/docs/stocks/get_v2_aggs_ticker__stocksticker__range__multiplier___timespan___from___to \\nRead documentation for proﬁt \\nand success.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 18, 'page_label': '19'}, page_content='r = requests.get(\"https://pokeapi.co/api/v2/pokemon/pikachu\")\\ndata = r.json()\\nfor ab in data[\"abilities\"]:\\n    print(ab)\\nWe can then use these API urls with our \\nrequests module to automatically extract \\ninformation in our Python program.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 19, 'page_label': '20'}, page_content='OpenAI API'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 20, 'page_label': '21'}, page_content='OpenAI API\\nFor this next lab, we will have you to interact with the OpenAI API to send \\nhuman-reviews for machine sentiment labeling.\\nHowever, before we dive into the syntax, let’s go over a brief overview of \\nthe context and expected usage of large language model technology.\\nThere’s a lot of mixed messaging regarding LLMs, so we would like to \\nemphasize a restrained look on how you should use LLMs in your workplace.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 21, 'page_label': '22'}, page_content='Neural Networks\\nIn Phase 2 of this fellowship, we will learn \\nabout a type of machine learning algorithm \\ncalled a perceptron.\\nThis takes inspiration from the neurons in our \\nbrain, but purely exist as a mathematical \\nfunction.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 22, 'page_label': '23'}, page_content='Neural Networks\\nWe can organize these perceptrons in speciﬁc \\narchitecture to have them perform some \\nimpressive tasks such as:\\n● Computer vision\\n● Numeric prediction\\n● Classiﬁcation\\n● Natural language processing'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 23, 'page_label': '24'}, page_content='Neural Networks - Transformers\\nBack in 2017, Google researchers published a paper \\ntitled Attention is All you Need to introduce a neural \\nnetwork architecture to translate text between \\ndifferent languages.\\nIn summary, this proposes a model for probabilistic \\ntext prediction. That is, the model is selecting the next \\nword (token) based on probabilities.\\nThis eventually became ChatGPT.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 24, 'page_label': '25'}, page_content='For example, let’s say you are babysitting your niece/nephew/cousin etc. \\nYou’ve spent a few days with them and there are certain phrases you hear \\nthem say over and over again.\\n“I hate carrots.”\\n“Carrots are \\ngross.”\\n“Can I buy robux.”\\n“Can I have my \\nIpad.”\\n“I hate carrots.”\\n“I don’t want to \\nsleep.”\\n“I hate carrots.”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 25, 'page_label': '26'}, page_content='You hear them begin a sentence again with “I hate…” Based on your \\nhistorical data, what do you predict is going to be the next word of this \\nsentence. \\n“I hate carrots.”\\n“Carrots are \\ngross.”\\n“Can I buy robux.”\\n“Can I have my \\nIpad.”\\n“I hate carrots.”\\n“I don’t want to \\nsleep.”\\n“I hate carrots.”\\n“I hate … “'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 26, 'page_label': '27'}, page_content='This is a massive over-simpliﬁcation of ChatGPT, but this is a useful mental \\nmodel to use going forward when we talk about large language models.\\n“I hate carrots.”\\n“Carrots are \\ngross.”\\n“Can I buy robux.”\\n“Can I have my \\nIpad.”\\n“I hate carrots.”\\n“I don’t want to \\nsleep.”\\n“I hate carrots.”\\n“I hate carrots.“'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 27, 'page_label': '28'}, page_content='ChatGPT\\nThis is why we emphasize that you do not directly \\nuse answers from ChatGPT in your TLABs/work.\\n By replacing your answers with LLM output, you \\nopen yourself up to:\\n● Hallucinations\\n● Not citing work\\n● Lack of authority in your answers'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 28, 'page_label': '29'}, page_content=\"ChatGPT - Healthy Scepticism \\nWe encourage you to have healthy scepticism of any new tool you \\ncome across. \\nIf a person/company/ceo/venture capitalist tells you that\\n● you need a product \\n● you will get left behind without it\\n● their product is eternal\\n● include an appeal to higher ideas (God, gov’t, history)\\nThey are either:\\n● Clueless to what they’re talking about\\n● Trying to sell you something\\nMost of the time it's the latter. \\nAbsolute nonsense, but \\ngood cash-grab.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 29, 'page_label': '30'}, page_content='OpenAI API Syntax'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 30, 'page_label': '31'}, page_content='Hopefully everyone is familiar with ChatGPT already. While we can open a chat-window and send \\nrequests to this LLM, how can we actually send requests over the internet programmatically? \\nIf you haven’t interacted with ChatGPT yet, we recommend you open the following URL and \\npractice sending it queries: https://chatgpt.com/'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 31, 'page_label': '32'}, page_content='OpenAI API\\nT o do this, we need to utilize something similar to using the requests module.\\nSometimes, speciﬁc tools have prebuilt Python packages which we can install and \\nutilize in our projects.\\nIn ChatGPT’s case we can use the openai package. \\nT odays lab will entail the setup of this package in your ds environment. We \\nrecommend that you simply watch us interact with this package as opposed to \\nfollowing along.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 32, 'page_label': '33'}, page_content='This block of code represents a simple “chat completion” request to OpenAI. \\nNote that you will not be able to run this code until you’ve set up your API \\nkey. \\nfrom openai import OpenAI\\nclient = OpenAI()\\ncompletion = client.chat.completions.create(\\n    model=\"gpt-4o-mini\",\\n    messages=[\\n{\\n “role”: \"user\" , \\n“content”: \"Write a one-sentence bedtime story about a unicorn. \"\\n}\\n    ]\\n)\\nprint(completion.choices[0].message.content)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 33, 'page_label': '34'}, page_content='T o begin sending requests to ChatGPT, we must ﬁrst import the OpenAI \\nclass from the openai package and create the OpenAI object. Here we name \\nour object “client. ”\\nfrom openai import OpenAI\\nclient = OpenAI()\\ncompletion = client.chat.completions.create(\\n    model=\"gpt-4o-mini\",\\n    messages=[\\n{\\n “role”: \"user\" , \\n“content”: \"Write a one-sentence bedtime story about a unicorn. \"\\n}\\n    ]\\n)\\nprint(completion.choices[0].message.content)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 34, 'page_label': '35'}, page_content='Next we can begin our request that ChatGPT generates a response to a list \\nof messages using the “completions” API endpoint. Here we simply need to \\ndeﬁne a series of objects client.chat.completions.create\\nfrom openai import OpenAI\\nclient = OpenAI()\\ncompletion = client.chat.completions.create(\\n    model=\"gpt-4o-mini\",\\n    messages=[\\n{\\n “role”: \"user\" , \\n“content”: \"Write a one-sentence bedtime story about a unicorn. \"\\n}\\n    ]\\n)\\nprint(completion.choices[0].message.content)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 35, 'page_label': '36'}, page_content='Inside of the create API call, we specify a series of parameters. Remember \\nparameters are simply variables that only exist within a speciﬁc class or \\nfunction. For the full list of parameters, we can check the docs: \\nhttps://platform.openai.com/docs/api-reference/chat/create \\nfrom openai import OpenAI\\nclient = OpenAI()\\ncompletion = client.chat.completions.create(\\n    model=\"gpt-4o-mini\",\\n    messages=[\\n{\\n “role”: \"user\" , \\n“content”: \"Write a one-sentence bedtime story about a unicorn. \"\\n}\\n    ]\\n)\\nprint(completion.choices[0].message.content)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 36, 'page_label': '37'}, page_content='The ﬁrst parameter we deﬁne is model. This is the large language model \\nthat we will be interfacing with. For our purposes, this will always be \\ngpt-4o-mini due to API limitations. \\nfrom openai import OpenAI\\nclient = OpenAI()\\ncompletion = client.chat.completions.create(\\n    model=\"gpt-4o-mini\",\\n    messages=[\\n{\\n “role”: \"user\" , \\n“content”: \"Write a one-sentence bedtime story about a unicorn. \"\\n}\\n    ]\\n)\\nprint(completion.choices[0].message.content)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 37, 'page_label': '38'}, page_content='However there are other models that you could possibly input. These are \\nrestricted for our API, so we will not be able to use them.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 38, 'page_label': '39'}, page_content='The next parameter is messages. This speciﬁes the messages that we are \\nsending to the model. T ake a look at the outermost brackets of the argument \\nof this parameter. What kind of data-structure do we pass?\\nfrom openai import OpenAI\\nclient = OpenAI()\\ncompletion = client.chat.completions.create(\\n    model=\"gpt-4o-mini\",\\n    messages=[\\n{\\n “role”: \"user\" , \\n“content”: \"Write a one-sentence bedtime story about a unicorn. \"\\n}\\n    ]\\n)\\nprint(completion.choices[0].message.content)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 39, 'page_label': '40'}, page_content='Notice that we are passing in a list! This will be a list composed of \\ndictionaries. Note that so far we only specify the user message. This the \\nprompt that ChatGPT receives in order to generate its output. \\nfrom openai import OpenAI\\nclient = OpenAI()\\ncompletion = client.chat.completions.create(\\n    model=\"gpt-4o-mini\",\\n    messages=[\\n{\\n “role”: \"user\" , \\n“content”: \"Write a one-sentence bedtime story about a unicorn. \"\\n}\\n    ]\\n)\\nprint(completion.choices[0].message.content)\\nLater on, we will also explore the \\n“developer” message to give the system \\nspeciﬁc instructions.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 40, 'page_label': '41'}, page_content='Finally we access the response generated from this prompt using our \\ncompletion variable. Note that we access its choices using index notation, \\nwhat does this tell you about the output ChatGPT generates?\\nfrom openai import OpenAI\\nclient = OpenAI()\\ncompletion = client.chat.completions.create(\\n    model=\"gpt-4o-mini\",\\n    messages=[\\n{\\n “role”: \"user\" , \\n“content”: \"Write a one-sentence bedtime story about a unicorn. \"\\n}\\n    ]\\n)\\nprint(completion.choices[0].message.content)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 41, 'page_label': '42'}, page_content='Just like we’ve encountered before, our API request results in a JSON object which \\nwe can access using Python syntax. Since “choices” is an array of different choices, we \\nuse our index notation to get the ﬁrst object. We then subsequently get the \\nmessage, and then content of the response.\\nfrom openai import OpenAI\\nclient = OpenAI()\\ncompletion = client.chat.completions.create(\\n    model=\"gpt-4o-mini\",\\n    messages=[\\n{\\n “role”: \"user\" , \\n“content”: \"Write a one-sentence bedtime story about a unicorn. \"\\n}\\n    ]\\n)\\nprint(completion.choices[0].message.content)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 42, 'page_label': '43'}, page_content='Note that often we will have to transform our string content into another \\ndata-structure which we can later use in other parts of our program. This is especially \\ntrue for our second tlab.\\nfrom openai import OpenAI\\nclient = OpenAI()\\ncompletion = client.chat.completions.create(\\n    model=\"gpt-4o-mini\",\\n    messages=[\\n{\\n “role”: \"user\" , \\n“content”: \"Write a one-sentence bedtime story about a unicorn. \"\\n}\\n    ]\\n)\\nprint(completion.choices[0].message.content)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 43, 'page_label': '44'}, page_content='OpenAI API\\nSo far we’ve gone over simple requests to ChatGPT.\\nHowever, often times we also want to give directions that will be shown to \\nthe model, but not to the end-user themselves.\\nThis is especially important if you would like to generate some sort of \\nChat-bot which will have unmoderated interaction with a person. For \\nexample, maybe you want to tell your LLM that it should always have a \\ncheery disposition.\\nWe will use this for TLAB 2 in order to tell our \\nmodel what kind of responses it should craft.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 44, 'page_label': '45'}, page_content='T o provide these types of instructions to the model, you will have to include \\nanother message using the developer tag. Notice that this follows the same \\nformat as the original message, except this time we are setting up the \\ncontext for the models response.\\nfrom openai import OpenAI\\nclient = OpenAI()\\ncompletion = client.chat.completions.create(\\n    model=\"gpt-4o-mini\",\\n    messages=[\\n{ “role”: \"developer\" ,  “content”: \"You are a children\\'s short-story writer\" },\\n{ “role”: \"user\" ,  “content”: \"Write a one-sentence bedtime story about a unicorn. \" }\\n    ]\\n)\\nprint(completion.choices[0].message.content)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 45, 'page_label': '46'}, page_content='A question that you might have is, “What’s the point of this type of prompt?” \\nWell to answer that, we must delve into something called prompt \\nengineering.\\nfrom openai import OpenAI\\nclient = OpenAI()\\ncompletion = client.chat.completions.create(\\n    model=\"gpt-4o-mini\",\\n    messages=[\\n{ “role”: \"developer\" ,  “content”: \"You are a children\\'s short-story writer\" },\\n{ “role”: \"user\" ,  “content”: \"Write a one-sentence bedtime story about a unicorn. \" }\\n    ]\\n)\\nprint(completion.choices[0].message.content)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 46, 'page_label': '47'}, page_content='“Prompt Engineering”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 47, 'page_label': '48'}, page_content='Prompt Engineering\\nOne of the jobs that were predicted to come out of LLMs was prompt \\nengineering, which is the supposed job of solely interacting with an LLM \\nmodel to get some speciﬁc output.\\nThis is most likely not to going to be a job anytime soon, but it does \\nemphasize a certain kind of skill in LLM interactions.\\nIt’s important to note, we often overestimate the effect of short-term \\nchanges due to technological advances, but underestimate the long-term \\nchanges (Amara’s Law).'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 48, 'page_label': '49'}, page_content='Prompt Engineering\\nWith this disclaimer let’s go over what “prompt engineering” entails.\\nWhen you are interfacing with ChatGPT, you send text queries/requests \\nwhich it then “responds to. ” In reality it generates a probabilistic series of \\nwords that it predicts is the most likely answer you would like to see, based \\non historical data (the internet).\\nThe level of quality to these responses depends on the quality of your \\ninput.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 49, 'page_label': '50'}, page_content='Prompt Engineering\\nWe will attempt to minimize the anthropomorphization of this tool, but generally \\nspeaking, prompt engineering entails some tips which involve being an effective \\ncommunicator as a manager. This includes:\\n● Providing helpful examples\\n● Be speciﬁc in your request\\n● Do plenty of context setting, provide frameworks.\\nHowever there are other tips which only apply to LLMs. These include:\\n● “Gas up” your model: “Y ou are an expert in XYZ. Y ou can do ABC.”\\n● Emphasize that you need something ASAP. Quality of responses tend to be better.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 50, 'page_label': '51'}, page_content='Let’s say I’m asking ChatGPT to transform a list of text according to some \\nchanges. By providing helpful examples, I can get output closer to what I \\nexpect.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 51, 'page_label': '52'}, page_content='By context setting and specifying which language I’m working on/what my \\nproject should do, I can further reﬁne my outputs.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 52, 'page_label': '53'}, page_content='Finally, by being speciﬁc in my request, I can get my ﬁnal answer which only \\ncontains a Python list. This will be useful for when I am interacting with the \\ngpt-4o-mini API programmatically.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 53, 'page_label': '54'}, page_content='Prompt Engineering - Odd Tricks\\nAs we’ve explained, you can also include additional context to further reﬁne your \\nanswers.\\n“Gas up” your model: \\n● T ell the model how good it is at some speciﬁc task.\\n● Ex: “Y ou are an expert software engineer with 20 years of experience in the Python \\nlanguage. Y ou are aware of test-driven development…”\\nYou need something ASAP. \\n● I cannot ﬁnd the literature supporting this yet, but there’s an odd tip that if you \\ntell ChatGPT that you need something immediately, it performs “better”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 54, 'page_label': '55'}, page_content='Prompt Engineering - Odd Tricks\\nThere are a few other odd tricks with ChatGPT that seem like they might improve \\nperformance:\\n● https://news.ycombinator.com/item?id=39495476\\n○ Pretending to tip ChatGPT might cause it to write longer text\\n● https://www.reddit.com/r/ChatGPT/comments/18gg6sr/tell_gpt_its_may_and_i\\ntll_perform_better/ \\n○ If you tell ChatGPT it’s May, it might perform better.\\nT ake these with a grain of salt, none of this is established research.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 55, 'page_label': '56'}, page_content='OpenAI API Exercise'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 56, 'page_label': '57'}, page_content='OpenAI API Exercise\\nFor this exercise you will take set up your API token and begin practicing \\ninteracting with the OpenAI API.\\nHowever before you get started there are a couple of things to note:\\n● NEVER write your API key in publicly accessible code\\n● Be responsible with API usage'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 57, 'page_label': '58'}, page_content='Keeping APIs Safe\\nFor this project, we will send you all API keys. By tonight, we will delete \\nthese keys from the Slack channel. Please be present.\\nYou will set up your API keys in your conda environment (ds). Follow the \\nlisted directions carefully.\\nIf you complete tonights lab, you will get ahead on TLAB #2.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 58, 'page_label': '59'}, page_content='NOTE: You should always keep your key a secret. Never push your API key \\nto GitHub. Always use the environment variable instead.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 59, 'page_label': '60'}, page_content='Responsible use of APIs\\nBecause OpenAI API is a paid service, there incurs a charge every time you \\nuse the API. \\nT o prevent costs from exploding we’ve set up our project to limit the \\nnumber of requests that can occur per minute (100) and per day (1500).\\nIf you encounter a 429 error while running your project you must either:\\n● Wait 1 minute for the requests per minute (RPM) to reset\\n● Wait till the next day for the requests per day (RPD) to reset (this will \\nalmost never happen unless you collude to run as many requests as possible) \\nTherefore, you should make API requests \\nresponsibly:\\n● A few test runs are ok\\n● 100 test runs are not'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 60, 'page_label': '61'}, page_content='Using this idea, complete the following API exercise as a group. Join a \\ngroup to receive an API key.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 61, 'page_label': '62'}, page_content='Wrap-Up'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 62, 'page_label': '63'}, page_content='Lab (Due 04/21)\\nYou are a growth analyst at a Vancouver-based consulting ﬁrm called \\nMonica Group. Your manager is spearheading the completion of a a new \\nanalytical tool which will automatically label if a review is positive, neutral, \\nnegative, or irrelevant. \\nYou will be kicking off completion of this milestone by independently \\nimplementing a minimal-viable-product. This will be a Python pipeline that \\ningests a text-ﬁle of review data and interfaces with the Open AI API in \\norder to automatically label each review.\\nWe will release API keys on 4/1\\nVancouver, Canada'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Rest APIs II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Rest APIs II.pptx.pdf', 'total_pages': 64, 'page': 63, 'page_label': '64'}, page_content=\"Wednesday\\nWednesday will entail:\\n● A review of probability\\n● Applied probability\\n● Work on the OpenAI Lab\\n Jupyter: scratchpad of the data \\nscientist\\nIf you understand what you're doing, you're \\nnot learning anything. - Anonymous\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 0, 'page_label': '1'}, page_content='Applied Web Scraping I'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 1, 'page_label': '2'}, page_content='Agenda - Schedule\\n1. Warm Up\\n2. HTML Review\\n3. Introduction to Web Scraping \\n4. Using BS4\\n5. Break\\n6. Web Scraping Lab\\nWeb scraping software may directly access the World Wide \\nWeb using the Hypertext Transfer Protocol or a web browser. \\nWhile web scraping can be done manually by a software user, \\nthe term typically refers to automated processes implemented \\nusing a bot or web crawler. \\nhttps://en.wikipedia.org/wiki/Web_scraping'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 2, 'page_label': '3'}, page_content='Agenda - Announcements \\n● Monthly Satisfaction Survey due 4/7 https://theknowledgehouse.typeform.com/to/JyoK7IHd \\n● Week 5 Pre-Class Quiz due 4/8\\n● TLAB #2 due 4/21\\n● Add music to your respective Cohort Link!\\n○ We will use this for the music recommendation algorithm in Phase 2!\\n● Lastly, look for announcements from #data-science-fellowship-instructor-announcements'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 3, 'page_label': '4'}, page_content='Agenda - Goals\\n● Interpret HTML pages and tags\\n● Learn how to request data over the web and scrape via the bs4 package\\n● Learn about common Web-scraping Methods'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 4, 'page_label': '5'}, page_content='Warm-Up'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 5, 'page_label': '6'}, page_content='import requests\\nurl = “https://api.spotify.com/v1/me/tracks”\\nr = requests.get(url)\\ndata = r.json()\\nvals = [] \\nfor item in data[“items”]:\\ntrack = item[“track”]\\nname = track[“name”]\\nvals.append(name)\\nprint(vals)\\nJoin your pod groups and evaluate this chunk of code. Work together to \\nﬁgure out what will occur when we run this code. Assume the JSON object \\nto the right is the resource we get when running this code.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 6, 'page_label': '7'}, page_content='HTML Review'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 7, 'page_label': '8'}, page_content='Layers of Data Access\\nHowever, what if the data that we need is not provided by an API? What do \\nwe do then?\\n1. Structured CSV ﬁles/folders \\na. Usually provided freely by organization (but boring and not \\ntransformative)\\n2. API calls to get JSON ﬁles\\na. Either offered freely or through a paid service\\n3. Web-scraping\\na. Always free, but not always appreciated'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 8, 'page_label': '9'}, page_content='Well in such cases, we go forward with carefully web-scraping a web-page \\nto extract information. But how do we tell a computer to interpret this \\nstructure?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 9, 'page_label': '10'}, page_content='As it turns out, all web-pages are structured via HTML. This is a \\nsemi-structured format that we can interpret in our code just like JSON. But \\nﬁrst, how do we read HTML?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 10, 'page_label': '11'}, page_content='T o learn more about HTML, let’s take a look at some web-dev slides (Slides 8 - 16): https://docs.google.com/presentation/d/13xZTXU_fwg_Df5ukBNKMY4f_wg06sEP_mFX-oRBdc0s/edit#slide=id.g25d81a010a0_0_0'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 11, 'page_label': '12'}, page_content='Web-Scraping'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 12, 'page_label': '13'}, page_content='Web Scraping  - Challenges\\nBefore we get started with web-scraping, let’s address a few challenges you will \\nencounter in this process:\\n● Variability: when designing a web-scraper for a unique website, you will \\noften have to start from scratch and design a unique scraper.\\n● Durability: websites change! A scraper that works one day might not work \\nthe next.\\n● Responsibility: too many requests for information will result in your scraper \\ngetting kicked\\nTherefore, even as we learn more about these new concepts, the previous lessons \\nof documentation and testing still apply!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 13, 'page_label': '14'}, page_content='Web Scraping – Getting Started\\nBefore we begin, we should inspect the website that we will be scraping in order to understand its structure and URL.\\nWe can accomplish this by accessing our website and browsing through while noting the following objects:\\n● Interactions: How can I access “next” pages in my website?● The URL: How do I modify my URL to access different parts of the website?● Format of website: Where does my data reside?\\nFor this guided exercise, we are scraping \\nthe fake job-posting site: \\nhttps://realpython.github.io/fake-jobs/'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 14, 'page_label': '15'}, page_content='Let’s explore the different sections we can access through simple clicks. \\nFirstly, let’s recognize how our jobs are formatted on this site.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 15, 'page_label': '16'}, page_content='Next, let’s note how our URL changes as we click into different parts of the \\nsite. Currently we are on “realpython.github.io/fake-jobs”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 16, 'page_label': '17'}, page_content='But when clicking “apply” on a certain job posting, our url transforms to \\n“realpython.github.io/fake-jobs/senior-python-developer-0.html” . Does \\nthis pattern remind you of any other type of URL that we’ve been using?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 17, 'page_label': '18'}, page_content='But when clicking “apply” on a certain job posting, our url transforms to \\n“realpython.github.io/fake-jobs/senior-python-developer-0.html” . Does \\nthis pattern remind you of any other type of URL that we’ve been using?\\nhttps://pokeapi.co/api/v2/pokemon/pikachu …we access endpoints of Web APIs in \\nthe same fashion.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 18, 'page_label': '19'}, page_content='This is sufﬁcient for simple websites, but what if we are scraping other \\nwebsites that entail a search-engine? How can we modify which resource \\nwe access?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 19, 'page_label': '20'}, page_content='In this case, we begin using search parameters. For example, to pull all “remote data analyst” jobs in Indeed, we would use the following URL: https://www.indeed.com/jobs?q=data+analyst&l=remote Again, does this pattern remind you of any other type of URL that we’ve been using?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 20, 'page_label': '21'}, page_content='In this case, we begin using search parameters. For example, to pull all “remote data analyst” jobs in Indeed, we would use the following URL: https://www.indeed.com/jobs?q=data+analyst&l=remote Again, does this pattern remind you of any other type of URL that we’ve been using?\\nhttps://api.polygon.io/v2/aggs/ticker/AAPL/range/1/day/2023-01-09/2023-02-10?adjusted=true&sort=asc&apiKey=123456'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 21, 'page_label': '22'}, page_content='Web Scraping – Getting Started\\nAfter getting an understanding of the URL \\nand structure, we can then move on to \\ninspecting the HTML of the website. This \\nwill give us an understanding of the tags we \\nwill need to access to scrape pertinent data. \\nWe can do this by selecting “Inspect” from \\nthe menu that appears when we right-click \\non the page itself.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 22, 'page_label': '23'}, page_content='By viewing the HTML, we can anticipate the HTML tags that we will need to \\naccess when coding our web-scraping script. Here we see that all of our job \\ncards are inside of a tag called “div” , with the id “ResultsContainer. ”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 23, 'page_label': '24'}, page_content='Web Scraping – Pulling HTML\\nIn order to scrape our own web-pages, we ﬁrst need to “request” the HTML \\npage itself to pull it programmatically into our computer, does anyone recall \\nwhich Python package we can use to make HTTP GET request?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 24, 'page_label': '25'}, page_content='Web Scraping – Pulling HTML\\nWe use the requests module once more, along with the get method. \\nHowever, this time, instead of accessing a Web API, we are simply pulling an \\nHTML page as if we are browsing the web.\\nr = requests.get(\"https://realpython.github.io/fake-jobs/\")'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 25, 'page_label': '26'}, page_content='Web Scraping – Pulling HTML\\nNow that we have pulled our HTML \\nweb-page, we can print out the raw \\nbinary data from this request using \\nthe “ .content” ﬁeld \\nNotice that this gives you the HTML \\ncontent along with a b”” in the front.\\nThis is what we call a binary string. \\nEach character represents a byte (8 \\nbits)\\nURL = \"https://realpython.github.io/fake-jobs/\"\\npage = requests.get(URL )\\npage = r.content\\nprint(page)\\nb\\'<!DOCTYPE html>\\\\n<html>\\\\n  <head>\\\\n…’'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 26, 'page_label': '27'}, page_content='Parsing HTML Using BeautifulSoup4\\nHowever, we still need a way to interpret \\nthis structure. We will use BeautifulSoup \\nto parse this HTML structure.\\nFirst we create a BeautifulSoup object by \\npassing in the page.content as the ﬁrst \\nargument, with “html.parser” as the \\nsecond argument.\\nThis extracts key attributes from this \\npage, which we can then access via \\nmethods and ﬁelds.\\nURL = \"https://realpython.github.io/fake-jobs/\"\\npage = requests.get(URL )\\nsoup = BeautifulSoup(page.content, \"html.parser\")\\nThis is the ﬁrst object we access (the \\nroot) before analyzing the rest of the \\nweb-page.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 27, 'page_label': '28'}, page_content='Parsing HTML Using BeautifulSoup4\\nJust like our JSON object, we must access our \\nweb-page hierarchically (with soup as the entry \\npoint).\\nThe two most common methods that you will use \\nwhen parsing a web-page are:\\n● ﬁnd(name, attributes) : ﬁnd one element\\n● ﬁnd_all(name, attributes) : ﬁnd all elements \\nWe use these methods to ﬁnd unique tags inside \\nof web-pages and the data located inside of \\nthese tags.\\nURL = \"https://realpython.github.io/fake-jobs/\"\\npage = requests.get(URL )\\nsoup = BeautifulSoup(page.content, \"html.parser\")\\nresults = soup.ﬁnd(id=\" ... \")\\nWhat is label of the tag that contains all of \\nour job data?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 28, 'page_label': '29'}, page_content='The BS4 Application Programming Interface\\nWe can specify the type of tag we want to extract, as well as the class or id \\nof the tag by using different positional arguments.\\nWhen we call functions or methods, we can mix the position of arguments \\nas long as we specify which argument goes to which parameter.\\nsoup.ﬁnd(“tag-label” , class_=“class name”)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 29, 'page_label': '30'}, page_content='Parsing HTML Using BeautifulSoup4\\nNow that we’ve extracted the \\n“ResultsContainer” tag, we will continue \\nwith our pattern of ﬁnding tags hidden inside \\nof this new object. Note that we are no \\nlonger using the “soup” object.\\nWhich tags contain our job data, and which \\nmethod should we use to get all of these \\nobjects?\\n● ﬁnd(name, attributes) : ﬁnd one element\\n● ﬁnd_all(name, attributes) : ﬁnd all \\nelements \\nURL = \"https://realpython.github.io/fake-jobs/\"\\npage = requests.get(URL )\\nsoup = BeautifulSoup(page.content, \"html.parser\")\\nresults = soup.ﬁnd(id=\"ResultsContainer\")\\njob_elements = …'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 30, 'page_label': '31'}, page_content='Inspecting our web-page, we can see that the div that contains our content \\nis a class called “card. ” You may want to try using the “column is-half” div, \\nbut we always want to opt for the last possible div before accessing the \\ncontent itself, but feel free to experiment with different approaches.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 31, 'page_label': '32'}, page_content='Parsing HTML Using BeautifulSoup4\\nUsing the ﬁnd_all() method, we can \\nspecify that we want to ﬁnd all divs of \\nclass “card” inside of the “results” object.\\nWe’ll focus in on extracting the title, \\ncompany, and location of each job.\\nHow can we iterate on this list of job \\nelements?\\nURL = \"https://realpython.github.io/fake-jobs/\"\\npage = requests.get(URL )\\nsoup = BeautifulSoup(page.content, \"html.parser\")\\nresults = soup.ﬁnd(id=\"ResultsContainer\")\\njob_elements = results.ﬁnd_all(“div” , class_=”card”)\\n[“<div class=\"card-content\">... ” , “<div \\nclass=\"card-content\">... ” , “<div \\nclass=\"card-content\">... ”]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 32, 'page_label': '33'}, page_content='Parsing HTML Using BeautifulSoup4\\nBy looping through each element in our \\nlist, we can continue to use the ﬁnd() and \\nﬁnd_all() methods as we search for our \\ntargeted data.\\nWhich tags contain information about job \\ntitle, company, and location?\\nAgain, let’s look back to our HTML \\nstructure.\\njob_elements = results.ﬁnd_all(“div” , class_=”card”)\\nfor job in job_elements:\\ntitle = job.ﬁnd(...)\\ncompany = job.ﬁnd(...)\\nlocation = job.ﬁnd(...)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 33, 'page_label': '34'}, page_content='Once again, we ﬁnd the last tag that contains the title in our “card” divs. \\nWhat kind of tag contains our title, which type of class is this? We do the \\nsame kind of search for company and location.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 34, 'page_label': '35'}, page_content='Parsing HTML Using BeautifulSoup4\\nNow that we’ve identiﬁed the tags that \\ncontain our pertinent information, we \\ncan stop our recursion and simply extract \\nthe text located in each tag via the .text \\nattribute.\\nWe also call the .strip() method to \\nremove any remaining new-line or \\nwhite-space characters.\\njob_elements = results.ﬁnd_all(“div” , class_=”card”)\\nfor job in job_elements:\\ntitle = job.ﬁnd(“h2” , class_=”title”)\\ncompany = job.ﬁnd(“h2” , class_=”company”)\\nlocation = job.ﬁnd(“h2” , class_=”location”)\\nprint(title.text.strip())\\nprint(company .text.strip())\\nprint(location .text.strip())'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 35, 'page_label': '36'}, page_content='Parsing HTML Using BeautifulSoup4\\nWhile this is sufﬁcient to get all job \\ninformation from our HTML, what if we \\nwanted to instead ﬁlter our HTML tags \\nand instead ﬁnd only roles that have \\ncertain keywords?\\nFor example, if we were interested in \\ndeveloper careers, we might want to \\ninstead look for the keyword “Python. ”\\nT o accomplish this, we use regular \\nexpressions (regex)\\njob_elements = results.ﬁnd_all(“div” , class_=”card”)\\nfor job in job_elements:\\ntitle = job.ﬁnd(“h2” , class_=”title”)\\ncompany = job.ﬁnd(“h2” , class_=”company”)\\nlocation = job.ﬁnd(“h2” , class_=”location”)\\nprint(title.text.strip())\\nprint(company .text.strip())\\nprint(location .text.strip())'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 36, 'page_label': '37'}, page_content='Web Scraping Lab'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 37, 'page_label': '38'}, page_content='Using this syntax, get started with your web-scraping lab!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 38, 'page_label': '39'}, page_content='Wrap-Up'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 39, 'page_label': '40'}, page_content='Lab (Due 04/21)\\nYou are a growth analyst at a Vancouver-based consulting ﬁrm called \\nMonica Group. Your manager is spearheading the completion of a a new \\nanalytical tool which will automatically label if a review is positive, neutral, \\nnegative, or irrelevant. \\nYou will be kicking off completion of this milestone by independently \\nimplementing a minimal-viable-product. This will be a Python pipeline that \\ningests a text-ﬁle of review data and interfaces with the Open AI API in \\norder to automatically label each review.\\nWe released API keys.\\nVancouver, Canada'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping I.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping I.pptx.pdf', 'total_pages': 41, 'page': 40, 'page_label': '41'}, page_content=\"Tuesday\\nTuesday will entail:\\n● More web-scraping!\\n● Regular expressions   \\nJupyter: scratchpad of the data \\nscientist\\nIf you understand what you're doing, you're \\nnot learning anything. - Anonymous\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 0, 'page_label': '1'}, page_content='Applied Web Scraping II'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 1, 'page_label': '2'}, page_content='Agenda - Schedule\\n1. Warm Up\\n2. Web Scraping Review\\n3. List Methods \\n4. Regular Expressions\\n5. Break\\n6. Web Scraping Lab II\\nWeb scraping software may directly access the World Wide \\nWeb using the Hypertext Transfer Protocol or a web browser. \\nWhile web scraping can be done manually by a software user, \\nthe term typically refers to automated processes implemented \\nusing a bot or web crawler. \\nhttps://en.wikipedia.org/wiki/Web_scraping'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 2, 'page_label': '3'}, page_content='Agenda - Announcements \\n● Week 5 Pre-Class Quiz due 4/8\\n● TLAB #2 due 4/21\\n● Add music to your respective Cohort Link!\\n○ We will use this for the music recommendation algorithm in Phase \\n2!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 3, 'page_label': '4'}, page_content='Agenda - Goals\\n● Review web-scraping methods\\n● Learn about “advanced” web-scraping techniques \\n● Review string methods for TLAB #2 success\\n● Learn about the concept of regular expressions'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 4, 'page_label': '5'}, page_content='Web Scraping Review'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 5, 'page_label': '6'}, page_content='Web Scraping Review\\nLet’s take a second to review where \\nweb-scraping falls on the data science hierarchy \\nof needs. \\nLike we established, we must ﬁrst capture data \\nbefore we can apply any sort of analysis or \\nmachine learning.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 6, 'page_label': '7'}, page_content='Just like we learned about with WebAPI requests, we can integrate \\nweb-scraping into our ETL pipeline to eventually load data into a database!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 7, 'page_label': '8'}, page_content='WebScraping Review \\nT o recap web-scraping, we ﬁrst begin parsing \\nour HTML by creating a BeautifulSoup object. \\nFrom there we can access our data \\nhierarchically through 2 simple methods:\\n● ﬁnd(name, attributes) : ﬁnd one element\\n● ﬁnd_all(name, attributes) : ﬁnd all \\nelements (loaded into the list)\\nRemember, you must start web scraping by \\nlooking at your HTML! There’s no way to tell \\nwhich data you need unless you see it.\\nURL = \"https://realpython.github.io/fake-jobs/\"\\npage = requests.get(URL )\\nsoup = BeautifulSoup(page.content, \"html.parser\")\\nresults = soup.ﬁnd(...., class_=\" ... \")'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 8, 'page_label': '9'}, page_content='Handling Pagination\\nOne last concept we want to introduce you to is pagination.\\nLike we established, we won’t always have the luxury of inﬁnite scroll.\\nInstead, a website will be broken down into multiple pages.\\nIn order to implement this functionality, we can make use the `requests` \\npackage and simply keep requesting data until we have no more pages!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 9, 'page_label': '10'}, page_content='For this example, we will work through the “hacker news” website in order \\nto pull all articles from this site.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 10, 'page_label': '11'}, page_content='String Methods'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 11, 'page_label': '12'}, page_content='For your TLAB #2 success, we will go over a few string methods that are \\nimperative for your success.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 12, 'page_label': '13'}, page_content='Regex'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 13, 'page_label': '14'}, page_content='Regular Expressions (Regex)\\nOne tool you will ﬁnd yourself using for \\ntext-parsing is regular expressions \\n(regex)\\nRegex is a powerful concept taken from \\nlinguistics that allows us to quickly \\nsearch for text in a text corpus.\\ntext corpus: collection of words'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 14, 'page_label': '15'}, page_content='We’ll go over a few regex patterns. However this will not be an exhaustive \\nlesson, the best resource to learn regex is arguably: \\nhttps://regexone.com/lesson/introduction_abcs'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 15, 'page_label': '16'}, page_content='T o search for text using regex, you simply describe a pattern of text to search for. Regex then searches your selected string to check if it satisfy’s this pattern. Let’s assume we’re iterating through a list of strings.\\nreview\\nFarukh is great\\nWell, Farukh is ok\\nFarrrrukh is terrible\\nI like Python27\\n@@@19586\\nRegex Pattern'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 16, 'page_label': '17'}, page_content='For example, by just using the regex string “Farukh” , we will look for all rows \\nthat contain the string “Farukh. ” Which rows will be matched?\\nreview\\nFarukh is great\\nWell, Farukh is ok\\nFarrrrukh is terrible\\nI like Python27\\n@@@19586\\nRegex Pattern\\nFarukh'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 17, 'page_label': '18'}, page_content='Elements 0 & 1 get matched. Why doesn’t row 2 get matched?\\nreview\\nFarukh is great\\nWell, Farukh is ok\\nFarrrrukh is terrible\\nI like Python27\\n@@@19586\\nRegex Pattern\\nFarukh'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 18, 'page_label': '19'}, page_content='Farrrrukh is not the same as Farukh\\nreview\\nFarukh is great\\nWell, Farukh is ok\\nFarrrrukh is terrible\\nI like Python27\\n@@@19586\\nRegex Pattern\\nFarukh\\nRemember, a \\ncomputer does not \\nunderstand intent. It \\nwill only do exactly \\nwhat you want it to do'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 19, 'page_label': '20'}, page_content='However, we can use special regex characters to indicate when we want to match words that contain repeating characters. We place the * after the letter we want to match multiple times. T o match the 2nd row (along with the 0th and 1st), where should we place our asterisk?\\nreview\\nFarukh is great\\nWell, Farukh is ok\\nFarrrrukh is terrible\\nI like Python27\\n@@@19586\\nRegex Pattern\\nFarukh'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 20, 'page_label': '21'}, page_content='We place it after the “r. ” Now we will match all misspellings of “Farukh” that \\ncontain duplicate r’s\\nreview\\nFarukh is great\\nWell, Farukh is ok\\nFarrrrukh is terrible\\nI like Python27\\n@@@19586\\nRegex Pattern\\nFar*ukh'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 21, 'page_label': '22'}, page_content='By placing a caret at the front, we only ﬁnd reviews that that begin with the \\nword “Farukh” with an arbitrary number of r’s/\\nreview\\nFarukh is great\\nWell, Farukh is ok\\nFarrrrukh is terrible\\nI like Python27\\n@@@19586\\nRegex Pattern\\n^Far*ukh'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 22, 'page_label': '23'}, page_content='There are many more regex patterns, and the only way to ﬁgure out which one to use is via practice. So as long as you understand the general idea of regex, you should be able to make your own pattern.Using these tables, what do we write to match rows that end with a number?\\nreview\\nFarukh is great\\nWell, Farukh is ok\\nFarrrrukh is terrible\\nI like Python27\\n@@@19586\\nRegex Pattern'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 23, 'page_label': '24'}, page_content='Knowing regex will save you hours of work. \\nreview\\nFarukh is great\\nWell, Farukh is ok\\nFarrrrukh is terrible\\nI like Python27\\n@@@19586\\nRegex Pattern\\n\\\\d$'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 24, 'page_label': '25'}, page_content='T o practice more regex, check out regex101'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 25, 'page_label': '26'}, page_content='Parsing HTML Using BeautifulSoup4\\nWith this new tool in our belt, we can \\neffectively search for strings that contain \\nthe “Python” keyword.\\nThis, however, is the most simple example \\nof a regex string that you will be \\nconstructing. \\nJust as we’ve seen in the previous slides, \\nweb-data (especially when it’s posted on \\na social network) is rarely this clean.\\nimport re\\njob_elements = results.ﬁnd_all(“div” , class_=”card”)\\nfor job in job_elements:\\ntitle = job.ﬁnd(“h2” , class_=”title”)\\nmatch = re.search(r\"Python\" , title .text)\\nif match:\\n print(title.text.strip())'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 26, 'page_label': '27'}, page_content='The fact is, we will not be going over the entire API for any package. And \\ntruthfully this isn’t knowledge that you necessarily should be carrying \\naround anyways. Always use the documentation.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 27, 'page_label': '28'}, page_content='Web Scraping Lab II'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 28, 'page_label': '29'}, page_content='Using this syntax, get started with your web-scraping lab!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 29, 'page_label': '30'}, page_content='Wrap-Up'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 30, 'page_label': '31'}, page_content='Lab (Due 04/21)\\nYou are a growth analyst at a Vancouver-based consulting ﬁrm called \\nMonica Group. Your manager is spearheading the completion of a a new \\nanalytical tool which will automatically label if a review is positive, neutral, \\nnegative, or irrelevant. \\nYou will be kicking off completion of this milestone by independently \\nimplementing a minimal-viable-product. This will be a Python pipeline that \\ningests a text-ﬁle of review data and interfaces with the Open AI API in \\norder to automatically label each review.\\nWe will release API keys on 4/1\\nVancouver, Canada'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Applied Web Scraping II.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Applied Web Scraping II.pptx.pdf', 'total_pages': 32, 'page': 31, 'page_label': '32'}, page_content=\"Wednesday\\nWednesday will entail:\\n● Hypothesis testing\\n● Applied hypothesis testing in data analysis \\nJupyter: scratchpad of the data \\nscientist\\nIf you understand what you're doing, you're \\nnot learning anything. - Anonymous\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 0, 'page_label': '1'}, page_content='Introduction to Naive \\nBayes Classifier'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 1, 'page_label': '2'}, page_content='Agenda - Schedule\\n1. Kahoot\\n2. Supervised Learning\\n3. Classiﬁcation T asks\\n4. Bayes Theorem\\n5. Break\\n6. Probability Lab It’s stats all the way down'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 2, 'page_label': '3'}, page_content='Agenda - Goals\\n● …'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 3, 'page_label': '4'}, page_content='Announcements\\n● …'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 4, 'page_label': '5'}, page_content='Warm Up'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 5, 'page_label': '6'}, page_content='Start Week 4 Kahoot - Logistic Regression'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 6, 'page_label': '7'}, page_content='Supervised Learning Review'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 7, 'page_label': '8'}, page_content='Now that we are thoroughly in Machine Learning territory, let’s go over the \\ndifferences between 2 types of supervised learning.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 8, 'page_label': '9'}, page_content='Supervised Learning\\nSupervised learning: output is known (a target is provided), model needs to \\nrecreate relationships. We “learn” which weights create a function predicts \\n○ Evaluation: Tested against the known data. How well did it identify what \\nwe know already?\\nSVM! \\nHere are my classes. What differentiates class 1 from \\nclass 2? Wow! 100% accuracy!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 9, 'page_label': '10'}, page_content='Unsupervised Learning\\nUnsupervised learning: output is unknown (target is not provided), model needs \\nto discover structure \\n○ Evaluation: Tested against relative performance criteria. How well did it \\nidentify sensible structure?\\nI have data, but I have no clue as to which classes I’m \\nseeing.\\nk-Means! \\nWow! Classes (I think)!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 10, 'page_label': '11'}, page_content='Supervised Learning - Training Methods\\nUntil week 8, we will be focusing on supervised learning methods and various case studies. \\nLet’s look at a high-level version of the supervised learning logistic regression algorithm.\\nX\\neβ0 + β1X\\n1+ eβ0 + β1X\\n Predicted \\ndata Y'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 11, 'page_label': '12'}, page_content='Supervised Learning - Training Methods\\neβ0 + β1X\\n1+ eβ0 + β1X\\n Predicted \\ndata \\nWe start with our \\npredictors (X) and our \\nknown targets (y)\\nX Y'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 12, 'page_label': '13'}, page_content='Supervised Learning - Training Methods\\neβ0 + β1X\\n1+ eβ0 + β1X\\n Predicted \\ndata \\nWe assume that this \\nfunction is sufﬁcient \\nto model the decision \\nboundary! \\nX Y'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 13, 'page_label': '14'}, page_content='Supervised Learning - Training Methods\\neβ0 + β1X\\n1+ eβ0 + β1X\\n Predicted \\ndata \\nThe model that we \\nuse has to be a \\ncompetent decision \\nmade by a human\\nX Y'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 14, 'page_label': '15'}, page_content='Supervised Learning - Training Methods\\neβ0 + β1X\\n1+ eβ0 + β1X\\n Predicted \\ndata \\nLet’s say that we start with a \\nguess for our weights (or \\ncoefﬁcients). We’ll assume \\nB0=0 and B1 = 1\\nX Y'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 15, 'page_label': '16'}, page_content='Supervised Learning - Training Methods\\ne0 + 0X\\n1+ e0 + 0X\\n Predicted \\ndata \\nOf course, this will result in \\npoor predictive performance. \\nHowever the model does \\nnot know that yet!\\nX Y'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 16, 'page_label': '17'}, page_content='Supervised Learning - Training Methods\\ne0 + 0X\\n1+ e0 + 0X\\n Predicted \\ndata \\nIt will calculate the MLE \\nof these coefﬁcients…\\nX Y'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 17, 'page_label': '18'}, page_content='Supervised Learning - Training Methods\\ne0 + 0X\\n1+ e0 + 0X\\n Predicted \\ndata \\nCome away with the \\n“error” or “cost” of using \\nthese coefﬁcients \\nX Y'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 18, 'page_label': '19'}, page_content='Supervised Learning - Training Methods\\ne1 + 0.5X\\n1+ e1 + 0.5X\\n Predicted \\ndata \\nAnd utilize calculus to push \\nthese  weights to a higher \\nMLE value!*\\nX Y\\n*Keep in mind that this is an extreme \\nover-simpliﬁcation of the algorithm. \\nYou must be familiar with the maths \\nbehind this to be a competent \\ndata-scientist. This high-level \\noverview is just a refresher.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 19, 'page_label': '20'}, page_content='Supervised Learning - Training Methods\\ne… + …X\\n1+ e… + …X\\n Predicted \\ndata \\nWe keep repeating these steps until \\nwe reach a certain number of \\niterations, or we simply cannot \\nimprove our cost further\\nX Y'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 20, 'page_label': '21'}, page_content='Supervised Learning - Training Methods\\ne… + …X\\n1+ e… + …X\\n Predicted \\ndata \\n3 train - 1 test\\nBeyond this, we have methods for \\ncross-validation…\\nX Y'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 21, 'page_label': '22'}, page_content='Optimize learning rate \\nSupervised Learning - Training Methods\\ne… + …X\\n1+ e… + …X\\n Predicted \\ndata \\nHyperparameter tuning…\\nX Y'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 22, 'page_label': '23'}, page_content='Calc accuracy, precision, … \\nSupervised Learning - Training Methods\\ne… + …X\\n1+ e… + …X\\n Predicted \\ndata \\nAnd lastly, model evaluation\\nX Y'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 23, 'page_label': '24'}, page_content='Supervised Learning - Applications\\nWe want to keep in mind that both types of ML have their utility in practical business and \\nresearch applications! No one methodology is superior.  When deciding which type of \\nalgorithm to apply, consider the following practical questions:\\n● Is my data labeled?\\n● Are my goals predictive or exploratory? \\n○ When we have something to predict, we usually want to opt for supervised learning. \\nHowever, if your aims are to explore structure and patterns, then perhaps unsupervised \\nlearning should be your goto.\\n● Do I have enough supplemented or domain knowledge on my target variable?\\n○ Was this target selected because it was available, or was this target selected for intentional \\nreasons?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 24, 'page_label': '25'}, page_content='Classiﬁcation Review'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 25, 'page_label': '26'}, page_content='Classiﬁcation: Binary Categories\\nIn the context of logistic regression (and naive bayes!), we always consider \\na binary classiﬁer to be an “on and off” switch. Is something present or is it \\nnot?\\n● Fraud vs not fraud\\n● Malignant vs nonmalignant \\n● Human vs not human\\n● Dog vs not dog\\nIs this a \\ndog or not  \\na dog?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 26, 'page_label': '27'}, page_content='In binary classiﬁcation, we round the calculated probability to either a 1 or 0 using a cutoff of 0.5. For example, 0.6 will be rounded to 1, therefore belongs to the “dog” class. Anything below 0.5 will belong to the “not dog” class.\\nYpred_dog = { \\n<=0.5 → Not dog \\n>0.5 → Dog\\nkibble_grams noise_dB dog\\n200 40 0\\n250 60 1\\n115 45 0\\n300 80 1\\n<- A not-dog'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 27, 'page_label': '28'}, page_content='Classiﬁcation: Multiple Categories\\nLet’s say we wanted to create a classiﬁcation system that can identify if an \\nimage contains a dog, cat, or hamster (K=3). Let’s assume that we can only \\nuse binary classiﬁers. \\nHow can we use binary classiﬁers to identify multiple classes?\\nFeel free to mention different ideas until something sticks.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 28, 'page_label': '29'}, page_content='Classiﬁcation: Multiple Categories\\nLet’s say we wanted to create a classiﬁcation system that can identify if an \\nimage contains a dog, cat, or hamster (K=3). Let’s assume that we can only \\nuse binary classiﬁers. \\nHow can we use binary classiﬁers to identify multiple classes?\\nFeel free to mention different ideas until something sticks.\\nMaybe try multiple classiﬁers???'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 29, 'page_label': '30'}, page_content='Let’s assume the following dataset. Note : some classiﬁers require this vector of 1’s and 0’s. \\nY = { \\n????\\nkibble_grams noise_dB dog cat hamster\\n200 40 0 1 0\\n250 60 1 0 0\\n115 45 0 1 0\\n300 80 1 0 0\\n50 75 0 0 1'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 30, 'page_label': '31'}, page_content='Which we then plot to this scatter-plot.\\nnoise_dB\\nkibble_grams\\n100\\n200\\n300\\n15 30 45 60 75 90 105 120\\n*We’re assuming loud \\nhamsters'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 31, 'page_label': '32'}, page_content='Let’s consider the following, we create a logistic regressor that only looks for hamsters. All other \\ndata-points will just be non-hamsters. This gives us one decision boundary.\\nnoise_dB\\nkibble_grams\\n100\\n200\\n300\\n15 30 45 60 75 90 105 120\\nLogisticHamster= eβ0 + β1X\\n1+ eβ0 + β1X'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 32, 'page_label': '33'}, page_content='Considering we made one decision boundary, then how many logistic regressors should we create for all 3 \\nclasses?\\nnoise_dB\\nkibble_grams\\n100\\n200\\n300\\n15 30 45 60 75 90 105 120\\nLogisticHamster= eβ0 + β1X\\n1+ eβ0 + β1X'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 33, 'page_label': '34'}, page_content='If we want to classify 3 classes, then we should create 3 binary classiﬁers! That is, for K classes we make K \\nbinary classiﬁers! This methodology is called one-versus-all. There is another technique called \\none-versus-one classiﬁcation which we will explore later (but generally applies the same idea).\\nnoise_dB\\nkibble_grams\\n100\\n200\\n300\\n15 30 45 60 75 90 105 120\\nLogisticHamster= eβ0 + β1X\\n1+ eβ0 + β1X\\nLogisticCat= eβ0 + β1X\\n1+ eβ0 + β1X\\nLogisticDog= eβ0 + β1X\\n1+ eβ0 + β1X'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 34, 'page_label': '35'}, page_content='You might be thinking, “Hey (Mickal/Farukh), what about our poor misclassiﬁed hamster friend? Does it \\nbecome a cat?”\\nnoise_dB\\nkibble_grams\\n100\\n200\\n300\\n15 30 45 60 75 90 105 120\\nLogisticHamster= eβ0 + β1X\\n1+ eβ0 + β1X\\nLogisticCat= eβ0 + β1X\\n1+ eβ0 + β1X\\nLogisticDog= eβ0 + β1X\\n1+ eβ0 + β1X'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 35, 'page_label': '36'}, page_content='No! The beauty of this method is that we assign classes based on the probabilities. Therefore if we have a \\nmore conﬁdent prediction for hamster, then we will likewise classify it as a hamster! \\nnoise_dB\\nkibble_grams\\n100\\n200\\n300\\n15 30 45 60 75 90 105 120\\nLogisticHamster= eβ0 + β1X\\n1+ eβ0 + β1X\\nLogisticCat= eβ0 + β1X\\n1+ eβ0 + β1X\\nLogisticDog= eβ0 + β1X\\n1+ eβ0 + β1X'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 36, 'page_label': '37'}, page_content='This could be interpreted two ways:\\n● We assign classes based on how many times a model “voted” for a speciﬁc classiﬁcation\\n● We assign classes based on “highest probability” that something belongs to a class.\\nnoise_dB\\nkibble_grams\\n100\\n200\\n300\\n15 30 45 60 75 90 105 120\\nLogisticHamster= eβ0 + β1X\\n1+ eβ0 + β1X\\nLogisticCat= eβ0 + β1X\\n1+ eβ0 + β1X\\nLogisticDog= eβ0 + β1X\\n1+ eβ0 + β1X'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 37, 'page_label': '38'}, page_content='Classiﬁcation: One vs One; One vs Rest\\nThis describes a very speciﬁc strategy to classify your dataset when you have multiple classes. \\nThere are two ways we can implement this.\\nOne vs Rest\\n● Create one classiﬁer per unique class, with samples of that class being considered positive \\ncases, and all other classes considered negative.\\nOne vs One\\n● Create one classiﬁer for every pair of classes. If there are “n” classes, you will train \\n(n*(n-1)/2) classiﬁers. We decide on tie-breakers by seeing how many times a sample is \\nclassiﬁed as a speciﬁc class. The class with the most “votes” wins.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 38, 'page_label': '39'}, page_content='Classiﬁcation: One vs One; One vs Rest\\nPros\\n● Simple implementation. More classes → More models!\\n● Can model a non-linear decision boundary. This is a \\nterm that we will explore more tomorrow.\\nHowever, there are negative consequences to this as well…'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 39, 'page_label': '40'}, page_content='Classiﬁcation: One vs. All Binary Classiﬁers \\nIn the one-vs-rest approach, we train \\nK binary classiﬁers, each time \\ncomparing one of the K classes to the \\nremaining K-1 classes.\\nWe assign observations to class for \\nwhich has the highest probability, as \\n“this amounts to the highest level of \\nconﬁdence that the test observation \\nbelongs to the kth class.”\\nBut what are the down-sides to this?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 40, 'page_label': '41'}, page_content='What if I don’t have 3 classes, but instead…\\nnoise_dB\\nkibble_grams\\n100\\n200\\n300\\n15 30 45 60 75 90 105 120'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 41, 'page_label': '42'}, page_content='What if I don’t have 3 classes, but instead…100 CLASSES\\nnoise_dB\\nkibble_grams\\n100\\n200\\n300\\n15 30 45 60 75 90 105 120'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 42, 'page_label': '43'}, page_content='This will necessitate that we create 100 models. Keep in mind that creating machine learning models is \\nexpensive in terms of time and resources. This becomes more applicable as we move to enterprise \\nenvironments. We would much rather prefer a cheaper alternative. \\nnoise_dB\\nkibble_grams\\n100\\n200\\n300\\n15 30 45 60 75 90 105 120'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 43, 'page_label': '44'}, page_content='Classiﬁcation: Multiple Categories\\nThis “cheaper alternative” are inherently multiclass classiﬁers (kNN,  \\ndecision trees). This allows us to have one model for identifying multiple \\nclasses. Some examples include:\\n● Digits: (0,1,2,3,4,5,6,7,8,9)\\n● Flower-type: (rose, tulip, petunia)\\n● Dog, cat, or hamster\\nIs this a \\ndog, a cat, \\nor a \\nhamster?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 44, 'page_label': '45'}, page_content='We want to use multiclass classiﬁers when we have K>2 classes, and we assume that each sample can only have one class. Sometimes, multiclass classiﬁers output probabilities.\\nY = [prob_dog, prob_cat, prob_ham]\\nkibble_grams noise_dB animal\\n200 40 cat\\n250 60 dog\\n115 45 cat\\n300 80 dog\\n50 75 hamster'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 45, 'page_label': '46'}, page_content='Other times they output discrete classes. Keep in mind however that most models support both outputs. \\nY = { \\ndog\\ncat\\nhamster\\nkibble_grams noise_dB animal\\n200 40 cat\\n250 60 dog\\n115 45 cat\\n300 80 dog\\n50 75 hamster'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 46, 'page_label': '47'}, page_content='Classiﬁcation: Multilabel Classiﬁcation\\nFinally, there is one more type of classiﬁcation, called multi-label \\nclassiﬁcation. Once again, we also calculate probabilities of a sample \\nbelonging to a class, however this time we assume that samples can belong \\nto multiple classes!\\n● Movie genre: horror, horror & comedy, …\\n● Computer Vision: dog, dog & cat, …\\n● Document Org: law, law & ﬁnancial, …\\nWhich \\nanimals \\ndoes this \\nphoto \\ncontain?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 47, 'page_label': '48'}, page_content='A good way to internalize this, is the fact that multi-label classiﬁers are a variant of multi-class classiﬁers, \\nexcept that we permit 0 or more classes to belong to one sample!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 48, 'page_label': '49'}, page_content='Bayes Theorem'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 49, 'page_label': '50'}, page_content='Bayes Theorem - Frequentist World-View \\nSo far, in our discussion of statistics and probability, we have assumed a frequentist \\nworld-view. \\nThat is, we deﬁne probability as simply a long-run frequency. For example, do you want \\nto ﬁgure out the probability of ﬂipping heads on a quarter? Simply run an experiment!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 50, 'page_label': '51'}, page_content='Bayes Theorem - Frequentist Pros\\nWe like this world-view because it is:\\n● Objective: we run experiments to ﬁgure out the world\\n● Unambiguous: you and I will calculate the same probability from one experiment'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 51, 'page_label': '52'}, page_content='Bayes Theorem - Frequentist Cons \\nBut, there are also negatives to this world-view:\\n● No use of prior information: when running our experiment, we close \\nourselves off from any prior information. \\n● Inﬂexible: Frequentists rely on large amounts of data to make statements \\non probability.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 52, 'page_label': '53'}, page_content='Bayes Theorem - Frequentist Cons \\nT o further explain the limitations of the frequentist perspective, let’s say I \\ngive you a coin. I tell you that there is a 30% chance that this coin lands on \\nheads.\\nFrom our previous perspective, how do we use this information? Well we \\nbasically chuck it in the trash.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 53, 'page_label': '54'}, page_content='Bayes Theorem - Bayesian Statistics  \\nEnter Thomas Bayes. \\nHe introduced probability as a degree \\nof belief to which a “rational agent” \\nassigns a truth to an event… \\n…as opposed to a ratio of experiments. \\nThis degree of belief is updated with \\nnew information. Let’s see an \\nexample…\\n Full-time minister, part-time \\nstatistician'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 54, 'page_label': '55'}, page_content='You’re approached by a hamster with a quarter and a proposition. Every time the coin lands on heads, \\nyou have to give him a carrot. Every time the coin lands on tails, he gives you a carrot.\\n*MidJourney Image of Hamster Flipping a \\nCoin'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 55, 'page_label': '56'}, page_content='First off, let’s understand what assumptions \\nwe’ve made about this game. What is your \\n“assumption” about the probability of this \\nbeing a fair game?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 56, 'page_label': '57'}, page_content='Let’s assume we don’t believe this hamster is \\nnefarious, but since we don’t personally know \\nthis hamster, we have an inkling of suspicion. \\nWe assume 98% chance of fairness\\nWe’ll keep this “belief” in mind.\\nP(Hyp) = 0.98'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 57, 'page_label': '58'}, page_content='An Aside - A Fair Coin\\nLet’s rehash what a “fair coin” means. \\nWe assume that the chance of a coin landing on the heads side, is equal to \\nthe chance of it landing on the tails side.\\nSince there are only 2 possible outcomes. What do we say is the probability \\nof landing on heads and tails???\\nP(Heads) = ? P(T ails) = ?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 58, 'page_label': '59'}, page_content='An Aside - A Fair Coin\\nLet’s rehash what a “fair coin” means. \\nWe assume that the chance of a coin landing on the heads side, is equal to \\nthe chance of it landing on the tails side.\\nSince there are only 2 possible outcomes. What do we say is the probability \\nof landing on heads and tails???\\nP(Heads) = 0.5 P(T ails) = 0.5'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 59, 'page_label': '60'}, page_content='An Aside - A Fair Coin\\nThis probability of 98% that we are using is a bit of a meta-probability.\\nFrom a frequentist point of view, we are basically stating that out of 100 \\ntimes that this hamster will ask us to play this game, 98 times will be played \\nwith a fair coin, whereas 2 times will be played with a biased coin.\\nIt’s a stretch of imagination, but bear with us.\\nP(Heads) = 0.5 P(T ails) = 0.5'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 60, 'page_label': '61'}, page_content='An Aside - A Fair Coin\\nFiguring out what this biased coin will behave like is out of scope of this \\nthought experiment, \\nso let’s just assume that if this hamster is tricking us, it is using a coin that is \\nbiased towards heads.\\nP(Heads) = 0.8 P(T ails) = 0.2'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 61, 'page_label': '62'}, page_content='P(Hyp) = 0.98\\nFirst round the hamster ﬂips heads. \\nDo we have reason to doubt our initial \\nassumption yet?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 62, 'page_label': '63'}, page_content='Probably not.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 63, 'page_label': '64'}, page_content='P(Hyp) = 0.98\\nAfter 4 rounds the hamster keeps ﬂipping \\nheads. \\nDo we have reason to doubt our initial \\nassumption yet?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 64, 'page_label': '65'}, page_content='Most likely yes! But which new \\nprobability do we use for the \\nprobability of heads? \\nThe frequentist framework does not \\ngive us an easy answer.\\nBayes, however, provides a formula for \\nupdating beliefs with evidence!\\n*MidJourney Image of Nefarious \\nHamster Flipping a Coin'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 65, 'page_label': '66'}, page_content='Here’s the formula, let’s break down its components before going through our hamster example again\\nP(H|E) = P(H)  P(E|H)\\nP(E)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 66, 'page_label': '67'}, page_content='P(H|E) = P(H)  P(E|H)\\nP(E)\\nRemember, the “|” is the symbol \\nfor conditional probability \\nstatements.\\n“Hypothesis given Event”\\nThe probability the hypothesis is true given the event is equal to'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 67, 'page_label': '68'}, page_content='The probability the hypothesis is true given the event is equal to\\nP(H|E) = P(H)  P(E|H)\\nP(E)\\nProbability of the hypothesis \\noccurring (also known as the \\nprior belief!)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 68, 'page_label': '69'}, page_content='The probability the hypothesis is true given the event is equal to\\nP(H|E) = P(H)  P(E|H)\\nP(E)\\nProbability of the hypothesis \\noccurring (also known as the \\nprior belief!)\\nProbability of seeing event \\ngiven that the hypothesis is \\ntrue (also known as the \\nlikelihood*)\\n*note that probability and \\nlikelihood are not the same \\nthing!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 69, 'page_label': '70'}, page_content='The probability of event occurring. This part is sometimes deceptively simple. Keep in mind that we want \\nto consider the event occurs given the hypothesis is true and given the hypothesis is false!\\nP(H|E) = P(H)  P(E|H)\\nP(E)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 70, 'page_label': '71'}, page_content='Let’s understand how to calculate this. I ﬁnd diagrams to be the most helpful \\nin visualizing this calculation \\nSample Space  \\n(AKA not H)\\nProb of \\nobserving H\\nP(H)\\nProb of \\nobserving E\\nP(E)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 71, 'page_label': '72'}, page_content='T o calculate P(E), we have to consider the intersection of P(E) and P(H), as \\nwell as the space where P(E) exists outside of P(H)\\nSample Space \\n(AKA not H)\\nP(H)\\nP(E)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 72, 'page_label': '73'}, page_content='This intersect can be labeled P(E & H)\\nSample Space \\n(AKA not H) \\nP(H)\\nP(E&H)\\nP(E)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 73, 'page_label': '74'}, page_content='In terms of conditional probability, that is P(H)P(E|H)\\nSample Space  \\n(AKA not H)\\nP(H)\\nP(E&H)\\nP(E)\\nP(H)P(E|H) +'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 74, 'page_label': '75'}, page_content='And lastly we have P(E & -H). Can anyone express this in terms of \\nconditional probability as well?\\nSample Space  \\n(AKA not H)\\nP(H)\\nP(E&H)\\nP(E)\\nP(H)P(E|H) + \\nP(E&-H)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 75, 'page_label': '76'}, page_content='P(-H)P(E|-H). This allows us to express P(E) as P(H)P(E|H) + P(-H)P(E|-H) \\nSample Space \\n(AKA not H) \\nP(H)\\nP(E&H)\\nP(E)\\nP(H)P(E|H) + P(-H)P(E|-H) \\nP(E&-H)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 76, 'page_label': '77'}, page_content='This is expressed as the sum of the probability of the hypothesis is true and the event occurs given the \\nhypothesis is true, with the probability the hypothesis is false and the event occurs given the \\nhypothesis is false.\\nP(H|E) = P(H)  P(E|H)\\nP(H)P(E|H) + P(-H)P(E|-H)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 77, 'page_label': '78'}, page_content='Let’s summarize this: the probability of a hypothesis given an event is our previous evidence multiplied by \\nthe probability of the event occurring ASSUMING OUR HYPOTHESIS IS TRUE.\\nP(H|E) = P(H)  P(E|H)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 78, 'page_label': '79'}, page_content='Divided by the probability of the event occurring when the hypothesis is true or not true!\\nP(H|E) = P(H)  P(E|H)\\nP(H)P(E|H) + P(-H)P(E|-H)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 79, 'page_label': '80'}, page_content='Let’s apply this framework to our hamster \\nexperiment\\nP(H|E) = Likelihood that hypothesis (not scam) \\nis true\\nP(H) = Our prior understanding of the \\nhypothesis\\nP(E|H) = Likelihood of ﬂipping heads given \\nbelief that the coin is fair\\nP(E|-H) = Likelihood of ﬂipping heads given \\nbelief that the coin is unfair\\nP(-H) = Chance hypothesis is NOT true \\n(1-P(H))\\nP(H|E) = \\nP(H)  P(E|H)\\nP(H)P(E|H) + P(-H)P(E|-H)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 80, 'page_label': '81'}, page_content='With this new formula in mind, let’s see how \\nour probability of us landing on tails updates \\nwith each additional ﬂip from our \\nscam-hamster. I switch some letters around:\\nH = “Coin is fair”\\nE = “Outcome of the bet”\\nOne challenge however is, what is our “prior” \\nbelief that the coin is fair?\\nP(H|E) = \\nP(H)  P(E|H)\\nP(H)P(E|H) + P(-H)P(E|-H)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 81, 'page_label': '82'}, page_content='For our “prior” we usually use the most \\navailable evidence of our probability. Let’s \\nbring back our prior assumption of 0.98.\\nP(H|E) = \\nP(H)  P(E|H)\\nP(H)P(E|H) + P(-H)P(E|-H)\\nP(H) = 0.98'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 82, 'page_label': '83'}, page_content='P(H) = 0.98\\nLet’s play the game again. First round, hammy \\nwins. We reach in our pocket and give it a \\nloose baby carrot.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 83, 'page_label': '84'}, page_content='Let’s recalculate our probabilities. Let’s see if we can \\ncalculate these ourselves.\\nP(H) = 0.98\\nP(E|H) = Probability of heads given fair coin\\nP(-H)  = Probability of unfairness\\nP(E|-H) = Probability of heads given unfair coin\\n \\nP(H|E) = \\nP(H)  P(E|H)\\nP(H)P(E|H) + P(-H)P(E|-H)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 84, 'page_label': '85'}, page_content='Let’s recalculate our probabilities. Let’s see if we can \\ncalculate these ourselves.\\nP(H) = 0.98\\nP(E|H) = 0.5\\nP(-H)  = 0.02\\nP(E|-H) = 0.8*\\n*This one is tricky, let’s just say we’re looking for \\nevidence of a biased coin towards heads, so we use \\nsome arbitrary probability that leans towards heads\\n \\nP(H|E) = \\n(0.98)(0.5)\\n(0.98)(0.5) + (0.02)(0.8)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 85, 'page_label': '86'}, page_content='We get 0.96. And this makes sense, we slightly \\ndecreased the probability that this coin is fair. We’ve \\nupdated our beliefs with evidence.\\nThis probability BECOMES OUR NEW PRIOR P(H)\\nLet’s go for another round.\\nP(H|E) = 0.9683'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 86, 'page_label': '87'}, page_content='P(H) = 0.97\\nHammy wins again'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 87, 'page_label': '88'}, page_content='Let’s recalculate our probabilities. Let’s see if we can \\ncalculate these ourselves.\\nP(H) = 0.97\\nP(E|H) = Probability of heads given fair coin\\nP(-H)  = Probability of unfairness\\nP(E|-H) = 0.8*\\n \\nP(H|E) = \\nP(H)  P(E|H)\\nP(H)P(E|H) + P(-H)P(E|-H)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 88, 'page_label': '89'}, page_content='Let’s recalculate our probabilities. Let’s see if we can \\ncalculate these ourselves.\\nP(H) = 0.97\\nP(E|H) = 0.5\\nP(-H)  = 0.03\\nP(E|-H) = 0.8*\\n \\nP(H|E) = \\n(0.97)(0.5)\\n(0.97)(0.5) + (0.03)(0.8)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 89, 'page_label': '90'}, page_content='Our probability drops again! \\nJust for fun, one last time.\\nP(H|E) = 0.9528'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 90, 'page_label': '91'}, page_content='P(H) = 0.9528\\nHammy wins again'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 91, 'page_label': '92'}, page_content='Let’s recalculate our probabilities. Let’s see if we can \\ncalculate this ourselves.\\nP(H) = 0.95\\nP(E|H) = 0.5\\nP(-H)  = 0.05\\nP(E|-H) = 0.8*\\n \\nP(H|E) = \\n(0.95)(0.5)\\n(0.95)(0.5) + (0.05)(0.8)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 92, 'page_label': '93'}, page_content='But wait! What if hammy ﬂips a tails.\\nP(H) = 0.92\\nP(E|H) = 0.5\\nP(-H)  = 0.05\\nP(E|-H) = Assuming the probability of heads given \\non unfair coin is 0.8, what would be the probability \\nof tails given the unfair coin?\\n \\nP(H|E) = \\n(0.95)(0.5)\\n(0.95)(0.5) + (0.05)(0.8)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 93, 'page_label': '94'}, page_content='Using these values, let’s recalculate our conditional \\nprobability. \\nP(H) = 0.92\\nP(E|H) = 0.5\\nP(-H)  = 0.05\\nP(E|-H) = 0.2\\n \\nP(H|E) = \\n(0.92)(0.5)\\n(0.92)(0.5) + (0.08)(0.2)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 94, 'page_label': '95'}, page_content='It goes back \\nup!!!!! \\nSince we received evidence that this coin is fair, the \\nprobability of a fair coin goes from 92% to 96%! This \\nshould be mind blowing. \\nP(H|E) = 0.9663\\n*MidJourney Image of Nice Hamster'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 95, 'page_label': '96'}, page_content='Naive Bayes Classiﬁer \\nWe can utilize this formula in a multiclass supervised learning classiﬁer \\ncalled the naive bayes classiﬁer. \\nThe goal of naive bayes classiﬁcation is to calculate the probability a new \\nsample belongs to a certain class.\\nWe can take this a step further and assume shapes of our our probability \\ndistribution.\\nWe’ll go over the details next week'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 96, 'page_label': '97'}, page_content='A Refresher on Classiﬁcation \\nMetrics'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 97, 'page_label': '98'}, page_content='Metrics\\n Actual \\nDefault\\nActual No \\nDefault\\nDefault 30 10\\nNo \\nDefault\\n40 70\\nPredicted\\nTrue Class\\nALL CLASSIFIERS CAN USE THESE \\nMETRICS!\\nAccuracy\\nOverall correctness of the \\nmodel.\\nPrecision\\nProportion of correct predicted \\npositive cases.\\nRecall\\nProportion of correctly \\nidentiﬁed positive cases.\\nSpeciﬁcity \\nAbility to predict negative \\ncases.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 98, 'page_label': '99'}, page_content='Metrics\\n Actual \\nDefault\\nActual No \\nDefault\\nDefault 30 10\\nNo \\nDefault\\n40 70\\nPredicted\\nTrue Class\\n● T o increase precision, we must \\nhave fewer False Positives.\\n○ However, we do not have \\nto worry about false \\nnegatives.\\n● T o increase recall, we must have \\nfewer False Negatives.\\n○ However, we do not have \\nto worry about false \\npositives.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 99, 'page_label': '100'}, page_content='Metrics\\n Actual \\nDefault\\nActual No \\nDefault\\nDefault 30 10\\nNo \\nDefault\\n40 70\\nPredicted\\nTrue Class\\nFor this reason, as we increase \\nprecision (proportion of correct \\npredicted), we decrease recall \\n(proportion of correctly identiﬁed). \\nThis is known as precision-recall \\ntradeoff. We usually want to ﬁnd the \\nright balance.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 100, 'page_label': '101'}, page_content='Metrics\\nWhen moving towards multiclass \\nclassiﬁers, our confusion matrix get’s \\na tad bit more complex, but the \\nconcept remains the same.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 101, 'page_label': '102'}, page_content='Probability & One vs All Lab'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 102, 'page_label': '103'}, page_content='Naive Bayes Lab\\nAs a class, let’s complete the challenge together.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Bayes Theorem Review', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Bayes Theorem Review.pdf', 'total_pages': 104, 'page': 103, 'page_label': '104'}, page_content=\"Monday\\nNext week, we will continue our \\nreview of classiﬁcation algorithms by \\ndiving deeper into Naive Bayes & \\nsomething called \\nK-Nearest-Neighbors.\\nY ou are who your neighbors \\nare.\\nIf you understand what you're doing, you're \\nnot learning anything. - Anonymous\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 0, 'page_label': '1'}, page_content='Data Reporting'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 1, 'page_label': '2'}, page_content='Agenda - Schedule\\n1. Leetcode Warm Up\\n2. Joining DataFrames\\n3. Data Reporting\\n4. Break\\n5. TLAB Work\\nStatistics is not immune from \\nhuman-trickery'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 2, 'page_label': '3'}, page_content='Agenda - Goals\\n● Load CSV data into pandas DataFrames.\\n● Concatenate datasets with similar structure using pd.concat().\\n● Merge datasets on a common key using pd.merge().\\n● Review foundational pandas methods to inspect your dataframes.\\n● Apply best practices when summarizing and reporting your ﬁndings.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 3, 'page_label': '4'}, page_content='Announcement(s)\\n● Career Class on 4/17 (this time for real)\\n● TLAB #2 due 4/21\\n● Farukh Group ofﬁce hours open (register via Canvas)\\n○ Cohort A Group Ofﬁce Hours on Thursday: 4:30 - 5:30\\n○ Cohort B Group Ofﬁce Hours  on Thursday: 2:00 - 3:00'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 4, 'page_label': '5'}, page_content='Warm Up'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 5, 'page_label': '6'}, page_content='During your 1st or 2nd-round interview, you will most likely be asked to \\nsolve some sort of technical task to prove your competency in the tools you \\nlisted on your resume.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 6, 'page_label': '7'}, page_content='That’s why going forward, we will start most of our classes off with a \\nLeetcode question. Now while we will not be grading you on this…'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 7, 'page_label': '8'}, page_content='After working on this problem for 10 minutes, we will be pulling from a \\nuniform distribution (with selective replacement) of names to make sure \\neveryone gets the leetcode experience.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 8, 'page_label': '9'}, page_content='T o start, please create a Leetcode account using your GitHub login \\ninformation.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 9, 'page_label': '10'}, page_content='T ake 10 minutes to work on the “Big Countries” Leetcode problem: \\nhttps://leetcode.com/problems/big-countries/description/?envType=study\\n-plan-v2&envId=30-days-of-pandas&lang=pythondata'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 10, 'page_label': '11'}, page_content='Pandas Merging & \\nConcatenation'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 11, 'page_label': '12'}, page_content=\"In yesterday's lecture, we learned how to manipulate a single CSV ﬁle for \\nsome light descriptive analytics.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 12, 'page_label': '13'}, page_content='But most of the time, you will not only be dealing with one dataset that \\ncontains all features. The most likely case is that you will be dealing with \\nnumerous data tables that need to be joined together so that you can \\nperform analysis.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 13, 'page_label': '14'}, page_content='Just like yesterday, we will apply these general syntax on our code-blocks to \\ndemonstrate the actual utility of this code. Remember, these slides are \\nsecondary, the best way to understand the code is to write and run it \\nyourself.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 14, 'page_label': '15'}, page_content='Pandas Review - Merging & Concatenating \\nMost of the time, we don’t have just one dataset but rather multiple. A few \\ncommon join operations that we will write include:\\n● Concatenate: appending two dataframes to one another\\n● Appending: appending one row to a database\\n● Joining: performing logical joins with two dataframes\\nThis is only a review, check out the full documentation for more info.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 15, 'page_label': '16'}, page_content='Pandas Review - Concatenating\\n“takes a list or dict of homogeneously-typed objects and \\nconcatenates them with some conﬁgurable handling \\nof ‘what to do with the other axes’”\\npd.concat([df1,df2,df3])\\n*This is the simplest case. The \\ndocumentation expands more upon this.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 16, 'page_label': '17'}, page_content=\"Pandas Review - Appending\\n“If you have a series that you want to append as a \\nsingle row to a DataFrame, you can convert the row \\ninto a DataFrame and use concat.”\\npd.concat([df1, \\ns2.to_frame().T],ignore_index=True)\\n*Always ask yourself if it's necessary to do \\nsuch a granular operation in pandas. More \\noften than not, we shouldn’t be.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 17, 'page_label': '18'}, page_content='Pandas Review - Joining\\n“high performance in-memory join \\noperations idiomatically very similar to \\nrelational databases like SQL.”\\npd.merge(left, right, on=\"key\")'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 18, 'page_label': '19'}, page_content='Notice that the merge occurs according to similar key values'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 19, 'page_label': '20'}, page_content='We can create these complex joins by using the simplicity of the pandas API. \\nJust use the correct parameter as your merge method! (aka ‘how=... ’)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 20, 'page_label': '21'}, page_content='Data Reporting'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 21, 'page_label': '22'}, page_content='Data Reporting\\nNot only do we need to have the technical/mathematical competency to \\nproperly use tools…\\nBut we also need to be able to communicate ﬁndings & methodology to both \\nhigh-context (other technologists) and low-context (external team) crowds.\\nThis applies to any analytical document you create'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 22, 'page_label': '23'}, page_content='Data Reporting\\nLet’s go over a few do’s & don’ts. \\n● Be speciﬁc \\n● Use helpful visuals\\n● Appropriately discuss inferences\\n● Report methods'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 23, 'page_label': '24'}, page_content='Data Reporting\\nT o frame our exploration of data write-ups, let’s take a look at the 2013 \\npaper titled The impact of free-ranging domestic cats on wildlife of the United \\nStates (https://www.nature.com/articles/ncomms2380)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 24, 'page_label': '25'}, page_content='Data Reporting - Be Speciﬁc\\nDO:\\nMention speciﬁc values, such as mean, median, mode, or any other \\nuseful metric when describing your observations. Discuss speciﬁc \\nmagnitude and direction when discussing changes.\\nDON’T:\\nMake broad or general statements with no backing by data.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 25, 'page_label': '26'}, page_content='Bad Example:  When describing your observations, we are ambiguous. What is “many?”\\nFree-ranging cats on islands have led \\nto many extinctions of different \\nmammals.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 26, 'page_label': '27'}, page_content='Good Example:  When describing your observations, make reference to the descriptives you’ve \\ncalculated.\\n“Free-ranging cats on islands have \\ncaused or contributed to 33 (14%) of \\nthe modern bird, mammal and reptile \\nextinctions…”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 27, 'page_label': '28'}, page_content='Bad Example:  When describing your observations, we are ambiguous. \\n“We estimate that cats in the \\ncontiguous United States annually kill \\nbetween 1.3 and 4.0 billion birds \\n(median=2.4 billion) (Fig. 1a), with \\nmost mortality caused by un-owned \\ncats.”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 28, 'page_label': '29'}, page_content='Good Example:  When describing your observations, make reference to the descriptives you’ve \\ncalculated.\\n“We estimate that cats in the \\ncontiguous United States annually kill \\nbetween 1.3 and 4.0 billion birds \\n(median=2.4 billion) (Fig. 1a), with \\n∼69% of this mortality caused by \\nun-owned cats.”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 29, 'page_label': '30'}, page_content='Data Reporting - Use Helpful Visualizations\\nDO:\\nUse well-annotated visuals to represent your insight. Point to key \\nleverage points in your visuals.\\nDON’T:\\nRely on visuals without explanatory text.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 30, 'page_label': '31'}, page_content='Bad Example:  An unmarked distribution, while telling, is not too useful to support your observations.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 31, 'page_label': '32'}, page_content='Good Example: Visuals utilize proper annotation to visually explain insights'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 32, 'page_label': '33'}, page_content='Data Reporting - Appropriate Inferences\\nDO:\\nUse standard language when describing the output of hypothesis tests \\nor other statistical methods. (fail to reject, reject, signiﬁcant) \\nDON’T:\\nUse ambiguous or unclear language when discussing outputs of \\ninferences.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 33, 'page_label': '34'}, page_content='Bad Example:  This is a misunderstanding of hypothesis testing.\\nThe t-test showed that we can accept \\nthe alternative hypothesis. One \\nteacher’s learning methods were \\ndefinitely better.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 34, 'page_label': '35'}, page_content='Good Example:  Use standard language when describing the output of hypothesis tests or other statistical \\nmethods. The information in the parentheses is not needed unless sharing this info with other statisticians.\\n“A Student’s independent samples t-test \\nshowed that this 5.4% difference was \\nsignificant (t(31)=2.1, p<.05, \\nCI95=[0.2,10.8]), suggesting that a genuine \\ndifference in learning outcomes has \\noccurred.”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 35, 'page_label': '36'}, page_content='Data Reporting - Report Methods\\nDO:\\nPlainly state your methodology of collecting data. This includes source, \\ntime frame, and techniques used if applicable. \\nDON’T:\\nLeave your data collection a mystery to unravel.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 36, 'page_label': '37'}, page_content='Bad Example:  Leave your data collection a mystery to unravel.\\n“We searched the web to identify studies that \\ndocument cat predation on birds and mammals.”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 37, 'page_label': '38'}, page_content='Good Example:  Plainly state your methodology of collecting data.\\n“We searched JSTOR, Google Scholar, and the \\nWeb of Science database (formerly ISI Web of \\nScience) within the Web of Knowledge search \\nengine published by Thomson Reuters to \\nidentify studies that document cat predation on \\nbirds and mammals.”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 38, 'page_label': '39'}, page_content='Bad Example:  Leave your data collection a mystery to unravel.\\n“We got the count of data-adjacent job-postings”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 39, 'page_label': '40'}, page_content='Good Example:  Plainly state your methodology of collecting data.\\n“We used regex via pandas to search for \\njob-postings that contain the title ‘data’ in order \\nto count the frequency of data-adjacent jobs in \\nthe industry.”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 40, 'page_label': '41'}, page_content='Entertaining Example\\n“I tapped into my secret worldwide network of \\ncat-related-news to identify studies that \\ndocument cat predation on birds and mammals. \\nMy contacts: Whiskers, Mr.Mittens, and Tom \\nintroduced me to this hidden bastion of \\ninformation.”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 41, 'page_label': '42'}, page_content='Applying to README'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 42, 'page_label': '43'}, page_content='README’s\\nWhen a recruiter, looks at your public projects, they are not immediately \\ndiving into code.\\nInstead, they will look for evidence of relevant skills in your\\nREADME\\nTherefore we will require us all to have README’s before submitting'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 43, 'page_label': '44'}, page_content='README’s\\nAt the minimum your README should contain:\\n● One-sentence project summary \\n● Y our methodology \\n● Y our conclusions with speciﬁc metrics\\n● Helpful/interesting visuals \\n● Y our challenges & next-steps'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 44, 'page_label': '45'}, page_content='README’s\\nFor the upcoming and ﬁnal TLAB, you will write README’s so that a \\nrecruiter understands the intent, analysis, and competencies associated \\nwith our projects.\\nHowever, in the future you should ﬁt your README to your target \\naudience:\\n● Engineers → Inform on software structure\\n● Stakeholders → Inform on value\\n● Regulators → Inform on compliance'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 45, 'page_label': '46'}, page_content='TLAB #2'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 46, 'page_label': '47'}, page_content='Lab (Due 04/21)\\nYou are a growth analyst at a Vancouver-based consulting ﬁrm called \\nMonica Group. Your manager is spearheading the completion of a a new \\nanalytical tool which will automatically label if a review is positive, neutral, \\nnegative, or irrelevant. \\nYou will be kicking off completion of this milestone by independently \\nimplementing a minimal-viable-product. This will be a Python pipeline that \\ningests a text-ﬁle of review data and interfaces with the Open AI API in \\norder to automatically label each review.\\nWe released API keys.\\nVancouver, Canada'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Data Reporting', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Data Reporting.pdf', 'total_pages': 48, 'page': 47, 'page_label': '48'}, page_content=\"Thursday\\nNo review session. Financial workshop\\nJupyter: scratchpad of the data \\nscientist\\nIf you understand what you're doing, you're \\nnot learning anything. - Anonymous\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 0, 'page_label': '1'}, page_content='Dimensionality \\nReduction'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 1, 'page_label': '2'}, page_content='Agenda - Schedule\\n1. Linear Algebra Review\\n2. Eigenvalues & Eigenvectors\\n3. Principal Component Analysis\\n4. Other T echniques (ICA, t-SNE)\\n5. PCA Lab\\nIt’s all perspective'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 2, 'page_label': '3'}, page_content='Agenda - Goals\\n● Review the fundamentals of linear algebra \\n● Understand the necessity for dimension decomposition\\n● Understand the intuition of singular value decomposition (SVD)\\n● Apply SVD to implement PCA   \\n● Implement dimensionality reduction'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 3, 'page_label': '4'}, page_content='Review'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 4, 'page_label': '5'}, page_content='Review Question\\nWhy do we resample our dataset via the bootstrap when implementing \\nbagged trees?\\nA) Because resampling reduces variance\\nB) Because resampling increases variance\\nC) Because decision trees need to learn to pull themselves up by their \\nbootstraps if they want to get anywhere in this world.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 5, 'page_label': '6'}, page_content='Review Question\\nRandom forests provide an improvement over bagged trees by selecting \\na subset of size sqrt(P) predictors, where P is our total number of \\npredictors. Which effect does this have?\\nA) De-correlates our variance\\nB) Re-correlates our variance\\nC) De-correlates our trees\\nD) Re-correlates our trees'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 6, 'page_label': '7'}, page_content='Review Question\\nHow do we measure feature importance in random forest classifiers?\\nA) Purity lost for each conditional node that contains a feature\\nB) Purity gained for each conditional node that contains a feature\\nC) MSE lost for each conditional node that contains a feature\\nD) MSE gained for each conditional node that contains a feature'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 7, 'page_label': '8'}, page_content='PCA Introduction'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 8, 'page_label': '9'}, page_content='The Curse of Dimensionality \\nTHE CURSE (...of dimensionality)\\nAs you increase your dimensions (the # of predictors), the distance \\nbetween your points become uniform! \\nBasically it becomes harder to distinguish which class of data a new test \\nsample belongs to as you add more and more dimensions to your \\ndataset.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 9, 'page_label': '10'}, page_content='What do you notice about the sparsity of our data as we increase dimensions?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 10, 'page_label': '11'}, page_content='Notice how the frequency of distances converges on a speciﬁc value as we increase dimensions: \\nhttps://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote02_kNN.html'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 11, 'page_label': '12'}, page_content='The Curse of Dimensionality \\nThis becomes more of an issue as we begin to deal with more advanced \\nmachine learning algorithms that take in highly rich data.\\nThe most “cutting-edge” algorithms are incredible data consumers:\\n● Number Classification Model: 64 predictors\\n● Computer Vision Models: 1000 predictors \\n● GPT-4: any guesses?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 12, 'page_label': '13'}, page_content='The Curse of Dimensionality \\nThis becomes more of an issue as we begin to deal with more advanced \\nmachine learning algorithms that take in highly rich data.\\nThe most “cutting-edge” algorithms are incredible data consumers:\\n● Number Classification Model: 64 predictors\\n● Computer Vision Models: 1000 predictors \\n● GPT-4: Untold number of predictors to train 1.8 TRILLION \\nparameters\\nBy nature, these algorithms are data-greedy. We cannot expect to feed \\nthem small amounts of data and expect them to work sufficiently.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 13, 'page_label': '14'}, page_content='PCA Introduction\\nHowever we can ward off this curse using an observation on highly \\ndimensional data.\\nDoes anyone recall what this blessing was?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 14, 'page_label': '15'}, page_content='The Curse of Dimensionality \\nBlessing of non-uniformity: highly dimensional datasets are concentrated \\nnear lower-dimension manifolds.\\nMost of our relevant data does not exist in higher-dimensions. Instead, \\nwe could map our data to a lower dimensional sheet that still retains \\nmost if not all of our dataset characteristics.\\nToday, we will learn more about the utilization of this fact via Principal \\nComponent Analysis.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 15, 'page_label': '16'}, page_content='Sure this data is plotted in 3-dimensions. However we could easily unfold \\nthis into 2 dimensions (i.e. a lower dimension manifold). \\nAll this empty \\nspace is “noise. ”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 16, 'page_label': '17'}, page_content='PCA Summary \\nThe Principal Component Analysis (PCA) entails the following steps:\\n1. Standardize the data via the mean\\n2. Calculate the covariance matrix\\n3. Calculate the eigenvalues and eigenvectors of the covariance \\nmatrix\\n4. Utilize eigenvectors to calculate your new principal components.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 17, 'page_label': '18'}, page_content='PCA Summary \\nThink of your principal components as the \\nessence of your multidimensional dataset.\\nPCA asks: If we could reduce all the noise of a \\ndataset and boil it down to its most important \\nfeatures, what would be revealed?\\nAlmost all real-world datasets are extremely noisy, \\nwe need a method to clean up this noise somehow.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 18, 'page_label': '19'}, page_content='Principal component analysis on the hand-written digit “3”: notice how we \\nhighlight the consistent shape of a 3 regardless of handwriting style.\\nNamely we \\nhighlight the curves \\nand dips of this \\nnumber.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 19, 'page_label': '20'}, page_content='Principal component analysis on human faces: a bit spooky, but notice that \\nthe same features are highlighted regardless of face-shape, race,  age: 2 \\neyes, a nose, and a mouth.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 20, 'page_label': '21'}, page_content='PCA Summary \\nLet’s first review linear algebra before breaking this algorithm down.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 21, 'page_label': '22'}, page_content='Geometric Interpretation of \\nLinear Algebra'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 22, 'page_label': '23'}, page_content='Before we go any further,  let’s review linear algebra concepts as \\ndimensionality reduction is completely reliant on this ﬁeld of \\nmathematics*.\\n*Generally, we say \\nmathematics in the \\nUS. But in the UK, \\nthey abbreviate this \\nas maths.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 23, 'page_label': '24'}, page_content='Linear Algebra\\nLet’s try to reason as to why we often use \\nlinear algebra in data science. \\nWhat is the one central object that always \\nre-emerges in applied data science\\nMore speciﬁcally, what is the one structure \\nwe always rely on to store our data'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 24, 'page_label': '25'}, page_content='Linear Algebra\\nA dataset! \\nThankfully we have 1000’s of years of maths \\nto formally discuss the implementations of  \\ninterpreting, decomposing, and  summarizing a \\nset of data (i.e. a  matrix)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 25, 'page_label': '26'}, page_content='Instead of staying put in the formal language of linear algebra, let’s instead view a toy dataset of \\nbasketball players and their stats and see how we can apply linear algebra concepts to it to \\nextract meaningful insight.\\nPointsPerGame AssistsPerGame\\n18.72 3.38\\n22.88 7.97\\n20.07 5.11\\n25.0 20.0\\n18.62 6.12\\n15.59 1.17'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 26, 'page_label': '27'}, page_content='And for the sake of story-telling, we are a Jonah Hill-like statistician from the movie MoneyBall, \\nand we are trying to teach Brad Pitt how to interpret his team\\nPointsPerGame AssistsPerGame\\n18.72 3.38\\n22.88 7.97\\n20.07 5.11\\n25.0 20.0\\n18.62 6.12\\n15.59 1.17'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 27, 'page_label': '28'}, page_content='Instead of seeing each sample as a static number, we will view each sample as a row-vector (1 row \\nand multiple columns)\\nFurthermore, we will visualize each vector as having magnitude and direction on a cartesian plot. \\nT o keep things simple, we interpret vectors according to their “X & Y” coordinates.\\nPointsPerGame AssistsPerGame\\n18.72 3.38\\n22.88 7.97\\n20.07 5.11\\n25.0 20.0\\n18.62 6.12\\n15.59 1.17\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 28, 'page_label': '29'}, page_content='First we consider the row-vector [18.72, 3.38]. For simplicity’s sake we start at the origin [0,0] of \\nour coordinate system  \\nPointsPerGame AssistsPerGame\\n18.72 3.38\\n22.88 7.97\\n20.07 5.11\\n25.0 20.0\\n18.62 6.12\\n15.59 1.17\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 29, 'page_label': '30'}, page_content='Next [22.88, 7.97]\\nPointsPerGame AssistsPerGame\\n18.72 3.38\\n22.88 7.97\\n20.07 5.11\\n25.0 20.0\\n18.62 6.12\\n15.59 1.17\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 30, 'page_label': '31'}, page_content='You get the idea, as well as the rest…\\nPointsPerGame AssistsPerGame\\n18.72 3.38\\n22.88 7.97\\n20.07 5.11\\n25.0 20.0\\n18.62 6.12\\n15.59 1.17\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 31, 'page_label': '32'}, page_content='This is no different from plotting these players on a scatter-plot! However we gain a few insights \\nby treating them as directional magnitudes (which we will see later)\\nPointsPerGame AssistsPerGame\\n18.72 3.38\\n22.88 7.97\\n20.07 5.11\\n25.0 20.0\\n18.62 6.12\\n15.59 1.17\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 32, 'page_label': '33'}, page_content='Let’s consider only two of these vectors. We will look at our high-performing player, as well as our \\nlower performing player. \\nPointsPerGame AssistsPerGame\\n18.72 3.38\\n22.88 7.97\\n20.07 5.11\\n25.0 20.0\\n18.62 6.12\\n15.59 1.17\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 33, 'page_label': '34'}, page_content='Basic vector arithmetic is simple. If you can match your rows and columns together, you will be able to apply operations such as addition and subtraction to individual values of the vector.Addition results in a new “larger vector” (in this case)\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25Player1 = [ 25.00,  20.00 ]\\nPlayer2 = [ 15.59,  1.17 ]\\nPlayer1 + Player2            =  [ 25.00,  20.00 ] + [ 15.59,  1.17 ]  \\n                                                   = [ 25.00 + 15.59,  20.00 + 1.17 ]\\n                                                   = [ … ,  … ] \\n \\nAddition'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 34, 'page_label': '35'}, page_content='Basic vector arithmetic is simple. If you can match your rows and columns together, you will be able to apply operations such as addition and subtraction to individual values of the vector.Addition results in a new “larger vector” (in this case)\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25Player1 = [ 25.00,  20.00 ]\\nPlayer2 = [ 15.59,  1.17 ]\\nPlayer1 + Player2            =  [ 25.00,  20.00 ] + [ 15.59,  1.17 ]  \\n                                                   = [ 25.00 + 15.59,  20.00 + 1.17 ]\\n                                                   = [ 40.59 ,  21.17 ] \\n \\nAddition'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 35, 'page_label': '36'}, page_content='Whereas subtraction results in a new “smaller” vector (in this case)\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25Player1 = [ 25.00,  20.00 ]\\nPlayer2 = [ 15.59,  1.17 ]\\nPlayer1 - Player2            =  [ 25.00,  20.00 ] - [ 15.59,  1.17 ]  \\n                                                 = [ 25.00 - 15.59,  20.00 - 1.17 ]\\n                                                 = [ … ,  … ] \\n \\nSubtraction'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 36, 'page_label': '37'}, page_content='Whereas subtraction results in a new “smaller” vector (in this case)\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25Player1 = [ 25.00,  20.00 ]\\nPlayer2 = [ 15.59,  1.17 ]\\nPlayer1 - Player2            =  [ 25.00,  20.00 ] - [ 15.59,  1.17 ]  \\n                                                 = [ 25.00 - 15.59,  20.00 - 1.17 ]\\n                                                 = [ 9.41 ,  18.83 ] \\n \\n*what if we did  [ 15.59,  1.17 ]  -  [ 25.00,  20.00 ] \\ninstead?\\nSubtraction'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 37, 'page_label': '38'}, page_content='We also have scalar multiplication has the effect of “stretching” a vector outwards (if we apply a \\npositive scalar to a vector with positive vector)\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25Player1 = [ 25.00,  20.00 ]\\nPlayer2 = [ 15.59,  1.17 ]\\n2 * Player2  = 2 *  [ 15.59,  1.17 ]\\n                                          = [ 2 * 15.59,  2 * 1.17 ]\\n                                          = [ … ,  … ] \\n \\nScalar Multiplication'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 38, 'page_label': '39'}, page_content='We also have scalar multiplication has the effect of “stretching” a vector outwards (if we apply a \\npositive scalar to a vector with positive vector)\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25Player1 = [ 25.00,  20.00 ]\\nPlayer2 = [ 15.59,  1.17 ]\\n2 * Player2  = 2 *  [ 15.59,  1.17 ]\\n                                          = [ 2 * 15.59,  2 * 1.17 ]\\n                                          = [ 31.18 ,  2.34 ] \\n \\nScalar Multiplication'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 39, 'page_label': '40'}, page_content='We also have the magnitude of a vector, which is usually denoted by two bars “||” on either side of \\na vector. This denotes the total distance that a vector covers. Think back to the kNN algorithm, \\nwhat kind of distance measurement does this look similar to?\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25Player1 = [ 25.00,  20.00 ]\\nPlayer2 = [ 15.59,  1.17 ]\\n||Player1||               = sqrt(A^2 + B^2)\\n                                          = sqrt(25^2 + 20^2)\\n                                          = …\\n \\nMagnitude'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 40, 'page_label': '41'}, page_content='This is just the euclidean distance AKA solving the hypotenuse. \\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25Player1 = [ 25.00,  20.00 ]\\nPlayer2 = [ 15.59,  1.17 ]\\n||Player1||               = sqrt(A^2 + B^2)\\n                                          = sqrt(25^2 + 20^2)\\n                                          ~ 32\\n \\nMagnitude \\n32'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 41, 'page_label': '42'}, page_content='We also have the ability to apply the “dot product” to two vectors. Note: we must ensure that the \\ncolumn of the ﬁrst matrix equals the row of the second matrix to take dot product. However if we \\nare simply using two vectors, we can simply align values.\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25Player1 = [ 25.00,  20.00 ]\\nPlayer2 = [ 15.59,  1.17 ]\\n \\nDot Product\\nPlayer1 * Player2        = \\n                                             = [ 25.00,  20.00 ] * [ 15.59, 1.17 ]\\n      =(25.00 * 15.59) + (20.00  * 1.17)\\n                =   …'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 42, 'page_label': '43'}, page_content='But how do we interpret this value? Dot product is also known as scalar product. It represents \\nhow closely two vectors align in direction. For this reason, we often use dot product as an \\nintermediate calculation for measures such as cosine similarity \\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25Player1 = [ 25.00,  20.00 ]\\nPlayer2 = [ 15.59,  1.17 ]\\n \\nDot Product\\nPlayer1 * Player2        = \\n                                             = [ 25.00,  20.00 ] * [ 15.59, 1.17 ]\\n      =(25.00 * 15.59) + (20.00  * 1.17)\\n                =   413.15'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 43, 'page_label': '44'}, page_content='Using the dot product and magnitude, we can calculate the angle (in radians) between two \\nvectors and see if they are pointed in the same direction. \\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25Player1 = [ 25.00,  20.00 ]\\nPlayer2 = [ 15.59,  1.17 ]\\n \\nCosine Similarity\\nPlayer1 * Player2  =   413.15\\n||Player1||  = 32\\n||Player2||  = 15.6\\ncos(θ) =\\n Player1 * Player2\\n||Player1|| ||Player2||'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 44, 'page_label': '45'}, page_content='Now that we have this equality, how do we solve for θ???\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25Player1 = [ 25.00,  20.00 ]\\nPlayer2 = [ 15.59,  1.17 ]\\n \\nCosine Similarity\\nPlayer1 * Player2  =   413.15\\n||Player1||  = 32\\n||Player2||  = 15.6\\ncos(θ) =\\n 413.15\\n32 * 15.6\\ncos(θ) = 0.82'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 45, 'page_label': '46'}, page_content='We take the inverse of cosine (aka arccosine) to calculate the radians between two vectors.In this case we got a θ of 0.609 radians aka ~35 degrees. If our two vectors pointed in the same direction, what would we get instead??? What if they were perpendicular to one another?\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25Player1 = [ 25.00,  20.00 ]\\nPlayer2 = [ 15.59,  1.17 ]\\n \\nCosine Similarity\\nPlayer1 * Player2  =   413.15\\n||Player1||  = 32\\n||Player2||  = 15.6\\ncos(θ) =\\n 413.15\\n32 * 15.6\\ncos(θ) = 0.82\\nθ = cos^-1(0.82)\\nθ = 0.609 radians\\n35'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 46, 'page_label': '47'}, page_content='Let’s consider Player3  to see how cosine similarity differs across vectors. What do you notice about the cosine similarity of Player1 and Player3?If we got a cosine similarity of 0, what would this indicate. What about a cosine similarity of π/2?\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25Player1 = [ 25.00,  20.00 ]\\nPlayer2 = [ 15.59,  1.17 ]\\nPlayer3 = [ 18.62,  6.12 ]\\n \\nCosine Similarity\\nPlayer1 * Player3  =   587.9\\n||Player1||  = 32\\n||Player2||  = 19.59\\ncos(θ) =\\n 587.9\\n32 * 19.59\\ncos(θ) = 0.93\\nθ = cos^-1(0.93)\\nθ = 0.37 radians\\n0.60 r\\n0.37 r'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 47, 'page_label': '48'}, page_content='By solving for the angle between two vectors (players or data points), we observe how “similar” two data points are.Note that this could also be used to measure the distance between two samples in kNN!\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25Player1 = [ 25.00,  20.00 ]\\nPlayer2 = [ 15.59,  1.17 ]\\n \\nCosine Similarity\\n0.37 r\\n0.60 r'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 48, 'page_label': '49'}, page_content='Before we leave the world of vectors, let’s identify a few key terminologies that you will see spring up in the world of ML. First is orthogonality,  which is when two vectors are perpendicular to each other (90 degrees).\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25\\n \\nWhen two vectors are orthogonal to each \\nother, they are completely uncorrelated.\\nThat is, they share no linear relationship, \\ntherefore they do not inﬂuence each other \\nand instead represent two separate \\nsources of unbiased information.\\n90 degrees'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 49, 'page_label': '50'}, page_content='Next is collinearity. This is when vectors line on the same line or when they \\nare parallel to each other.\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25\\n \\nWhen two vectors are collinear to each \\nother, they are completely correlated.\\nYou are essentially looking at the same \\nvector twice, and if you incorporate \\ninformation from this vector, you run the \\nrisk of adding noise to your model.\\nO degrees'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 50, 'page_label': '51'}, page_content='These vector deﬁnitions will become relevant again soon, but for now, let’s \\ncombine all our players into a single matrix so that we can begin exploring \\ndimensionality reduction.\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25team1 = [ 18.72, 3.38\\n       22.88, 7.97\\n                     20.07, 5.11\\n      25.0, 20.0\\n                    18.62, 6.12\\n      15.59, 1.17]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 51, 'page_label': '52'}, page_content='Can you see any way we can express these data points on a single axes \\n(line)?\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25\\nteam1 = [ 18.72, 3.38\\n       22.88, 7.97\\n                     20.07, 5.11\\n      25.0, 20.0\\n                    18.62, 6.12\\n      15.59, 1.17]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 52, 'page_label': '53'}, page_content='Notice how most of these points fall around one axes (sort of like a line of \\nbest ﬁt). We will utilize PCA to reduce these points to this axes \\n(1-dimension). However we must ﬁrst review eigenvectors.\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25\\nteam1 = [ 18.72, 3.38\\n       22.88, 7.97\\n                     20.07, 5.11\\n      25.0, 20.0\\n                    18.62, 6.12\\n      15.59, 1.17]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 53, 'page_label': '54'}, page_content='PCA Step 1 - Standardize'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 54, 'page_label': '55'}, page_content='Step 1: Before moving forward, we must standardize this dataset around 0 \\nby subtracting the average off of each sample.\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25\\nteam1 = [ 18.72 - 20.15, 3.38 - 7.29\\n       22.88 - 20.15, 7.97  - 7.29\\n                     20.07 - 20.15, 5.11  - 7.29\\n      25.0 - 20.15, 20.0  - 7.29\\n                    18.62 - 20.15, 6.12  - 7.29\\n      15.59 - 20.15, 1.17  - 7.29] \\nCol1 avg = 20.15\\nCol2 avg = 7.29'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 55, 'page_label': '56'}, page_content='This simpliﬁes all subsequent calculations.\\nNext we calculate the covariance matrix.\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25\\nteam1 = [ -1.43, −3.91\\n       2.73, 0.68\\n                     −0.08, −2.18\\n      4.85, 12.71\\n                    −1.53, −1.17\\n      −4.56, −6.12]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 56, 'page_label': '57'}, page_content='PCA Step 2 - Covariance Matrix'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 57, 'page_label': '58'}, page_content='First, let’s go over the concept of a covariance matrix.\\nteam1 = [ -1.43, −3.91\\n       2.73, 0.68\\n                     −0.08, −2.18\\n      4.85, 12.71\\n                    −1.53, −1.17\\n      −4.56, −6.12] \\nFor each column possible \\ncombination of features, \\nwe calculate covariance\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 58, 'page_label': '59'}, page_content='An Aside - Covariance\\nIt might seem like we are introducing a \\nbrand new formula with no context, but \\nwe’ve actually interacted with covariance \\nalready!\\nNotice that along our diagonal of the \\ncovariance matrix, we calculate the \\ncovariance of a feature with itself.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 59, 'page_label': '60'}, page_content='An Aside - Covariance\\nLet’s place the predictor “X” into our \\ncovariance function.\\nIs there any way we can simplify the \\nnumerator with an exponent?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 60, 'page_label': '61'}, page_content='An Aside - Covariance\\nYes, we can convert this into the following \\nformula. \\nWhat is this formula also known as???'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 61, 'page_label': '62'}, page_content='An Aside - Covariance\\nNotice that this is the same as our \\nSAMPLE VARIANCE!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 62, 'page_label': '63'}, page_content='An Aside - Covariance\\nIn summary, our sample covariance is the measure of joint variability \\nbetween two random variables.\\nIf covariance is large & positive, our two random variables move in the same \\ndirection (e.g. height & weight), whereas negative covariances indicate \\nopposite directions (e.g. exercise & blood pressure).\\n*What do you think a covariance of 0 \\nindicates?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 63, 'page_label': '64'}, page_content='An Aside - Covariance\\nAs we observed, calculating the covariance of  a predictor with itself gives \\nus spread (variance)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 64, 'page_label': '65'}, page_content='Let’s continue our calculation of our covariance metric.\\nAlong our diagonal we have variance for PPG & APG. In the corners of our matrix, we have \\nthe covariance of both APG & PPG (19.79).\\nNext, we will calculate the eigenvectors of this covariance matrix.\\nteam1 = [ -1.43, −3.91\\n       2.73, 0.68\\n                     −0.08, −2.18\\n      4.85, 12.71\\n                    −1.53, −1.17\\n      −4.56, −6.12] \\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25\\n[ 11.23, 19.79,\\n19.79, 44.18]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 65, 'page_label': '66'}, page_content='PCA Step 3 - Eigenvalues & \\nEigenvectors'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 66, 'page_label': '67'}, page_content='We use eigenvectors to answer: what are the main directions of variance in \\nperformance? (i.e. does PointsPerGame explain AssistsPerGame, or does \\nAssistsPerGame explain  PointsPerGame )?\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25team1 = [ -1.43, −3.91\\n       2.73, 0.68\\n                     −0.08, −2.18\\n      4.85, 12.71\\n                    −1.53, −1.17\\n      −4.56, −6.12] \\nCovariance matrix = \\n[ 11.23, 19.79,\\n19.79, 44.18]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 67, 'page_label': '68'}, page_content='First, we must understand matrices as linear transformations of coordinate \\nspace. \\nFor example, if we were to take a vector and calculate its dot product with this \\nmatrix, this would result in the coordinate moving to another point in our \\ncartesian plot.\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25Covariance matrix = \\n[ 11.23, 19.79,\\n19.79, 44.18] \\nCovariance * [ 1, 1  ]     =  [ 31.02,  63.97 ] \\n     \\nNow we are \\nplotting our \\ncovariance \\nvectors.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 68, 'page_label': '69'}, page_content='However, what about the case where our vector does not experience any \\nchange in direction after these linear transformations?\\nThis vector would instead describe the most meaningful axis or direction of \\nrotation\\nCovariance matrix = \\n[ 11.23, 19.79,\\n19.79, 44.18]\\nCovariance * v1    =  v2\\nWhere v2 has a cosine similarity of 0 with v1\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 69, 'page_label': '70'}, page_content='For most datasets, there exists vectors that keep their direction after this matrix \\nmultiplication.\\nWe call these vectors eigenvectors and their scale of transformation \\neigenvalues. We signify these components via the terminology above, where “ A ” \\nis our matrix (dataset of samples).\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25Covariance matrix = \\n[ 11.23, 19.79,\\n19.79, 44.18]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 70, 'page_label': '71'}, page_content='Discovering the eigenvectors and eigenvalues of a matrix is not a trivial \\noperation, so we will skip this step and only focus on the calculation of \\neigenvalues in order to discover the most important components of a \\ndataset.\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25Covariance matrix = \\n[ 11.23, 19.79,\\n19.79, 44.18]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 71, 'page_label': '72'}, page_content='We calculate the eigenvalues and eigenvectors of this covariance matrix using our eigen-decomposition algorithm, which give us the following vectors and values.What do you notice about our eigenvectors? What kind of vectors are they in relation to one another?\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25\\n[ 11.23, 19.79,\\n19.79, 44.18]\\neigenvalue 1 = 53.45\\neigenvector 1  = [-2.13, 1]\\neigenvalue 2 = 0.632\\neigenvector 2  = [0.46, 1]\\nWe will leave this \\ncalculation as a \\nmystery \\n90'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 72, 'page_label': '73'}, page_content=\"These are orthogonal vectors. While these aren't the principal components \\nthemselves, we’ve successfully captured the unique directions of this \\ndataset. This will allow us to calculate new uncorrelated dimensions.\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25\\n[ 11.23, 19.79,\\n19.79, 44.18]\\neigenvalue 1 = 53.45\\neigenvector 1  = [-2.13, 1]\\neigenvalue 2 = 0.632\\neigenvector 2  = [0.46, 1]\\n90\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 73, 'page_label': '74'}, page_content='Furthemore we calculate how much variance is explained by each \\neigenvector by calculating the ratio of their respective eigenvalues.\\nThe higher the value (from 0 to 1) the more important this dimension is.\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25\\n[ 11.23, 19.79,\\n19.79, 44.18]\\neigenvalue 1 = 53.45\\neigenvector 1  = [-2.13, 1]\\neigenvalue 2 = 0.632\\neigenvector 2  = [0.46, 1]\\n90 \\nvariance = \\n53.45/(53.45+0.632)\\nvariance = \\n0.632/(53.45+0.632)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 74, 'page_label': '75'}, page_content='We can see that eigenvector 1 accounts for roughly 98% of variance in our \\ndata. That is, we can explain 98% of movement in our dataset using this \\nsingle dimension.\\nPointsPerGame\\nAssistsPerGame\\n5\\n5 10 15 20 25\\n10\\n15\\n20\\n25\\n[ 11.23, 19.79,\\n19.79, 44.18]\\neigenvalue 1 = 53.45\\neigenvector 1  = [-2.13, 1]\\neigenvalue 2 = 0.632\\neigenvector 2  = [0.46, 1]\\n90 \\nvariance = \\n0.9883\\nvariance = \\n0.0116'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 75, 'page_label': '76'}, page_content='We will now center our graph around 0 to better visualize the PCA \\ntransformation. \\nPointsPerGame\\nAssistsPerGame\\neigenvalue 1 = 53.45\\neigenvector 1  = [-2.13, 1]\\neigenvalue 2 = 0.632\\neigenvector 2  = [0.46, 1]\\nteam1 = [ -1.43, −3.91\\n       2.73, 0.68\\n                     −0.08, −2.18\\n      4.85, 12.71\\n                    −1.53, −1.17\\n      −4.56, −6.12]\\n1 2 3\\n1\\n2\\n3\\n-3\\n-2\\n-1\\n-3 -2 -1'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 76, 'page_label': '77'}, page_content='PCA Step 4 - Mapping Values to \\nLower Dimensions'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 77, 'page_label': '78'}, page_content='We can multiply our combination of eigenvectors (V) with our standardized \\nmatrix (team1) to create new features that express our principal \\ncomponents.\\nV = \\n[-2.13,  0.46\\n        1,          1]\\nteam1 = [ -1.43, −3.91\\n       2.73, 0.68\\n                     −0.08, −2.18\\n      4.85, 12.71\\n                    −1.53, −1.17\\n      −4.56, −6.12]\\nteam1 * V = …\\nPointsPerGame\\nAssistsPerGame\\n1 2 3\\n1\\n2\\n3\\n-3\\n-2\\n-1\\n-2 -1-3'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 78, 'page_label': '79'}, page_content='Remember the main purpose of PCA is reduce our number of variables, \\ncurrently it seems that we still have 2 variables. However, let’s recall how \\ndid we determine the importance of each eigenvector?\\nV = \\n[-2.13,  0.46\\n        1,          1]\\nteam1 = [ -1.43, −3.91\\n       2.73, 0.68\\n                     −0.08, −2.18\\n      4.85, 12.71\\n                    −1.53, −1.17\\n      −4.56, −6.12]\\nteam1 * V =  [ -0.86, -4.56\\n       -5.13, 1.94\\n                     -2.01, -2.22\\n      2.38, 14.94\\n                    2.09, -1.87\\n      3.59, -8.22]\\nPC1\\nPC2\\n2 4 6\\n2\\n4\\n6\\n–6\\n–4\\n–2\\n-4 –2-6'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 79, 'page_label': '80'}, page_content='We utilize the proportion of variance explained to determine the \\nimportance of principal components. The general rule of thumb is to utilize \\nthe smallest number of components that explain 80%-90% of variance. \\nWhich PC explains almost 100% of variance?\\nV = \\n[-2.13,  0.46\\n        1,          1]\\nteam1 = [ -1.43, −3.91\\n       2.73, 0.68\\n                     −0.08, −2.18\\n      4.85, 12.71\\n                    −1.53, −1.17\\n      −4.56, −6.12]\\nteam1 * V =  [ -0.86, -4.56\\n       -5.13, 1.94\\n                     -2.01, -2.22\\n      2.38, 14.94\\n                    2.09, -1.87\\n      3.59, -8.22]\\nPC1\\nPC2\\n2 4 6\\n2\\n4\\n6\\n–6\\n–4\\n–2\\n-4 –2-6\\nPC1 variance = \\n0.9883\\nPC2 variance = \\n0.0116\\nThe more variance a \\nPC explains, the more \\npowerful it is.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 80, 'page_label': '81'}, page_content='PC1. Therefore we can simply discard PC2 and use PC1 in our ML algorithm \\nto get the least noisy predictions. Remember, your unseen (test) data must \\nalso be multiplied by your calculated eigenvectors.\\nV = \\n[-2.13,  0.46\\n        1,          1]\\nteam1 = [ -1.43, −3.91\\n       2.73, 0.68\\n                     −0.08, −2.18\\n      4.85, 12.71\\n                    −1.53, −1.17\\n      −4.56, −6.12]\\nteam1 * V =  [ -0.86, \\n       -5.13,\\n                     -2.01, \\n      2.38,\\n                    2.09, \\n      3.59]\\nPC12 4 6-4 –2-6\\nPC1 variance = \\n0.9883\\n0\\nYou’ve just reduced your dataset to 1 dimension \\nand kept 98% of original variance!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 81, 'page_label': '82'}, page_content='PCA Summary \\nFor repetition, the Principal Component Analysis (PCA) entails the \\nfollowing steps:\\n1. Standardize the data via the mean\\n2. Calculate the covariance matrix\\n3. Calculate the eigenvalues and eigenvectors of the covariance \\nmatrix\\n4. Utilize eigenvectors to calculate your new principal components.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 82, 'page_label': '83'}, page_content='Additional Implementations of \\nDimensionality Reduction'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 83, 'page_label': '84'}, page_content='Additional Dimensionality Reduction Techniques\\nWhile PCA is the ﬁrst dimensionality reduction algorithm almost all ML \\nengineers learn, it is by no means is the only technique. There is also: \\n● t-SNE (manifold learning): \\nhttps://www.datacamp.com/tutorial/introduction-t-sne  \\n● Independent Component Analysis\\n● Linear Discriminant Analysis\\n● Low Variance Filter\\n● Transformers'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 84, 'page_label': '85'}, page_content='PCA Lab'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 85, 'page_label': '86'}, page_content='PCA Lab\\nComplete the pca.ipynb notebook.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 86, 'page_label': '87'}, page_content='Wrap Up'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 87, 'page_label': '88'}, page_content='Thursday\\nML Review\\n● Review ML concepts from the week\\n● Work on TLAB #2'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Dimensionality Reduction with PCA', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Dimensionality Reduction with PCA.pdf', 'total_pages': 89, 'page': 88, 'page_label': '89'}, page_content='Lab (Due 04/22)\\nYou are a data scientist working at an up & coming music platform startup \\nthat just secured its Series B ﬁnancing. \\nWith this infusion of new cash ﬂow, you are tasked with building an \\nunsupervised recommendation algorithm that will recommend users new \\nsongs based on their previous listening history. As this is a brand new \\nproject, you will have to build this project from scratch.\\nSubmit a link to your GitHub repository by 4/22.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 0, 'page_label': '1'}, page_content='Data Wrangling and \\nFeature Engineering'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 1, 'page_label': '2'}, page_content='Agenda - Schedule\\n1. Identifying “Good” Data\\n2. Data Cleaning & Normalizing\\n3. Feature Engineering\\n4. Break\\n5. Feature Engineering Lab\\nWe discussed converting numeric into categorical \\nvariables, now let’s discuss the reverse.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 2, 'page_label': '3'}, page_content='Agenda - Goals\\n● …'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 3, 'page_label': '4'}, page_content='Announcements\\n● TLAB #2 Checkpoint Due 7/9\\n● Pre-Class Quiz #7 Due 7/14'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 4, 'page_label': '5'}, page_content='Data Wrangling'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 5, 'page_label': '6'}, page_content='Data Prep\\nThe entire goal of today is to get our data ready for machine learning\\nRemember, end of the day, machine learning is essentially just a bunch of \\nfancy statistics\\nThat means we need our data to be clean!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 6, 'page_label': '7'}, page_content='Good Data\\nWhat does good data look like?\\nIt is:\\n- consistently formatted (we don’t mix numbers and strings if we can help it)\\n- primarily numerical (unless dealing with language models)\\n- scaled consistently (we discuss this later)\\n- minimal/unnecessary outliers are removed\\n- well labeled\\nIn general, this just means it is not going to have issues and this comes with experience\\nThe exact steps change with each model, today we will discuss general best practices for good \\ndata'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 7, 'page_label': '8'}, page_content='Good Data\\nT o get our data there we will perform data wrangling and feature processing\\nDon’t get too caught up in the terminology, these two overlap a lot and are basically the \\nsame thing \\nData Wrangling focuses on cleaning and standardizing our data\\nFeature processing focuses on creating , removing, or modifying features \\nThis is prior to pre-processing for modeling\\nPre-processing tends to do things more closely tied to our model and we’ll give you a taste \\nnext session'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 8, 'page_label': '9'}, page_content='Wrangle my data?\\nYep, we’re going to have to herd this \\ndata together into something \\nmeaningful\\nData wrangling (and feature \\nengineering) is more art than science\\nIt takes experience, domain \\nknowledge, and some technical skill\\nT oday, we focus on the intuition'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 9, 'page_label': '10'}, page_content='Data Wrangling\\nIn general, data wrangling is the idea of getting raw data ready for machine \\nlearning\\nThe key concepts of data wrangling are:\\n- cleaning\\n- transforming\\n- removing outliers'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 10, 'page_label': '11'}, page_content='Cleaning Data\\nHere are some key concepts of cleaning data:\\n- removing duplicates\\n- dealing with missing values'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 11, 'page_label': '12'}, page_content='Removing Duplicates\\nThis one is pretty easy to understand! If data is duplicated then it will be \\nweighed incorrectly\\nThis is pretty easy to do with data in pandas.\\nYou might want to use something like df.duplicated() and \\ndf.drop_duplicates()'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 12, 'page_label': '13'}, page_content='Missing Values\\nDealing with missing values is an art, not a science\\nFirst, ﬁgure out how many missing values there are in each feature:\\ndf.isna().sum()\\nIf there are a lot of missing values, consider dropping that feature\\ndf.drop() or df.dropna()\\nBut if there aren’t a lot… maybe we can ﬁll in the gaps?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 13, 'page_label': '14'}, page_content='Imputing Missing Values\\nWhen we ﬁll in missing values, we call that “imputing”\\nThere is no one way. We generally use the method df.ﬁllna()\\nYou can either:\\n- ﬁll in all the missing values with the same value (maybe 0)\\n- ﬁll in with the average, median, or other statistical measure\\n- ﬁll in with the value before or after the row\\nThere are merits to each. We should stick to what makes sense for the data'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 14, 'page_label': '15'}, page_content='Imputing Missing Values\\nMissing data means no record? Consider putting in 0\\nMissing data is due to a forgotten record but is mostly stable? Consider \\nusing the mean\\nMissing data is generally sequential and moves pretty consistently with \\ntime? Consider backﬁll (using value of the next record) or forward ﬁll (using \\nthe value of the record prior) to ﬁll in the gap\\nEnd of the day, you can try different methods and see what works best for \\nyour data'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 15, 'page_label': '16'}, page_content='Transforming Data\\nHere are the key concepts regarding transforming data into something \\nmeaningful:\\n- changing data types\\n- reshaping data\\n- converting/encoding categorical data'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 16, 'page_label': '17'}, page_content='Changing Data Types\\nThis is straightforward! Have numbers that should be numbers but reading \\nas strings? Convert that to a numerical data type!\\nDo something like pd.astype()'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 17, 'page_label': '18'}, page_content='Reshaping Data\\nReshaping data is where we \\ncan get creative\\nRemember, the ideal is that \\neach row is a separate \\nrecord \\nMaybe instead our data has \\nour variable of interest as \\ncolumns. Think student \\nperformance'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 18, 'page_label': '19'}, page_content='Reshaping Data\\nSure, the wide format is easier \\nfor us to understand but it’s \\nharder because our model has \\ntrouble understanding that \\n“math” , “literature” , and “pe” are \\nrelated as one singular thing \\nknown as a “subject”\\nThe long format lets us better \\ntrain our models\\nConsider using pd.melt()'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 19, 'page_label': '20'}, page_content='Encoding Categorical Variables\\nRemember, most of our models require the usage of numbers and \\ncannot handle text\\nIn fact, many will refuse to run if there is any string value\\nMaybe we need the data provided by the string though! How can we \\nstill use it?\\nWe encode that data as numerical!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 20, 'page_label': '21'}, page_content='Encoding Methods\\nThere are 2 main methods we will talk about:\\nOne-Hot Encoding - we turn every category into a boolean with each \\nrow getting a 1 or a 0\\nDummy Encoding - the same thing as one-hot encoding but we leave \\none variable out (we’ll explain why)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 21, 'page_label': '22'}, page_content='One-Hot Encoding'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 22, 'page_label': '23'}, page_content='Dummy Encoding'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 23, 'page_label': '24'}, page_content='One-Hot vs Dummy Encoding'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 24, 'page_label': '25'}, page_content='One-Hot vs Dummy Encoding\\nSo why choose dummy encoding?\\nBecause of something called multicollinearity which basically means \\nthat the categories are very closely related to each other and mess up \\nour model\\nThink of it this way, if there are only 3 options and I know 2 of the \\noptions are false, do I need to explicitly state the 3rd option as true?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 25, 'page_label': '26'}, page_content='One-Hot vs Dummy Encoding\\nNo! I can derive that the 3rd option must be true because the other 2 \\nare false\\nHowever, if I leave that 3rd option in for the machine learning \\nalgorithm then it’ll get trapped into thinking that the 3rd option \\nmatters more than it does'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 26, 'page_label': '27'}, page_content='One-Hot vs Dummy Encoding\\nT o do one-hot encoding in pandas use get_dummies() \\nhttps://pandas.pydata.org/docs/reference/api/pandas.get_dummies.h\\ntml \\npd.get_dummies()\\nto do dummy encoding:\\npd.get_dummies(drop_ﬁrst=True)\\nDon’t forget to drop your newly encoded column!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 27, 'page_label': '28'}, page_content='Removing Outliers\\nAgain, this is an art\\nYou can just drop the records that have outliers but use EDA and your \\nbest judgment \\nMaybe the outlier is meaningful!\\nOkay! Now that our data is in a better place, lets feature engineer'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 28, 'page_label': '29'}, page_content='For more information on data normalization & outlier removal, read up on the following: \\nhttps://developers.google.com/machine-learning/crash-course/numerical-data/normaliz\\nation'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 29, 'page_label': '30'}, page_content='Feature Engineering'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 30, 'page_label': '31'}, page_content='What is Feature Engineering?\\nFeature engineering is the process of manipulating your data to make the \\nfeatures more useful \\nThere are three major components:\\n- adding features\\n- removing features\\n- modifying features\\nAll of these take experience, knowledge, and understanding of the data'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 31, 'page_label': '32'}, page_content='Removing Features\\nThis is the easiest topic so we’ll start here!\\nRemoving features is basically just saying “this column is useless, let’s get rid \\nof it”\\nMaybe it’s something like customer IDs (no numerical meaning) or the color \\nof the sky \\nBut also, maybe there’s a lot of missing data or the data is extremely skewed\\nSimply put, we can just use df.drop() on these things'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 32, 'page_label': '33'}, page_content='Adding Features - Interaction\\nThis is more about feature extraction than really creating features out of \\nthin air\\nMaybe we have two features like… sq. foot and cost\\nThese 2 features are probably pretty closely related\\nRemember multicollinearity? We do not want to undermine the variables \\nwith each other! \\nIt makes them less useful so why don’t we repurpose these 2 features?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 33, 'page_label': '34'}, page_content='Adding Features\\nWe can add a feature called “price per sq. foot” which is a calculation of \\nprice/sq. foot which gives us an idea of what both features bring without \\nhaving both of them conﬂict\\nWe can now remove those two columns making our feature space smaller'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 34, 'page_label': '35'}, page_content='Adding Features - Polynomial/Interaction\\nLikewise, maybe instead of dividing our features we multiply them\\nFor instance, square footage (it returns!)\\nMaybe we have length and width, it makes sense to convert that to square \\nfootage if we are interested in area\\nOr we have volume and mass which can turn into density\\nThink about the data we have and how to get more information out of it'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 35, 'page_label': '36'}, page_content='Adding Features and then some!\\nThere are many more ways to add features, the goal is to enrich our model \\nby decreasing the overall feature space (combining multiple features into \\none) while avoid overﬁtting\\nAs we get into more advanced models, we will discuss feature engineering \\nspeciﬁc to that model'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 36, 'page_label': '37'}, page_content='Modifying Features\\nModifying features is where we can get a little interesting… some \\ntransformations include:\\n- Log Transformation\\n- Square Root transformation\\n- Creating Binary Features'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 37, 'page_label': '38'}, page_content='Log Transformation\\nModifying features is where we can get a little interesting… two very \\ncommon transformations include:\\n- Log Transformation\\n- Creating Binary Features'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 38, 'page_label': '39'}, page_content=\"Binary Features\\nCreating Binary Features is a great way of simplifying our features\\nThis also helps if the relationship is non-linear and more-so focused on \\ncategorical features\\nMaybe we just care if someone is “old” or “not old” .\\nWe can do something like: df['is_old'] = (df['age'] > 60).astype(int)\\nT o create a binary “is old” vs “not old”\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 39, 'page_label': '40'}, page_content='Log Transformation\\nThe log transformation help normalize our data\\nThe overall goal of Log Transformation is to bring the relationship between the \\npredictor and the output variable to become more linear, the same is true of the \\nsquare root transformation\\nLog Transformation is useful for when values grow very quickly or disproportionately\\nLet’s go over this article for more detail:\\nhttps://www.codecademy.com/article/data-transformations-for-multiple-linear-regr\\nession'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 40, 'page_label': '41'}, page_content='Other Transformations\\nOther transformations include the Square Root Transformation, Box-Cox \\ntransformation, Arcsine Transformation, and more!\\nThe goal is always to help us better understand the relationship between \\nour predictor variables and output variables\\nOver time you will learn which ones to use where but for now stick to log \\ntransformations and binary'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 41, 'page_label': '42'}, page_content='Feature Engineering Lab'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 42, 'page_label': '43'}, page_content='Feature Engineering Lab\\nDownload and complete the Feature Engineering lab in your pod groups.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Feature Engineering and Wrangling', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Feature Engineering and Wrangling.pdf', 'total_pages': 44, 'page': 43, 'page_label': '44'}, page_content=\"Next Week\\nNext Week we will learn about a new machine \\nlearning algorithm called logistic regression.\\nPre-class content for Week 4 will be due 6/25.\\nRead the springer textbook (it will be difﬁcult!) \\nThen, watch the StatQuest videos (it will be a \\nwelcome reprieve). \\n \\nIf you understand what you're doing, you're \\nnot learning anything. - Anonymous\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 0, 'page_label': '1'}, page_content='Hypothesis Testing'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 1, 'page_label': '2'}, page_content='Agenda - Schedule\\n1. Distributions Review & Z-score\\n2. Introduction to Hypothesis T esting\\n3. Hypothesis T esting Thought Experiment\\n4. Break\\n5. TLAB\\nWhere do we expect most of our data to fall?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 2, 'page_label': '3'}, page_content='Agenda - Announcements \\n● TLAB #2 due 4/21'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 3, 'page_label': '4'}, page_content='Agenda - Goals\\n● Review the concept of probability distributions\\n● Understand what a hypothesis test is using a real example\\n● Identify the steps to hypothesis testing'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 4, 'page_label': '5'}, page_content='Distributions Review'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 5, 'page_label': '6'}, page_content='Distributions Review\\nWe’ve spoken about the different distributions that you might encounter \\nduring your data analysis.\\nNext week, we will formally begin the process of doing effective data \\nanalysis using the pandas package.\\nHowever, before we open this new chapter, let’s dive back into the world of \\ndistributions and explore which shapes we might encounter when looking \\nfor changes in our dataset.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 6, 'page_label': '7'}, page_content='Distributions Review\\nT o ensure that we’re operating off of the same vocabulary for the next \\ncouple of slides, let’s review how a distribution visualization is formed once \\nmore.\\nLet’s say we are measuring the caffeine consumption of a typical American. \\nWe get the funds to randomly call 30 phone numbers across America \\n(anyone remember why 30?).'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 7, 'page_label': '8'}, page_content='We will slowly build our histogram as we collect survey responses. \\nCups of coffee\\nNumber of \\nresponses\\n1 2 3 4\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n0'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 8, 'page_label': '9'}, page_content='We call the ﬁrst phone number. A participant named Farukh tells us he \\ndrank 4 cups of coffee in one day! We create our ﬁrst bar for the “4” \\nquantity on our histogram to indicate 1 person drank 4 cups of coffee.\\nCups of coffee\\nNumber of \\nresponses\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n1 2 3 40'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 9, 'page_label': '10'}, page_content='We call the next participant and they give us a more reasonable response of \\n2 cups of coffee. We then indicate 1 person drank 2 cups of coffee.\\nCups of coffee\\nNumber of \\nresponses\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n1 2 3 40'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 10, 'page_label': '11'}, page_content='The next randomly selected participant also tells us they drank 2 cups of coffee, this \\nbumps our “2” bar. We now see that 2 participants have drank 2 cups of coffee and 1 \\nparticipant has drank 4.\\nCups of coffee\\nNumber of \\nresponses\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n1 2 3 40'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 11, 'page_label': '12'}, page_content='Our next participant tells us they drank 1 cup of coffee \\nCups of coffee\\nNumber of \\nresponses\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n1 2 3 40'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 12, 'page_label': '13'}, page_content='We then complete our data collection by surveying the rest of the 30 participants. \\nCups of coffee\\nNumber of \\nresponses\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n1 2 3 40'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 13, 'page_label': '14'}, page_content='We then complete our data collection by surveying the rest of the 30 participants. \\nCups of coffee\\nNumber of \\nresponses\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n1 2 3 40'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 14, 'page_label': '15'}, page_content='We then complete our data collection by surveying the rest of the 30 participants. \\nCups of coffee\\nNumber of \\nresponses\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n1 2 3 40'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 15, 'page_label': '16'}, page_content='We then complete our data collection by surveying the rest of the 30 participants. \\nCups of coffee\\nNumber of \\nresponses\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n1 2 3 40'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 16, 'page_label': '17'}, page_content='We then complete our data collection by surveying the rest of the 30 participants. \\nCups of coffee\\nNumber of \\nresponses\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n1 2 3 40'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 17, 'page_label': '18'}, page_content='Skipping ahead, what kind of distribution do you notice we form after we are done \\ncollecting all of our data?\\nCups of coffee\\nNumber of \\nresponses\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n1 2 3 40'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 18, 'page_label': '19'}, page_content='While this is technically a histogram, we could calculate the probability of pulling a \\nspeciﬁc “cups of coffee” from our dataset. This gives us a probability distribution \\nwhich we see is the normal distribution.\\nCups of coffee\\nNumber of \\nresponses\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n2 3 40\\n1\\n10%\\n20%\\n5%'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 19, 'page_label': '20'}, page_content='Distributions Review\\nLet’s go over the names of distributions and what they might indicate about \\nour real-world dataset before we move forward:\\n● Uniform distribution\\n● Binomial distribution\\n● Normal distribution\\nCan anyone provide context, when might we see these distributions?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 20, 'page_label': '21'}, page_content='Distributions Review\\nRemember, distributions don’t happen by chance! Each distribution \\nemerges from speciﬁc real-world phenomenon:\\n● Uniform distribution: Random games of chance/simulations\\n● Binomial distribution: Repeated games of chance\\n● Normal distribution: Real-life distributions of physical phenomenon \\n(height of humans, weight of frogs, daily coffee consumption)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 21, 'page_label': '22'}, page_content='Thought experiment: What if you survey one more participant who indicates that \\nthey drink 10 cups of coffee a day. Can we reasonably assume they are part of this \\ndistribution? First, let’s see how the z-score helps us determine outliers.\\nCups of coffee\\nNumber of \\nresponses\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n1 2 3 40 10…'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 22, 'page_label': '23'}, page_content='Z-Score'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 23, 'page_label': '24'}, page_content='Normal Distribution\\nWe see the normal distribution when observing \\nmeasurements on real world quantities (height, miles \\ndriven, mosquito wingspan, number of gun crimes in the \\nUS). \\nSo far, we’ve been discussing the perfect case of the \\nstandard normal distribution.\\nThis is the case where the mean & median are 0, the \\nstandard deviation is 1.\\nHowever, we can turn our normal distributions into \\nthe standard normal by standardizing our dataset.\\nBy converting our normal \\ndistribution to the standard \\nnormal, we are able to better \\ndetermine when a sample is an \\noutlier.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 24, 'page_label': '25'}, page_content='We will revisit this process when we get introduced to machine learning.\\nBut ﬁrst, let’s identify the calculation we use to standardize our data. We \\ncall this the Z-score. We calculate this “score” by subtracting each sample by \\nthe mean and dividing it by the standard deviation.\\nIn essence, this tells us “how many standard deviations is our sample \\nfrom the mean.”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 25, 'page_label': '26'}, page_content='T o see how the Z-score allows us to detect outliers, let’s work with \\nthe following toy dataset of customer wait-times at a coffee shop.\\nNotice that we form a normal distribution (with a slight skew)…\\ndata = [5, 6, 7, 8, 8, 9, 9, 9, 9, 10, 10, 11, 16]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 26, 'page_label': '27'}, page_content='But this is still not a standard normal! I.e. our average is not 0 and \\nour standard deviation is not 1.\\ndata = [5, 6, 7, 8, 8, 9, 9, 9, 9, 10, 10, 11, 16]\\nAverage = 9\\nSample Standard Dev ~= 2.6'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 27, 'page_label': '28'}, page_content='Let’s calculate the z-score of each sample, note that we apply this \\ncalculation to each value in our list to create a brand new list.\\nDoes anyone recall the name of this pattern in Python?\\ndata = [5, 6, 7, 8, 8, 9, 9, 9, 9, 10, 10, 11, 16]\\nAverage = 9\\nSample Standard Dev ~= 2.6'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 28, 'page_label': '29'}, page_content='Let’s start off with the ﬁrst element (5)… \\ndata = [5, 6, 7, 8, 8, 9, 9, 9, 9, 10, 10, 11, 16]\\nAverage = 9\\nSample Standard Dev ~= 2.6\\nnew_data = []\\nz_score = (5 - 9) / 2.6\\nz_score = …'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 29, 'page_label': '30'}, page_content='Let’s recall our interpretation of the z-score “how many standard \\ndeviations is our sample from the mean.” Using this deﬁnition, \\nhow many standard deviations is 5 from the mean???\\ndata = [5, 6, 7, 8, 8, 9, 9, 9, 9, 10, 10, 11, 16]\\nAverage = 9\\nSample Standard Dev ~= 2.6\\nnew_data = []\\nz_score = (5 - 9) / 2.6\\nz_score = -1.53'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 30, 'page_label': '31'}, page_content='Using the Z-score, state that our ﬁrst data point is -1.53 standard \\ndeviations from the mean. Because this is a negative value, we \\nstate that it is 1.53 standard deviations to the left of the mean.\\ndata = [5, 6, 7, 8, 8, 9, 9, 9, 9, 10, 10, 11, 16]\\nAverage = 9\\nSample Standard Dev ~= 2.6\\nnew_data = [-1.53, …]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 31, 'page_label': '32'}, page_content='We’re not done yet… let’s continue this calculation for the rest of \\nthe data points.\\ndata = [5, 6, 7, 8, 8, 9, 9, 9, 9, 10, 10, 11, 16]\\nAverage = 9\\nSample Standard Dev ~= 2.6\\nnew_data = [-1.53, -1.15, …]\\nz_score = (6 - 9) / 2.6\\nz_score = -1.15'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 32, 'page_label': '33'}, page_content='We’re not done yet… let’s continue this calculation for the rest of \\nthe data points.\\ndata = [5, 6, 7, 8, 8, 9, 9, 9, 9, 10, 10, 11, 16]\\nAverage = 9\\nSample Standard Dev ~= 2.6\\nnew_data = [-1.53, -1.15, -0.76, …]\\nz_score = (7 - 9) / 2.6\\nz_score = -0.76'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 33, 'page_label': '34'}, page_content='We’re not done yet… let’s continue this calculation for the rest of \\nthe data points.\\ndata = [5, 6, 7, 8, 8, 9, 9, 9, 9, 10, 10, 11, 16]\\nAverage = 9\\nSample Standard Dev ~= 2.6\\nnew_data = [-1.53, -1.15, -0.76, -0.38, …]\\nz_score = (8 - 9) / 2.6\\nz_score = -0.38'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 34, 'page_label': '35'}, page_content='Eventually we will complete the loop and calculate the z-score for \\neach sample. This gives us our standard normal distribution. \\ndata = [5, 6, 7, 8, 8, 9, 9, 9, 9, 10, 10, 11, 16]\\nAverage = 9\\nSample Standard Dev ~= 2.6\\nnew_data = [-1.555, -1.166, -0.778, -0.389, -0.389, 0.0, 0.0, 0.0, 0.0, 0.389, \\n0.389, 0.778, 2.722]'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 35, 'page_label': '36'}, page_content='Eventually we will complete the loop and calculate the z-score for \\neach sample. This gives us our standard normal distribution. \\nNotice that the mean and standard deviation are approaching 0 \\nand 1 respectively (the more samples we get, the closer we get to \\nthis value).\\nnew_data = [-1.555, -1.166, -0.778, -0.389, -0.389, 0.0, 0.0, 0.0, 0.0, 0.389, 0.389, \\n0.778, 2.722]\\nAverage = 0.000077\\nSample Standard Dev ~= 1.041'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 36, 'page_label': '37'}, page_content='Most importantly, note that we can now directly observe when a  \\nsample is truly an outlier.\\nThinking back to the normal distribution, within how many \\nstandard deviations do we expect ~99% of our data to be?\\nnew_data = [-1.555, -1.166, -0.778, -0.389, -0.389, 0.0, 0.0, 0.0, 0.0, 0.389, 0.389, \\n0.778, 2.722]\\nAverage = 0.000077\\nSample Standard Dev ~= 1.041'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 37, 'page_label': '38'}, page_content='Within 3 standard deviations.\\nDo you see any z-score representing more than 3 standard \\ndeviations on either the negative or positive side? No! This means \\nthat, so far, none of this data represents an outlier.\\nnew_data = [-1.555, -1.166, -0.778, -0.389, -0.389, 0.0, 0.0, 0.0, 0.0, 0.389, 0.389, \\n0.778, 2.722]\\nAverage = 0.000077\\nSample Standard Dev ~= 1.041\\nKeep in mind that we only have 13 samples. \\nThis is a tiny dataset, and as we collect more \\ndata, we will need to update our z-scores.\\nRemember z-scores change as you collect \\nmore data.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 38, 'page_label': '39'}, page_content='But let’s go back to our coffee study. Even without the proof of Z-scores, do you \\nnotice any values that are obviously outliers?\\nCups of coffee\\nNumber of \\nresponses\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n1 2 3 40 10…'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 39, 'page_label': '40'}, page_content='Clearly we have a 10-coffee a day outlier. If we were to calculate this z-score we \\nwould get 8. This means that this participant is 8 standard deviations away from the \\nmean! \\nCups of coffee\\nNumber of \\nresponses\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n1 2 3 40 10…'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 40, 'page_label': '41'}, page_content='Assuming this person is still alive, a question we should consider is: is this person uniquely  different from the average person we surveyed? Or framed another way, does this person belong to a different distribution of people? This is a question that companies try to answer every day.\\nCups of coffee\\nNumber of \\nresponses\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n1 2 3 40 10…\\nOther follow up questions \\nmight include:\\n● what makes these \\npeople such voracious \\ncoffee drinkers?\\n● are they consuming the \\nsame type of coffee? \\nRegular coffee drinkers Coffee fanatics'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 42, 'page_label': '43'}, page_content='Introduction to Hypothesis \\nTesting'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 43, 'page_label': '44'}, page_content='We do AB testing to check if users that used an alternative product \\nresponded/reacted differently. \\nDid a green button make our customers engage with our \\nwebsite more?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 44, 'page_label': '45'}, page_content='We do use the chi-squared test to check if two categorical variables are \\ndependent on one another.\\nDo changes in offer affect if a subscriber responds or not?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 45, 'page_label': '46'}, page_content='Like we saw in foundations day 1, it’s important and proﬁtable to note the \\ndifference between distributions. One represents a fabricated dataset, \\nwhile another represents a real-world dataset.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 46, 'page_label': '47'}, page_content='Introduction to Hypothesis Testing\\nBefore we formally introduce hypothesis testing, let’s identify some \\nframeworks of experiments we could run:\\n● One Sample T est: Does one group contain an average we expect?\\n● Two Sample T est: Is one group different from another group?\\nNote that experiments like these must be set up well before you perform \\ndata analysis so that you can guarantee that the effects you observe are \\ntruly due to some speciﬁc change.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 47, 'page_label': '48'}, page_content='One sample testing example: Let’s say I want to check if data science \\nstudents are getting at least 8 hours of sleep per day. I survey 10 students \\nand get the following dataset and average.\\ndata = [6.1, 7.2, 6.4, 6.9, 5.8, 6.7, 7.0, 5.9, 6.3, 6.6]\\nExpected Avg = 8 \\nReal Avg = 6.49\\nDoes this value seem off from our expected average \\nof 8? \\nHow off is this calculated average from the \\nexpected average?\\nAll of these questions can be answered using \\none-sample testing.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 48, 'page_label': '49'}, page_content='One-Sample Test\\nDuring one sample testing, we collect data and check if the sample set we \\ncollected has an expected mean.\\nThis is not as simple as just calculating the mean of a sample and comparing \\nit with our expected mean. Keep in mind that since samples are \\napproximations of the population, we expect a bit of variability in our \\ncalculations. We need a special formula to answer this question.\\nThe one-sample test gives us the ability to determine if a calculated sample \\nfalls within some expected range of values.\\nWe will not go over these calculations \\njust yet. Instead we will get \\nintroduced to these formulas next \\nWednesday.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 49, 'page_label': '50'}, page_content='Two sample testing example: Let’s say I made a single change to the TKH \\nwebsite (I made the logo orange) and I want to measure how long users \\nspend on the website (in minutes). I direct 10 users to the unmodiﬁed \\noriginal website and 10 other users to the modiﬁed website. \\noriginal_site  = [5.25, 4.93, 5.32, 5.76, 4.88, 4.88, 5.79, 5.38, 4.77, 5.27]\\noriginal_average = 5.223\\nnew_site  = [5.27, 5.27, 5.62, 4.54, 4.64, 5.29, 5.09, 4.94, 5.24, 4.60]\\nnew_average = 5.05\\nWhat happened to the average amount of time on \\nthe site after we made this change?\\nIs this change signiﬁcant or could it be due to \\nrandom chance?\\nAll of these questions can be answered using \\ntwo-sample testing.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 50, 'page_label': '51'}, page_content='Two-Sample Test\\nDuring two sample testing, we collect from two groups: ideally the control \\nand the experimental group. \\nThe control gets no “treatment” , while the experimental receives some sort \\nof “treatment. ”\\nThe two-sample test gives us the ability to determine if some sort of change \\nhad a real impact on a population of users.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 51, 'page_label': '52'}, page_content='Introduction to Hypothesis Testing\\nThese are just quick introductions to the testing methods we will get \\nintroduced to next week.\\nFor now, let’s understand how we form a hypothesis test using the domain \\nof \\nEXTRA-SENSORY PERCEPTION'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 52, 'page_label': '53'}, page_content='Example of Hypothesis Testing \\n- ESP Study'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 53, 'page_label': '54'}, page_content='If you think this is ridiculous, the CIA in 1984 didn’t think so: \\nhttps://www.cia.gov/readingroom/docs/cia-rdp96-00788r001900760001-\\n9.pdf'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 54, 'page_label': '55'}, page_content='Hypothesis Testing - ESP Testing\\nT o introduce the concept of hypothesis testing, let’s go through a live demonstration.\\nI am a researcher of ghosts, clairvoyance, and other extra-natural phenomena.\\nI want to prove that extra sensory perception exists. I will run the following \\nexperiment:\\n● I have two buttons.\\n● I randomly hide the words “Cat” and “Dog” behind these buttons\\n● I ask ~60 individuals to guess which button has the word “Cat” on it\\n● I calculate how often individuals are correct\\nClick here to run through this experiment: https://esp-experiment.streamlit.app/'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 55, 'page_label': '56'}, page_content='Hypothesis Testing - ESP Testing\\nIn order to perform this experiment, and then interpret the data I must perform the \\nfollowing steps:\\n1. Establish my research hypothesis, as well as statistical hypothesis.\\n2. Establish my null and alternative hypothesis.\\n3. Calculate my test-statistic and sampling distribution.\\n4. Calculate p-value.\\n5. Interpret ﬁndings (as opposed to drawing conclusions!)\\nWhile this experiment is purely introductory, the same pattern follows for all other \\nhypothesis testing methods.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 56, 'page_label': '57'}, page_content='Hypothesis Testing - 1) Establish Hypothesis\\nWe have some idea about the world. We want to see if our data supports or refutes \\nthis idea.\\nT o do this, we must ﬁrst identify our research and statistical hypothesis: \\nResearch hypothesis: testable scientiﬁc claim \\nex: drinking magnesium supplements lowers stress\\nStatistical hypothesis: correspond to speciﬁc claims about the characteristics of the \\ndata \\nex: experimental group mean stress levels will be less than control group\\nWhat will be my research hypothesis here, and \\nwhat is my statistical hypothesis?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 57, 'page_label': '58'}, page_content='Hypothesis Testing - 1) Research vs Stats\\nIn this ESP example, I have the following hypothesis.\\nResearch hyp: ESP exists\\nStatistical hyp: The ratio of correct answers will NOT be 0.5 (chance). This \\nmeans it could be either greater than or less than 0.5\\nESP either works in the positive direction (ESP tells where the correct \\nbutton is), \\nESP works in the negative (ESP gives a signal where the correct button is, \\nbut humans interpret that as the wrong answer).'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 58, 'page_label': '59'}, page_content='Hypothesis Testing - 2) Null vs Alt \\nIn order to prevent ourselves from “cheating” and drawing conclusions where they do \\nnot exist, we must next establish a null and alternative hypothesis.\\nNull Hypothesis: the exact opposite of what I am testing,\\nAlternative Hypothesis: the thing that I am trying to prove, \\nBecause what I’m about to do is invent a new statistical hypothesis (the “null” hypothesis, \\nH0) that corresponds to tand then focus exclusively on that, almost to the neglect of the \\nthing I’m actually interested in (which is now called the “alternative” hypothesis, H1).'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 59, 'page_label': '60'}, page_content='Hypothesis Testing - 2) Null vs Alt \\nThe important thing to recognise is that the goal of a hypothesis test is not \\nto show that the alternative hypothesis is (probably) true; \\nthe goal is to show that the null hypothesis is (probably) false. \\nWhat is the null and alt of my ESP statistical \\nhypothesis (in the context of correct vs wrong \\nguesses).'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 60, 'page_label': '61'}, page_content='Hypothesis Testing - 2) Null vs Alt \\nIn this case, if ESP did not exist, then our supposed ratio of correct guesses \\nshould be 0.5 (chance). This is our null hypothesis (data shows no effect).\\nH0: theta = 0.5\\nHowever if ESP exists (in either direction), then we don’t necessarily want to \\nname a speciﬁc value that our correct ratio should go, but rather state that \\nthe ratio of correct guesses is NOT 0.5 (not chance). This is our alternative \\nhypothesis (data might show effect).\\nH1: theta != 0.5'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 61, 'page_label': '62'}, page_content='Hypothesis Testing - 2) Null vs Alt \\nThe null hypothesis is the defendant, the researcher is the prosecutor, and \\nthe statistical test itself is the judge. \\nJust like a trial, there is a presumption of innocence: \\nthe null hypothesis is deemed to be true unless you, the researcher, can \\nprove beyond a reasonable doubt that it is false.\\nBasically we are stating: the effect we are looking for does not exist, and then \\nwe check if our data agrees with this hypothesis.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 62, 'page_label': '63'}, page_content='Hypothesis Testing - 2) Null vs Alt \\nYour goal when doing so is to maximise the chance that the data actually \\nshows an effect.\\nThe catch is that the statistical test sets the rules of the trial, ’\\nand those rules are designed to protect the null hypothesis – speciﬁcally to \\nensure that if the null hypothesis is actually true, the chances of a false \\nconviction are guaranteed to be low.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 63, 'page_label': '64'}, page_content='By performing hypothesis testing in this fashion we are attempting to \\nminimize our chances of making a type I error, where the Null is true (there \\nis no effect in your dataset), but you erroneously assume there is an effect.\\nWe also control for this error using something called signiﬁcance level.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 64, 'page_label': '65'}, page_content='Hypothesis Testing - 3) Test-Statistic & Distribution\\nWhich ratio of correct guesses would lead us to concede that the null is \\nincorrect? \\nFor example we tested N = 100 people, and X = 53 of them got the question \\nright,...\\nwe’d probably be forced to concede that the data are quite consistent with \\nthe null hypothesis.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 65, 'page_label': '66'}, page_content='Hypothesis Testing - 3) Test-Statistic & Distribution\\nWhat about if X = 99 of our participants got the question right or only X = 3 \\npeople got the answer right,...'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 66, 'page_label': '67'}, page_content='Hypothesis Testing - 3) Test-Statistic & Distribution\\nWhat about if X = 99 of our participants got the question right or only X = 3 \\npeople got the answer right,...\\n we’d be similarly conﬁdent that the null was wrong. This metric (X) is the \\ntest-statistic which we will use to draw conclusions on our null hypothesis. \\nIf X is super large (or super small), we consider that as evidence that the null \\nis false. However if X is around 50, then we state that the null is most likely \\nnot false.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 67, 'page_label': '68'}, page_content='Let’s suppose for the moment that the null hypothesis really is true: ESP doesn’t exist, and the true probability that anyone picks the correct colour is exactly θ = 0.5. \\nWhat would we expect the data to look like? (i.e. which probability distribution do we of games of random chance with multiple trials?)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 68, 'page_label': '69'}, page_content='We will use the binomial distribution as we are discussing repeated trials of \\ngames of random chance. This is our sampling distribution of the test \\nstatistic.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 69, 'page_label': '70'}, page_content='As of data collection, we have N=95 (95 responses). This gives us the following simulated binomial distribution. \\nWe state: if ESP did not exist, this is what our distribution of X would look like.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 70, 'page_label': '71'}, page_content='Notice that the average of this dataset is around ~48. Therefore our Null \\nHypothesis will state that X = 48.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 71, 'page_label': '72'}, page_content='Hypothesis Testing - 4) Critical Decisions\\nUsing this distribution and the metric we’ve \\ncalculated from our survey, we can now \\nﬁgure out if ESP exists in our dataset.\\nOur collected X  is 49 (we correctly ﬁgured out \\nwhere the cat is 49 times)\\nIs this pretty darn close to X=48???'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 72, 'page_label': '73'}, page_content='Hypothesis Testing - 4) Critical Decisions\\nYes! \\nIn fact if we were to calculate the z-score of \\nX=49 we would get 0.308\\nThis means that our collected value is only \\n0.308 standard deviations away from the \\nmean.\\nThis is a completely reasonable amount that \\nwe should expect if ESP does not exist and \\nwe randomly sampled our population.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 73, 'page_label': '74'}, page_content='Hypothesis Testing - 4) Critical Decisions\\nThe critical region corresponds to those values of X for which we would \\nreject the null hypothesis.\\nAs we can observe, getting values near the mean are expected and we \\nshould not consider those values to be part of the critical region.\\nNext week, we will formally identify what this critical region is.\\nFor now we will state that the critical region falls anywhere past we get a \\nz-score of 2.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 74, 'page_label': '75'}, page_content='In this distribution, we see that Z=-2 when X=38, and Z=2 when X=57.\\nNotice that this demarcates two areas under the probability distribution \\n(near the tails) where we reject the null hypothesis. \\nIf we get an X \\nvalue that falls \\nin the red, most \\nlikely our null \\nhypothesis is \\nfalse!'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 75, 'page_label': '76'}, page_content='Let’s say we get that X=67! Wow this falls past the critical region and we get a Z-score of 4.\\nFor those of you familiar with calculus, keep in mind that we can calculate the area under the curve (which is then expressed as a probability)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 76, 'page_label': '77'}, page_content='The probability that X=67 belongs to this distribution (where we assume \\nthe null is true) is 0.0039%. This is extremely small, therefore we would \\nstate that we reject the null hypothesis.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 77, 'page_label': '78'}, page_content='However, keep in mind that we got X=49. Not only does this not fall in the \\ncritical region, but the likelihood of getting this value in our assumed \\ndistribution is 83.76%. This shows that X=49 is a very typical amount and \\nthat we cannot reject the null hypothesis.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 78, 'page_label': '79'}, page_content='Hypothesis Testing - 5) Interpret Findings\\nOur presumption of innocence held (the X value we calculated ﬁt well with \\nour null distribution).\\nTherefore we cannot reject the null hypothesis that X=48.\\nThis corresponds with the statement ESP does not exist.\\nNote that we are only interpreting what the data tells us, and this hinges on \\nhow well we set up the experiment.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 79, 'page_label': '80'}, page_content='Hypothesis Testing - ESP Testing\\nAgain let’s review the steps that we just took when running our hypothesis \\ntest:\\n1. Establish my research hypothesis, as well as statistical hypothesis.\\n2. Establish my null and alternative hypothesis.\\n3. Calculate my test-statistic and sampling distribution.\\n4. Calculate p-value.\\n5. Interpret ﬁndings \\nAs we will see in next weeks class, we will use this same framework to \\nperform data analysis in the workplace.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 80, 'page_label': '81'}, page_content='Wrap-Up'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 81, 'page_label': '82'}, page_content='Lab (Due 04/21)\\nYou are a growth analyst at a Vancouver-based consulting ﬁrm called \\nMonica Group. Your manager is spearheading the completion of a a new \\nanalytical tool which will automatically label if a review is positive, neutral, \\nnegative, or irrelevant. \\nYou will be kicking off completion of this milestone by independently \\nimplementing a minimal-viable-product. This will be a Python pipeline that \\ningests a text-ﬁle of review data and interfaces with the Open AI API in \\norder to automatically label each review.\\nVancouver, Canada'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Hypothesis Testing.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Hypothesis Testing.pptx.pdf', 'total_pages': 83, 'page': 82, 'page_label': '83'}, page_content=\"Thursday Review Session\\nSee you all at the Thursday Review Session!\\n● Say hi to Cohort B\\n● Review GitHub\\n● Work on TLAB #2\\n● …and more!!!\\nJupyter: scratchpad of the data \\nscientist\\nIf you understand what you're doing, you're \\nnot learning anything. - Anonymous\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Conda & File I/O Review.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Conda & File I_O Review.pptx.pdf', 'total_pages': 44, 'page': 0, 'page_label': '1'}, page_content='Introduction to Conda & \\nFile I/O Review'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Conda & File I/O Review.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Conda & File I_O Review.pptx.pdf', 'total_pages': 44, 'page': 1, 'page_label': '2'}, page_content='Agenda - Schedule\\n1. Warm-Up\\n2. Software T ools\\n3. File I/O\\n4. Break\\n5. Conda Lab\\nJavaScript Object Notation (JSON) is an open-standard data \\nformat or interchange for semi-structured data. It is \\ntext-based and readable by humans and machines. \\nhttps://www.snowﬂake.com/guides/what-is-json'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Conda & File I/O Review.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Conda & File I_O Review.pptx.pdf', 'total_pages': 44, 'page': 2, 'page_label': '3'}, page_content='Agenda - Goals\\n● Ensure proper setup of all software tools for Phase 1\\n● Review usage of software tools\\n● Create conda environment\\n● Understand how to work with text ﬁles in your Python program\\n● Get familiar with opening projects in VSCode'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Conda & File I/O Review.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Conda & File I_O Review.pptx.pdf', 'total_pages': 44, 'page': 3, 'page_label': '4'}, page_content='Warm-Up'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Conda & File I/O Review.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Conda & File I_O Review.pptx.pdf', 'total_pages': 44, 'page': 4, 'page_label': '5'}, page_content='def evaluate(obj) -> bool:\\naccumulate = False\\nfor d in obj:\\nval = ﬂoat(d.strip())\\naccumulate = accumulate or val > 140\\nreturn accumulate\\nobj = open(\"data.txt\")\\nprint(evaluate(obj))\\nWork together to ﬁgure out what will occur when we run this code.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Conda & File I/O Review.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Conda & File I_O Review.pptx.pdf', 'total_pages': 44, 'page': 5, 'page_label': '6'}, page_content='Software Tools - VSCode, \\nGitHub, Pip, & Conda'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Conda & File I/O Review.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Conda & File I_O Review.pptx.pdf', 'total_pages': 44, 'page': 6, 'page_label': '7'}, page_content='VS Code\\nEvery programmer needs an integrated development \\nenvironment (IDE) or a simple code editor.\\nWe will be using VSCode. \\n● Great add-ons\\n● Easy to set up & use\\n● Great support \\nWe will be demonstrating how to open a project with \\nVSCode.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Conda & File I/O Review.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Conda & File I_O Review.pptx.pdf', 'total_pages': 44, 'page': 7, 'page_label': '8'}, page_content='Demonstration of opening VSCode'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Conda & File I/O Review.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Conda & File I_O Review.pptx.pdf', 'total_pages': 44, 'page': 8, 'page_label': '9'}, page_content='The Terminal\\nAll should technologists should be familiar with the process of navigating \\ntheir computer using a terminal.\\nReason’s being:\\n● It’s accurate\\n● It’s fast\\n● It’s used by everyone \\nAs we develop in this fellowship we should shift to using the terminal'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Conda & File I/O Review.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Conda & File I_O Review.pptx.pdf', 'total_pages': 44, 'page': 9, 'page_label': '10'}, page_content='The Terminal\\nSome commands you should get used to include:\\n● ls : list all ﬁles in current working directory\\n○ dir : if you’re on windows\\n● pwd : print working directory\\n○ cd : if you’re on windows\\n●  cd [folder]: change directory to speciﬁed folder (same on windows)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Conda & File I/O Review.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Conda & File I_O Review.pptx.pdf', 'total_pages': 44, 'page': 10, 'page_label': '11'}, page_content='Demonstration of terminal interaction'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Conda & File I/O Review.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Conda & File I_O Review.pptx.pdf', 'total_pages': 44, 'page': 11, 'page_label': '12'}, page_content='Virtual Environments - Metaphor\\nYou are a carpenter with a private business.\\nYou get requests for numerous types of jobs:\\n● House framing\\n● Wooden furniture\\n● Cabinet-making\\nWhen leaving to your worksite, you spend an hour gathering your tools \\n(inefﬁcient).'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Conda & File I/O Review.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Conda & File I_O Review.pptx.pdf', 'total_pages': 44, 'page': 12, 'page_label': '13'}, page_content='Virtual Environments - Metaphor\\nInstead you set up 3 separate tool-boxes with different sets of tools (depending on what kind of \\njob).\\nNow you can start your day by simply grabbing the box you need (efﬁcient).'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Conda & File I/O Review.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Conda & File I_O Review.pptx.pdf', 'total_pages': 44, 'page': 13, 'page_label': '14'}, page_content='Virtual Environments - Real\\nYou are a data scientist. \\nYou get requests for numerous types of jobs:\\n● Exploratory Data Analysis\\n● Dashboard building\\n● Machine Learning\\nYou will have sandboxes called “virtual environments” set up in your \\nterminal that have all the 3rd party packages necessary to complete these \\njobs (efﬁcient).'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Conda & File I/O Review.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Conda & File I_O Review.pptx.pdf', 'total_pages': 44, 'page': 14, 'page_label': '15'}, page_content=\"Virtual Environments \\nconda env create -f environment.yml\\nconda activate ds\\nconda deactivate\\n: creates a venv\\n: activates the venv\\n: deactivates the venv\\nWe will not demonstrate how to work with conda environments, instead \\nwe want to challenge you to create your own environment in tonight's \\nlab.\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Conda & File I/O Review.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Conda & File I_O Review.pptx.pdf', 'total_pages': 44, 'page': 15, 'page_label': '16'}, page_content='Pip\\npip install <package>'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Conda & File I/O Review.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Conda & File I_O Review.pptx.pdf', 'total_pages': 44, 'page': 16, 'page_label': '17'}, page_content='Pip\\npip install pandas\\npip install pandas==2.1.0\\npip install -r requirements.txt\\n: install updated pkg\\n: install speciﬁc pkg\\n: install all pckg’s'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Conda & File I/O Review.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Conda & File I_O Review.pptx.pdf', 'total_pages': 44, 'page': 17, 'page_label': '18'}, page_content='File I/O Review'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Conda & File I/O Review.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Conda & File I_O Review.pptx.pdf', 'total_pages': 44, 'page': 38, 'page_label': '39'}, page_content='Lab'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Conda & File I/O Review.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Conda & File I_O Review.pptx.pdf', 'total_pages': 44, 'page': 39, 'page_label': '40'}, page_content='Lab - Conda Module\\nFor the remaining lab time, break into your pod \\ngroups and complete the Conda Installation Lab\\nIf you encounter an error, do not give up!\\nAn expert is someone who has failed 1000s of \\nmore times than the beginner. No pain no gain.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Conda & File I/O Review.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Conda & File I_O Review.pptx.pdf', 'total_pages': 44, 'page': 40, 'page_label': '41'}, page_content='Wrap-Up'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Conda & File I/O Review.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Conda & File I_O Review.pptx.pdf', 'total_pages': 44, 'page': 41, 'page_label': '42'}, page_content='Lab (Due 03/28)\\nThe company you work for, Seng-Links, aims to identify periods when a user \\nsleeps or exercises using their varying recorded heart rates. \\nYour company has provided you a data folder (data/) of 4 ﬁles that contain \\nheart-rate samples from a participant. The participants device records heart \\nrate data every 5 minutes (aka sampling rate). \\nYou are tasked with writing code that processes each data ﬁle. You will \\nutilize test-driven development in order to complete this project.\\nTaipei City, Taiwan'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Conda & File I/O Review.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Conda & File I_O Review.pptx.pdf', 'total_pages': 44, 'page': 42, 'page_label': '43'}, page_content='Stats Quiz (Due 03/28)\\nPlease complete this quiz by 03/28.\\nThis is a 10-question quiz that will \\ntest your knowledge of statistics \\nconcepts.\\n2 attempts allowed.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Conda & File I/O Review.pptx', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Conda & File I_O Review.pptx.pdf', 'total_pages': 44, 'page': 43, 'page_label': '44'}, page_content=\"Tuesday\\nTuesday will entail:\\n● Introduction to different data formats\\n● A review of JSON data.\\nJupyter: scratchpad of the data \\nscientist\\nIf you understand what you're doing, you're \\nnot learning anything. - Anonymous\"),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 0, 'page_label': '1'}, page_content='Introduction to Data \\nAnalysis I'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 1, 'page_label': '2'}, page_content='Agenda - Schedule\\n1. Intro to Data Analytics\\n2. Basics & Charts \\n3. Functions & Pivot T ables\\n4. Break \\n5. Sheets Lab When it comes to simple data \\nanalysis, spreadsheet software \\ncannot be beat'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 2, 'page_label': '3'}, page_content='Agenda - Goals\\n● Modify column names, sort columns, and format columns in Google Sheets\\n● Create bar-plots, line-plots, and scatter plots in Google sheets\\n● Calculate aggregate metrics using the functions\\n● Create and read pivot tables in Google Spreadsheets'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 3, 'page_label': '4'}, page_content='Agenda - Announcements \\n● Week 6 Pre-Class Quiz due 4/15 (2 attempts)\\n● Career Class on 4/17 (this time for real)\\n● TLAB #2 due 4/21'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 4, 'page_label': '5'}, page_content='Warm Up'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 5, 'page_label': '6'}, page_content='Hypothesis Testing Warmup\\nWe are data analysts running a hypothesis test on our website. We would \\nlike to ﬁgure out if adding a ChatGPT Agent leads to more sales. \\nWe provide a version of our website with the ChatGPT agent to our \\nexperimental group. Our null hypothesis states that this group will spend \\nan average of $10 per customer. \\nThe experimental group spends on average $2 per customer. This gives us a \\nz-score of -4. Is this z-score in the critical region? Is this a desirable \\nz-score?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 6, 'page_label': '7'}, page_content='Data Analytics'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 7, 'page_label': '8'}, page_content='Introduction to Data Analytics\\nNow that we have the foundational computational knowledge needed to \\nwork through a series of data pipeline problems, let’s begin applying our \\nstatistical knowledge to datasets. \\nRemember, it’s vital to be able to code the pipelines needed to extract the \\ndata. \\nNow let’s go about analyzing and reasoning about the data.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 8, 'page_label': '9'}, page_content='In both TLAB 1 and TLAB 2, we went about the process of generating \\nvisualizations, which we then wrote reports on. But, what are the patterned \\ntools to completing such workﬂows?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 9, 'page_label': '10'}, page_content='Well, it’s not actually not base Python. \\nInstead it entails a series of powerful data manipulation tools which will \\nallow you to transform and eventually analyze entire data ﬁles.\\nWe will dive into one of these tools today, but before that, let’s go over what \\ndata analysis actually is.\\nData Analysis'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 10, 'page_label': '11'}, page_content='Data Analysis\\nData analysis could be deﬁned as the following:\\n● Exploratory or intentional research of insights, patterns, and trends… \\n● …on a consistent set of data objects…\\n● …where you look for reliable explanations of how things occurred in \\nthe past, or how things will occur in the future assuming certain \\nconditions.\\nThis is a loaded set of statements that we must peel back for the remainder \\nof phase 1.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 11, 'page_label': '12'}, page_content='Data Analysis\\nBefore we begin to formally deﬁne which visualizations & steps you might \\ntake to accomplish the goals listed on the previous slide, let’s run through an \\nexample.\\nY ou are a travel agency company. Like every company, you are trying to ensure \\nyour business survives and remains proﬁtable. Which questions might you have \\nabout your business?\\n● …'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 12, 'page_label': '13'}, page_content='Data Analysis\\nY ou are a travel agency company. Like every company, you are trying to ensure \\nyour business survives and remains proﬁtable. Which questions might you have \\nabout your business?\\n● How much money did we spend and make last year?\\n● Which countries did people visit the most?\\n● How have TV-shows shaped our clients travel desires?\\n● Will tariffs increase or decrease travel?\\nThe next question is, how do we answer these questions?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 13, 'page_label': '14'}, page_content='Data Analysis\\nWell the answer ﬁrst entails getting the data. \\nThe next step entails hiring a data analyst (you) who is knowledge of the statistics \\nand technology needed to effectively and reliably assess and make predictions on \\nyour data!\\nThis entails doing a few things (some of which we’ve gone over already).\\n● Transforming your dataset\\n● Calculating descriptive statistics\\n● Making pivot tables \\n● Making visualizations'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 14, 'page_label': '15'}, page_content='Data Analysis Spreadsheets\\nT o introduce you all to this process, we will begin working with Google \\nSheets.\\nWhile not as “high-tech” as other data analysis solutions out there, it is \\nstill a reliable tool and effectively does what other Python-based tools \\ndo! In fact, some data analysis teams solely use spreadsheet technology \\nto get their work done. \\nHowever, we generally don’t recommend limiting yourself to \\nspreadsheets, as there are some downsides to this.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 15, 'page_label': '16'}, page_content='For today’s spreadsheet demonstration we will work through the data ﬁle \\ntitled sample.csv. Download and extract the folder titled spreadsheets_lab \\nto get this ﬁle.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 16, 'page_label': '17'}, page_content='You can open this ﬁle by going to \\nhttps://workspace.google.com/products/sheets/ and clicking on “Sign In”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 17, 'page_label': '18'}, page_content='From there, select “Blank Spreadsheet”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 18, 'page_label': '19'}, page_content='Next click File and then Import.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 19, 'page_label': '20'}, page_content='Then you can select the Upload tab, where you can click on Browse to \\nsearch for the sample.csv ﬁle in your spreadsheet_lab folder.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 20, 'page_label': '21'}, page_content='Upon successful import, you will be able to view the following ﬁle.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 21, 'page_label': '22'}, page_content='A good chunk of data-related position will have you working with the tools \\nwe’ll be discussing.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 22, 'page_label': '23'}, page_content='Spreadsheets - Basics'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 23, 'page_label': '24'}, page_content='Spreadsheets\\nWhen beginning a data analysis project, the best thing we can do is to simply \\nview the data in Excel (or Google Sheets in our context).\\nNo technologist is too good for spreadsheets!Viewing in spreadsheets \\nallows you to:\\n● Quickly understand data\\n● Notice missing values\\n● Find dataset features'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 24, 'page_label': '25'}, page_content='Spreadsheets\\nFurthermore, when working in tech-adjacent roles where your coworkers \\nare not programmers, sheets are a nice reprieve from reading code.\\nExample: Y our growth analyst coworker would like you to modify a dataset of \\ntravel data.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 25, 'page_label': '26'}, page_content='Spreadsheets\\nGiving them a spreadsheet is usually \\nan easier “sell” than making them \\nlearn Python.\\nThink of spreadsheets as the bridge \\nbetween your computational \\nknowledge and your stakeholders \\ndomain knowledge.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 26, 'page_label': '27'}, page_content='Lets analyze a dataset of global air health metrics solely in google sheets. No Python, \\nno pandas, and no numpy.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 27, 'page_label': '28'}, page_content='Spreadsheets - Notations\\nT o get started with sheets, lets iron out a few key phrases:\\nColumn\\nA vertical arrangement of data indicated by letters. \\nRow\\nA horizontal arrangement of data indicated by numbers.\\nCell\\nAn individual square in our sheet that aligns with some row/column'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 28, 'page_label': '29'}, page_content='Column: vertical arrangement of data. We often label our own columns as \\nthey correspond to a speciﬁc “attribute” of our dataset. We can call this \\ncolumn “country” or “C”'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 29, 'page_label': '30'}, page_content='Row: horizontal arrangement of data. We sometimes label this as well, but \\nnot too often. Usually a row indicates a new sample. We can call this row 3.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 30, 'page_label': '31'}, page_content='Cell: an individual square of our data. When referring to a cell we ﬁrst \\nmention row then column. In this case it’s C3 \\n(aka row 3, column C, or row 3, column “country”, or row 3 column 3)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 31, 'page_label': '32'}, page_content='Spreadsheets - Basic Controls\\nThe key features of Sheets include\\nNavigating Cells\\nUsing our mouse or keyboard to move across the dataset.\\nModifying Cells\\nUpdating the value in a cell by simply clicking in a cell and typing.\\nAutomating Updates\\nLetting Sheets “intelligently” auto-complete our cells by dragging.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 32, 'page_label': '33'}, page_content='Modiﬁcation: let’s say I dislike the names of these year columns, let’s update \\nthem'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 33, 'page_label': '34'}, page_content='Modiﬁcation: let’s say I dislike the names of these year columns, let’s update \\nthem'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 34, 'page_label': '35'}, page_content='Modiﬁcation: let’s say I dislike the names of these year columns, let’s update \\nthem'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 35, 'page_label': '36'}, page_content='Automatic Updates: Let’s autocomplete by dragging across my two updated \\ncells over my previously created columns'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 36, 'page_label': '37'}, page_content='This automatically updates all subsequent columns.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 37, 'page_label': '38'}, page_content='Spreadsheets - Basic Controls\\nIt also pays to know that there are more advanced features by \\n“right-clicking” on a column, row, or cell. We can:\\nDelete\\nRemove data\\nSort\\nArrange your data'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 38, 'page_label': '39'}, page_content='Delete: I don’t care about the “code” column so I will just delete it.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 39, 'page_label': '40'}, page_content='Sort: Lastly, I want to arrange my data in such a way that I can see who had \\nthe lowest years of life lost per 100,000 people for poor air quality (for \\n2015)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 40, 'page_label': '41'}, page_content='Sort: I select the ﬁrst row which represents my column names. From there, I \\nselect the “funnel” icon which will apply a sort to all these columns'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 41, 'page_label': '42'}, page_content='We’ve created a ﬁlter, now let’s apply a sort on the column that represents \\n2015.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 42, 'page_label': '43'}, page_content='We click on the ﬁlter icon for our column of interest and specify the arraignment \\n(least to greatest A to Z) or (greatest to least Z to A)'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 43, 'page_label': '44'}, page_content='Now we see which country has the highest and lowest air-quality EPI metric \\nfor 2015.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 44, 'page_label': '45'}, page_content='Spreadsheets - Format Controls\\nJust like Python, we have different data-types. In sheets, we have the ability \\nto modify data-types according to human-readable types. A couple of \\nimportant types to be aware of include:\\nCurrency: Dollars & cents. Will cut off decimal values.\\nData + Time: Will force numbers into dates\\nNumber: Safe bet. Will keep a number as is.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 45, 'page_label': '46'}, page_content='By using the data format controls above, I can manipulate my column to \\nrepresent an easier-to-read real number.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 46, 'page_label': '47'}, page_content='Spreadsheets - Graphs'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 47, 'page_label': '48'}, page_content='Spreadsheets - Graphs\\nRecall that during exploratory data analysis, we generate visualizations to \\nreveal trends and dataset patterns.\\nSome common visualizations include:\\n● Bar Charts\\n● Line Plots\\n● Scatter Charts'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 48, 'page_label': '49'}, page_content='Spreadsheets - Graphs\\nUsing our table as our primary reference, we can make a variety of \\nvisualizations.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 49, 'page_label': '50'}, page_content='I ﬁrst highlight my columns of interest by dragging my mouse across my table.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 50, 'page_label': '51'}, page_content='And then select insert on the menu-bar.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 51, 'page_label': '52'}, page_content='From there, notice how I have the ability to select a chart.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 52, 'page_label': '53'}, page_content='Sheets will make a best-guess as to which chart I need.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 53, 'page_label': '54'}, page_content='On the right-hand side however, I can modify the presentation and \\naxes.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 54, 'page_label': '55'}, page_content='Let’s say I want to limit my choice to the US, and plot a line-chart \\nacross the years.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 55, 'page_label': '56'}, page_content='I switch my rows & columns.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 56, 'page_label': '57'}, page_content='Let’s remove all series except for the US'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 57, 'page_label': '58'}, page_content='And ﬁnally, let’s change this to a line plot using the “chart type” \\nmenu.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 58, 'page_label': '59'}, page_content='Notice the variety of charts available to us.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 59, 'page_label': '60'}, page_content='And now we have created a (somewhat uninteresting) line chart. \\nWhat do you notice about the labels however. Did those change?'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 60, 'page_label': '61'}, page_content='We encourage you to experiment and explore features to improve \\nyour charts.'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 61, 'page_label': '62'}, page_content='Spreadsheets - General Tips\\nWhen creating a data visualization, we have a lot of options when it comes \\nto customizing look. A couple of tips for making charts interesting & \\nimpactful include:\\n● Always label axes & titles\\n● Don’t hesitate to use signiﬁers to point to patterns/events \\n○ …but still be economical with space\\n● Large swaths of empty space usually indicates underutilized space\\n● Don’t hesitate to include text'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 62, 'page_label': '63'}, page_content='Spreadsheets - Functions'),\n",
       " Document(metadata={'producer': 'PyPDF', 'creator': 'Google', 'creationdate': '', 'title': 'Introduction to Data Analysis I', 'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Introduction to Data Analysis I.pdf', 'total_pages': 98, 'page': 63, 'page_label': '64'}, page_content='Spreadsheets - Formulas\\nMuch like in Python, we use \\nfunctions to calculate \\nmetrics & implement \\nbehavior.'),\n",
       " ...]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "documents = []\n",
    "\n",
    "for pdf in slides.glob(\"*.pdf\"):\n",
    "    pdf_pages = PyPDFLoader(pdf).load_and_split()\n",
    "    documents.extend(pdf_pages)\n",
    "\n",
    "\n",
    "documents\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fd325d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-huggingface in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.70 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langchain-huggingface) (0.3.75)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langchain-huggingface) (0.21.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.33.4 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langchain-huggingface) (0.34.3)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.20)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (24.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.11.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2025.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (4.67.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.27.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.24.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (4.6.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (2.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\casham2045\\miniconda3\\envs\\ds\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.33.4->langchain-huggingface) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "345e2e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "db = FAISS.from_documents(documents, embedder)\n",
    "\n",
    "\n",
    "retriever = db.as_retriever(search_kw={\"k\":5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "baf2f7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = retriever.invoke(\"SQL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_result = results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '958971b7-f728-40fd-9a46-41cac73d58ec',\n",
       " 'metadata': {'producer': 'PyPDF',\n",
       "  'creator': 'Google',\n",
       "  'creationdate': '',\n",
       "  'title': 'Advanced SQL I',\n",
       "  'source': 'C:\\\\Users\\\\Casham2045\\\\Downloads\\\\Phase 2 Project\\\\Operation-Genius-Alert\\\\data\\\\Advanced SQL I.pdf',\n",
       "  'total_pages': 43,\n",
       "  'page': 0,\n",
       "  'page_label': '1'},\n",
       " 'page_content': 'Advanced SQL I',\n",
       " 'type': 'Document'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_result.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'student_feedback.csv' has been created successfully!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "# Topics to base feedback on\n",
    "topics = [\n",
    "    \"Python Basics\", \"NumPy\", \"Pandas\", \"Data Visualization\",\n",
    "    \"Statistics\", \"Machine Learning\", \"SQL\", \"AB Testing\",\n",
    "    \"Data Cleaning\", \"Regression Analysis\"\n",
    "]\n",
    "# Sample feedback messages (adjusted to include topics dynamically)\n",
    "positive_feedback = [\n",
    "    \"Great job on your assignments! You’ve shown strong progress in understanding {}.\",\n",
    "    \"Excellent effort in applying {} concepts to real problems!\",\n",
    "    \"Your coding practices in {} are clean and efficient. Keep up the great work!\",\n",
    "    \"You’ve demonstrated strong analytical thinking when working with {} datasets.\",\n",
    "    \"Fantastic progress in {}. You’re ready to tackle more advanced challenges!\"\n",
    "]\n",
    "negative_feedback = [\n",
    "    \"Your submissions on {} are missing key sections, and you need to review the basics.\",\n",
    "    \"You struggled with {} exercises. Try to work on time management and practice more.\",\n",
    "    \"Your understanding of {} concepts is weak. Please revisit the lecture notes.\",\n",
    "    \"The quality of your code in {} lacks proper structure and documentation.\",\n",
    "    \"You need to participate more actively in {} activities to strengthen your understanding.\"\n",
    "]\n",
    "neutral_feedback = [\n",
    "    \"You are doing fine in {}, but try focusing more on practicing exercises.\",\n",
    "    \"Your {} concepts are clear, but revising them regularly will help retain the knowledge.\",\n",
    "    \"You’re making steady progress in {}, but solving more real-world case studies will help.\",\n",
    "    \"Consider setting aside 30 minutes daily to review {} alongside new topics.\",\n",
    "    \"Good work so far in {}, but consistency in practicing challenges is key.\"\n",
    "]\n",
    "# Feedback types\n",
    "feedback_types = [\"Positive\", \"Negative\", \"Neutral\"]\n",
    "# Generate feedback for 15 students\n",
    "students = [f\"Student_{i}\" for i in range(1, 16)]\n",
    "feedback_data = []\n",
    "for student in students:\n",
    "    topic = random.choice(topics)\n",
    "    feedback_type = random.choice(feedback_types)\n",
    "    if feedback_type == \"Positive\":\n",
    "        feedback = random.choice(positive_feedback).format(topic)\n",
    "    elif feedback_type == \"Negative\":\n",
    "        feedback = random.choice(negative_feedback).format(topic)\n",
    "    else:\n",
    "        feedback = random.choice(neutral_feedback).format(topic)\n",
    "    feedback_data.append({\n",
    "        \"Student\": student,\n",
    "        \"Feedback_Type\": feedback_type,\n",
    "        \"Topic\": topic,\n",
    "        \"Feedback\": feedback\n",
    "    })\n",
    "# Save to CSV\n",
    "filename = \"student_feedback.csv\"\n",
    "with open(filename, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=[\"Student\", \"Feedback_Type\", \"Topic\", \"Feedback\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(feedback_data)\n",
    "print(f\"CSV file '{filename}' has been created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a600686b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca8e33c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
